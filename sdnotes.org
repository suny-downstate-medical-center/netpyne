* 14jun18 Created repo
* 14sep19 First improvements by Giljael and me
** README by Gil
1.How to add new cell types in the model: <plx_cellpopdata.py> Insert cell info in lists like PMd case.  popnames = ['PMd',
'ER2', 'IF2', 'IL2', 'ER5', 'EB5', 'IF5', 'IL5', 'ER6', 'IF6', 'IL6'] popclasses = [-1, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3] #
Izhikevich population type popEorI = [ 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1] # Whether it's excitatory or inhibitory popratios =
[numPMd,150, 25, 25, 167, 72, 40, 40, 192, 32, 32] Prior cells will have lower gids. E.g., PMd.gid < ER2.gid <...<IL6.gid

Change cellproperties() according to the cell types: cell info is returned to plx_model and the info is used for simulations.
For PMd type cells, the following is added, because the number of PMd cells are not changed as scale changes.  If cells
increase in the cell types as scale increases, the following modification is not needed.  indexPopName =
checkIndexPopName('PMd', popnames) # checkIndexPopName returns PMd index in popnames if not indexPopName == -1:
popnumbers[indexPopName] = numPMd # Number of PMds is fixed. # return back the number of PMd cells to numPMd.  "ncells" is a
global value, and total number of cells in the model.

According to the cell types added, return statement in names2inds() and its call in plx_cellpopdata.py and plx_model.py
should be updated.

def setconnprobs() needs connection probabilities for new cell types. Currently inserting PMds doesn't modify this function.

def setconnweights() needs new connection weight. For the PMds, connweights[PMd,ER2,AMPA]=10 was added.

<In plx_model.py> Update "## set cell types." @Line 189 For PMd, "elif cellclasses[c]==-1: celltypes.append(pmdnsloc)" is
added. pmdnsloc is defined in nsloc.py

Update "## set positions." @Line 202 Positions are changed. That is, if new cell types are added in the model, existing cells
in the model will have different positions because of randomness change.  xlocs = modelsize*rand(ncells) # Create random x
locations ylocs = modelsize*rand(ncells) # Create random y locations zlocs = verticalextent*rand(ncells) # Create random z
locations Add zlayer position update. For PMd, "elif cellnames[c][-1]=='d': zlocs[c]+=zlayerpositions[5]" is added. 'd' is in
'PMd'.

Update "## Actually create the cells." @Line 221 In this version(r2206 in SVN), all cells including new cells inserted are
distributed evenly in a round-robin way by "for c in xrange(int(pc.id()), ncells, nhosts):."  "cellsperhost" indicates how
many cells including new cell types inserted each worker created. Each worker might have different value of cellsperhost.
For PMd, the following code snippet is executed for NULL->NetCon->PMd connection. NSLOC-based cell types will follow the code
snippet, but inncl is only to feed PMds with external PMd spikes: if cellnames[gid] == 'PMd': cell = celltypes[gid](cellid =
gid) # create an NSLOC inncl.append(h.NetCon(None, cell)) # This netcon will receive external PMd spikes innclDic[gid] =
ninnclDic # This dictionary will be used for NetCon search.  ninnclDic += 1 else:

Update ##calculate distance and probabilities. @Line 256 Connection probabilities among cells are calculated prior to making
connections, However, PMds won't be post synaptic cells in the connections. So the following code snippet is only for PMds:
if cellnames[gid] == 'PMd': # There is no connection for cells -> PMds continue In order to make connections between the new
cells added and others based on probabilities, def setconnprobs() in plx_cellpopdata.py should be modified accordingly.
Connection between a ER2 and PMd is controlled explicitly by PMd[gid%numPMd]->ER2[gid]. So, if you want to control the
connections for other cells, follow the code for PMds:

pmdStart = cpd.popGidStart[PMd] # get pmd's start gid by using cpd.popGidStart[cellname] pmdEnd = cpd.popGidEnd[PMd] # get
PMd's end gid for c in xrange(pmdStart, pmdEnd + 1): allrands[c] = 1 # set all PMd values in allrands to 1.  if
cellnames[gid] == 'ER2': pMdId = (gid % numPMd) # select PMd being connected to this ER2 cell.  allconnprobs[pMdId] = 1 # to
make this PMd connected to the ER2 cell allrands[pMdId] = 0 # to make this PMd connected to the ER2 cell distances[pMdId] =
300 # to make the NetCon delay for this connection 5ms

Update ## Add background inputs @Line 447 ER2 and PMd cells won't be fired by background spikes. The following avoid them not
to be fired by background spikes: gid = gidvec[c] if isOriginal == 0: if cellnames[gid] == 'ER2' or cellnames[gid] ==
'PMd': # 'ER2' won't be fired by background stimulations.  continue

2.How to connect m1ms with Plexon?  # Connect m1ms with Plexon
- Copy m1ms/sim/Client to Windows machine having MATLAB and Plexon software.
- Open Client/plx_mat_interface.m on the Windows machine, and set up "remoteAddr" to the IP address m1ms runs on. In
  addition, set up "addapth" with the path for the library required for the Plexon software.
- Set up parameters in m1ms/sim/config.py accordingly.  isOriginal|isCommunication|isQueueTest a. 1 | x | x - To run the
  original m1ms (Cliff's parallelized model). X means don't care b. 0 | 1 | 1 - To run m1ms w/o connection to Plexon, but
  with PMd spike files c. 0 | 1 | 0 - To run m1ms, getting spikes from Plexon through the communication program Note: for b
  and c, check if PMd spike file (spikePMd-6sec.txv) is in data/.

3. How to run m1ms?  For 2.a, 2.b: $plx_runsim <# of workers>

For 2.c, 1. $plx_runsim <# of workers> 2. Run client in the Windows machine.  3. Run the Plexon softsever.

4. How to plot raster, lfp and power spectra?  Spikes are stored in m1ms/sim/m1ms-spk.txt and m1ms-spk.txt.mat Just run
python fileplots.py m1ms-spk.txt. It stores plots to files.  $python fileplots.py m1ms-spk.txt



** List of changes by Gil
- Added PMd population receiving external input
- Cells (inlcuidng PMd) distributed over workers using round-robin (each worker doesnt have same number of cells)
- Cells not referenced by realtive id, so easier to add and reference cells
- Master worker gets data from PMd cells and broadcasts it to other workers
- With PMd data, 30 workers over 10 nodes, and 10 scale (7846 cells), this model (6sec sim) runs in real-time (6sec).
- Added P population (proprioceptive from virtual arm) and udp interface to arm
** List of changes by me
- Tidied up code and merged with cliff's tutorial code
- Included generic stimulation code based on classes, eg. class for 'natural touch', class for 'optogenetic'

* 14sep22 RL in M1 model
** stdp.mod implementation
- adapted from george's cleanmodel by cliff
- includes STDP and RL as 2 diff mechanisms -- not dopamine-based STDP! - need to modify
- To implement RL in model need to run reward_punish from each element of stdpmechs (instantiations of stdp.mod = weight
adjuster) eg. every 100 ms: for s in stdpmechs: s.reward_punish
** RL interval?
- error used RL rewards should include difference etween current and previous time step (eg. 5ms) or previous RL update (50
  or 100 ms) ??
- in arm2dms it was errro with previous time step (10 ms) -- but I think it should be prev RL update or maybe Eligibility
  trace interval or motor command window !?
- No EM lag because aready included in the musculoskeletal arm
* 15jan11 Learning targets (reward signal)  :paper:
** reward-modulated STDP between biological neurons and model neurons
- different reward signal to different L2 subpopulations depending on target
- similar to Koca15
- PMd population = 128 neurons = biological neurons
- P population = proprioceptive = PPC / Thalamus (from virtual arm)
- To speed up training: 1) play back vector of PMd inputs; 2) use simple kinematic arm (once working replace with
  musculoskeletal and retrain)
- Start with just 2 targets (left, right); if working move to 4 targets
*** Training: different options from more realistic to more practical
- Feed PMd data (for different targets) and for each one enforce exploratory movements over all targets
- STDP + RL when hand getting closer to correct target
- Plasticity only between PMd->L2; L5/CSP -> Spinal Cord; P->L2 ??
- What connections will be reinforced: those linking PMd data corresponding to target X, with the arm movements to target X
- Need to divide training and testing dataset?
- In L2/3, the accuracy of neuronal ensemble prediction of lever trajectory remained unchanged globally, with a subset of
  individual neurons retaining high prediction accuracy throughout the training period. However, in L5a, the ensemble
  prediction accuracy steadily improved, and one-third of neurons, including subcortical projection neurons, evolved to
  contribute substantially to ensemble prediction in the late stage of learning. The L2/3 network may represent coordination
  of signals from other areas throughout learning, whereas L5a may participate in the evolving network representing
  well-learned movements.(Masamizu et al, 2014)

*** Connectivity: different options from more realistic/autonomous, to more hard-wired/easy to learn
**** PMd -> L2 (all-to-all) overlapping with P -> L2 (all-to-all)
**** PMd -> L2 (all-to-50%), P -> L2 (all-to-other 50%)

* 15jan28 Focus on this model now (2 months to final demo) first steps: mpi, circuitry, conceptual framework
** Debug msarm.py so can run model
- modified msarm to use self. for most variables in run method
- 'randomOutput' arm runs fast, but dummyArm quite slow because has to search/collect spikes to generate motor command
** Test mpi in mac
*** Salvador-Duras-MacBook-Pro% mpiexec -n 4 nrniv -python -mpi model.py
ssh: Could not resolve hostname Salvador-Duras-MacBook-Pro: nodename nor servname provided, or not known
^C[mpiexec@Salvador-Duras-MacBook-Pro] Sending Ctrl-C to processes as requested [mpiexec@Salvador-Duras-MacBook-Pro] Press
Ctrl-C again to force abort [mpiexec@Salvador-Duras-MacBook-Pro] HYDU_sock_write (./utils/sock/sock.c:291): write error (Bad
file descriptor) [mpiexec@Salvador-Duras-MacBook-Pro] HYD_pmcd_pmiserv_send_signal (./pm/pmiserv/pmiserv_cb.c:170): unable to
write data to proxy [mpiexec@Salvador-Duras-MacBook-Pro] ui_cmd_cb (./pm/pmiserv/pmiserv_pmci.c:79): unable to send signal
downstream [mpiexec@Salvador-Duras-MacBook-Pro] HYDT_dmxu_poll_wait_for_event (./tools/demux/demux_poll.c:77): callback
returned error status [mpiexec@Salvador-Duras-MacBook-Pro] HYD_pmci_wait_for_completion (./pm/pmiserv/pmiserv_pmci.c:197):
error waiting for event [mpiexec@Salvador-Duras-MacBook-Pro] main (./ui/mpich/mpiexec.c:331): process manager error waiting
for completion
*** Salvador-Duras-MacBook-Pro% mpiexec
[mpiexec@Salvador-Duras-MacBook-Pro] set_default_values (./ui/mpich/utils.c:1542): no executable provided
[mpiexec@Salvador-Duras-MacBook-Pro] HYD_uii_mpx_get_parameters (./ui/mpich/utils.c:1751): setting default values failed
[mpiexec@Salvador-Duras-MacBook-Pro] main (./ui/mpich/mpiexec.c:153): error parsing parameters Salvador-Duras-MacBook-Pro%
which mpiexec /usr/local/bin/mpich3/bin/mpiexec

*** Salvador-Duras-MacBook-Pro% brew install mpich - works
==> Installing dependencies for mpich2: cloog, gfortran Error: You must `brew link isl' before cloog can be installed
Salvador-Duras-MacBook-Pro% brew link isl Linking /usr/local/Cellar/isl/0.12.1... 9 symlinks created
Salvador-Duras-MacBook-Pro% brew install mpich ==> Installing dependencies for mpich2: cloog, gfortran ==> Installing mpich2
dependency: cloog ==> Downloading https://downloads.sf.net/project/machomebrew/Bottles/cloog-0.18.1.mavericks.bottle.1.tar.gz
######################################################################## 100.0% ==> Pouring
cloog-0.18.1.mavericks.bottle.1.tar.gz ðŸº /usr/local/Cellar/cloog/0.18.1: 33 files, 556K ==> Installing mpich2 dependency:
gfortran ==> Downloading https://downloads.sf.net/project/machomebrew/Bottles/gfortran-4.8.2.mavericks.bottle.1.tar.gz
######################################################################## 100.0% ==> Pouring
gfortran-4.8.2.mavericks.bottle.1.tar.gz ==> Caveats Formulae that require a Fortran compiler should use: depends_on :fortran
==> Summary ðŸº /usr/local/Cellar/gfortran/4.8.2: 960 files, 113M ==> Installing mpich2 ==> Using Homebrew-provided fortran
compiler.  This may be changed by setting the FC environment variable.  ==> Downloading
http://www.mpich.org/static/downloads/3.1/mpich-3.1.tar.gz
######################################################################## 100.0% ==> ./configure --disable-silent-rules
--prefix=/usr/local/Cellar/mpich2/3.1 --mandir=/usr/local/Cellar/mpich2/3.1/share/man ==> make ==> make install ðŸº
/usr/local/Cellar/mpich2/3.1: 457 files, 15M, built in 3.3 minutes Salvador-Duras-MacBook-Pro%
*** Warning: detected user attempt to enable MPI, but MPI support was disabled at build time.

** Install NEURON in mac
http://www.neuron.yale.edu/neuron/download/compilestd_osx

brew install mpich build.sh config: ./configure --with-iv=$IVB --prefix=$ND --with-nrnpython=dynamic CC='gcc-4.6'
CCX='g++-4.6' --with-paranrn https://discussions.apple.com/thread/3406578 make make install python setup.py install
--home=/usr/arch/nrn/share/python

*** clean steps from scratch
- install required libraries via brew (list of libs?)
- brew install open-mpi
- cd $NSRC; ./build.sh
-./configure --with-iv=$IVB/iv --prefix=$ND --with-nrnpython=dynamic CC='gcc-4.6' CCX='g++-4.6' --with-paranrn=dynamic
- sudo bash
- export ARCHFLAGS='-arch i386 -arch x86_64'
- cd $ND
- make
- make install
- cd $NB/src/nrnpython
- python setup.py install --home=/usr/arch/nrn/share/python

**** didnt work (see error here)
Salvador-Duras-MacBook-Pro% m1ms Salvador-Duras-MacBook-Pro% /usr/local/Cellar/open-mpi/1.7.4/bin/mpirun -n 4 nrniv -python
-mpi model.py dyld: Library not loaded: /usr/local/lib/libpmpich.12.dylib Referenced from:
/usr/arch/nrn/x86_64/lib/libnrnoc.0.dylib Reason: image not found dyld: Library not loaded: /usr/local/lib/libpmpich.12.dylib
Referenced from: /usr/arch/nrn/x86_64/lib/libnrnoc.0.dylib Reason: image not found dyld: Library not loaded:
/usr/local/lib/libpmpich.12.dylib Referenced from: /usr/arch/nrn/x86_64/lib/libnrnoc.0.dylib Reason: image not found dyld:
Library not loaded: /usr/local/lib/libpmpich.12.dylib Referenced from: /usr/arch/nrn/x86_64/lib/libnrnoc.0.dylib Reason:
image not found -------------------------------------------------------------------------- mpirun noticed that process rank 2
with PID 24333 on node Salvador-Duras-MacBook-Pro exited on signal 5 (Trace/BPT trap: 5).
-------------------------------------------------------------------------- Salvador-Duras-MacBook-Pro% nrniv dyld: Library
not loaded: /usr/local/lib/libpmpich.12.dylib Referenced from: /usr/arch/nrn/x86_64/lib/libnrnoc.0.dylib Reason: image not
found Trace/BPT trap

**** try specifying open-mpi folder - worked!
 ./configure --with-iv=$IVB/iv --prefix=$ND --with-nrnpython=dynamic CC='gcc-4.6' CCX='g++-4.6'
 --with-paranrn=/usr/local/Cellar/open-mpi/1.7.4/

** Define inputs to M1 circuitry :paper:
*** what layer do proprioceptive inputs (via spinal cord+thalamus) target?
- thalamic inputs to upper layers (Weiler et al,2008; Kiritani et al, 2010)
- Thalamocortical inputs from anterior, motor-related thalamic regions (VA/VL) with cerebellar afferents -> L2/3, L5A, L5B (IT+PT)
  (Hooks et al, 2013)
- Posterior sensory-related thalamic areas (POm) -> L2/3 and L5A (Hooks et al, 2013)
- Inputs from sensory-related cortical and thalamic areas preferentially target the upper-layer pyramidal neurons in
  vM1.(Hooks et al, 2013)
- VL axons in the cortex excited both IT and PT neurons (Yamawaki & Shepherd, 2015)
- Area 2 receives its main input from area 1 as well as from the VPS, which is the main relay nucleus for proprioceptive
  information in the monkey. (Francis 2009); Until recently, the rat homolog of the VPS had not been identified, which is
  surprising given the wide spread use of the rat as an animal model. (Francis 2009) --> In macaque proprioceptive info via
  VPS
- Mapped out a region in the rostral VPL of the rat that responds preferentially to joint manipulation and muscle palpation
  (Francis et al. 2008) --> In rat proprioceptive info via VPL

*** what layer do PMd inputs target?
- cortical inputs to upper layers (Weiler et al,2008; Kiritani et al, 2010)
- Orbital cortex (OC) -> L6
- Secondary motor cortex (M2) -> L5B
- Inputs from OC and M2, areas associated with volitional and cognitive aspects of movements, bypass local circuitry and have
  direct monosynaptic access to neurons projecting to brainstem and thalamus.
- In macaque input from PMd seems to go primarily to upper layers (layer 1?) and spread across the rest (based on fig 2 Shipp, 2005) 
- In macaque PMd->M1 target ~55% deep layers and ~45% superficial layers (1-3) (Dum & Strick, 2005)
- In rhesus monkey more than 90% of all labeled neurons within the premotor and motor cortices were found in layer 3; the rest in
  layers 5 and 6 (Barbas & Panday, 1987)

- "In L2/3, the accuracy of neuronal ensemble prediction of lever trajectory remained unchanged globally, with a subset of
  individual neurons retaining high prediction accuracy throughout the training period. However, in L5a, the ensemble
  prediction accuracy steadily improved, and one-third of neurons, including subcortical projection neurons, evolved to
  contribute substantially to ensemble prediction in the late stage of learning. The L2/3 network may represent coordination
  of signals from other areas throughout learning, whereas L5a may participate in the evolving network representing
  well-learned movements" (Masamizu et al, 2014)

** Cell and neuron densities in the primary motor cortex of primates (Young,2013)
** Added new spinal cord populations
*** code
-popnames = ['PMd', 'ASC', 'DSC', 'ER2', 'IF2', 'IL2', 'ER5', 'EB5', 'IF5', 'IL5', 'ER6', 'IF6', 'IL6'] popclasses = [-1, -1,
--1, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3] # Izhikevich population type popEorI = [ 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1] # Whether
-it's excitatory or inhibitory popratios = [numPMd, 48, 48, 150, 25, 25, 167, 72, 40, 40, 192, 32, 32] # Cell population
-numbers
*** description
- PMd = input from PMd with target/reward information; NSLOCs; reproduces PMd recorded data
- ASC = Ascending Spinal Cord; proprioceptive info; encode x-y speed (previously P population encoding muscle lengths); 
- DSC = Descending Spinal Cord; muscle excitations; receives input from EB5 (all-to-all mapping)
  
** Proprioceptive population encodes cartesian direction and velocity :papers:
*** From Roll04
It is widely recognized nowadays that sensory information produced by muscle spindles constitutes a crucial part of
proprioception (Cordo 1990; Gandevia 1996; Gandevia and Burke 1992; Roll 2003). As far as the sensory level is concerned, one
might mention recent studies examining the coding of two-dimensional pointing and drawing movements, the results of which
have shown that muscle spindle population activity is strongly correlated with both the direction and the velocity of the
ongoing movement under both passive and active conditions (Bergenheim et al. 2000; Roll et al. 2000; Jones et al. 2001). In
addition, these studies showed that each muscle spindle is sensitive to a specific range of movement directions (the
so-called preferred sensory sector, PSS), and shows maximum sensitivity to a specific direction (denoted the preferred
sensory direction, PSD). The PSS and the PSD of the various muscle spindles within a given muscle are quite similar, which
makes it possible to calculate an average PSD and PSS for that muscle. Each muscle has its own PSD and PSS which differs from
those of other muscles.  When examining the PSS of the muscle groups acting on the ankle joint, it was observed that they
overlapped in such a way that, together, they covered the whole range of possible movement directions in that particular
joint (Bergenheim et al. 2000; Roll et al. 2000). The authors of the latter studies concluded that the proprioceptive
information arising from all muscles surrounding a joint was needed for accurate sensory and perceptual coding to be
performed throughout the whole movement.  In other studies, using a similar population vector model to that used by Schwartz
(1992, 1993) at the cortical level, it was established that the â€œsum vectorâ€ of all the oriented and weighted activity from
the whole population of muscle spindles in all the muscles acting on a given joint, accurately describes the instantaneous
direction and velocity of the ongoing movement in two dimensional space (Bergenheim et al. 2000; Roll et al. 2000; Jones et
al. 2001; Ribot-Ciscar et al. 2002).

*** From Bosc01 cited in Fran09
XV. SUMMARY

A.â€‚ Role of Limb Biomechanics in Global Limb Representations

We have presentedhere a possible framework for interpreting proprioceptive signals at the spinal level. It is based on the
premise that global limb information rather than localized receptor-like proprioceptive information is encoded by the nervous
system. Within a basic global framework, information is encoded by a distributed system in which each neural element may
still bias the global information according to some local detail. For example, the DSCT data suggest that details about
stiffness at a single joint might be contained in a population signal that encodes a representation of the limb end point
that may then depend on the joint covariance resulting from specific levels of joint stiffness.

This global sensory representation is not organized entirely by the neural circuitry however. It begins in the periphery with
the biomechanical structure of the limb. Biomechanical constraints ensure that theactivity from individual sensory receptors
will be correlated in certain ways that depend on whole limb parameters. Therefore, even a minimum of central sensory
convergence could lead to global representations with this peripheral apparatus (37,38, 281).

B.â€‚ Significance of Kinematic-Based Representations

We also suggest that this framework could be based on limb kinematics. If so, it is noteworthy that while many participating
sensory receptors are associated with muscles and some even specifically tuned to muscle force, nevertheless their ensemble
is capable of encoding limb kinematics. In other words, inputs from receptors located in individual muscles or associated
deep structures as well as in the skin are assembled at very early stages of central processing to provide a representation
of limb kinematics. Because this occurs at these earliest stages, it suggests that the peripheral apparatus may also in some
way play a role in itsdetermination. The result, however, is that centrally directed sensory information may be encoded in a
framework common to that of central motor activity that relates to limb kinematics. It may therefore be analogous to the
situation in the superior colliculus where sensory information from various modalities is mapped congruently within a
retinotopic map (227, 306) that may be modified or transformed by gaze (123, 124,157, 158); that is, the sensory information
is combined and integrated through a common coding framework. Although the retinal projection may provide the basis for a
common framework for eye, head, and body movement control, limb biomechanics and associated proprioceptors appear to provide
the basis for a common framework for limb movement control.
*** From Berg00
The results show that each muscle spindle afferent, and likewise each muscle, has a specific preferred sensory direction, as
well as a preferred sensory sector within which it is capable of sending sensory information to the central nervous
system. Interestingly, the results also demonstrate that the preferred directions are the same as the directions of
vibration-induced illusions. In addition, the results show that the neuronal population vector model describes the
multipopulation proprioceptive coding of spatially oriented 2D limb movements, even at the peripheral sensory level, based on
the sum vectors calculated from all the muscles involved in the movement.
 

** PMd input with multiple targets requires new conceptual framework! :papers:
- PMd provides preparation activity -- where to go; target info with respect to hand
- Learning adpats weight to map different PMd activity to M1 activity that directs arm to different targets
- ASC population encodes proprioceptive info from arm (direction and velocity) and visual feedback from eyes (arm position;
  or arm - target position) -- doesn't make sense because ASC (=spinal cord) doesn't contain vision; would have to call it
PPC -- if only encode direction (population code for angle) and velocity (amplitude as firing rate), system shouldn't be able
to tell difference if placed in different starting point; however this may not be required because input from PMd is guiding
movement (ie. telling system, go to the right/left etc., not specifying target location!), so can argue hand/target position
more relevant for PMd (?!)  -- when pmd activity dies off (reached target), so should M1 activity?


- "We demonstrate that an MI ensemble can reconstruct hand or joint trajectory more accurately than an equally sized PMd
  ensemble.In contrast, PMd can more precisely predict the future occurrence of one of several discrete targets to be
  reached.These results also support the hierarchical view that MI ensembles are involved in lower-level movement execution,
  whereas PMd populations represent the early intention to move to visually presented targets." Hatsopoulos, 2004

- Above also possible argument for developing model of M1 -- PMd activity itself doesn't provide accurate position/vel representation

* 15feb06 dummyArm
- dummyArm was independent python executable which used udp messages to communicate with model
- udp obsolete (now pipes)
- replaced dummyArm with same code but running within model (no udp or pipes)
- requires all same RL apparatus; after that working test muscskel
* 15feb09 MPI issues: gidDic, motor commands, and RL
** gidVec vs gidDic
- CHECK gidVec vs gidDic
- gidVec is vector local to each node, where index=local id, and value = gid
- gidDic is dictionary local to each node, where key=global id, value = local id 
- redundant! but using gidVec.index() to get the local id is very slow (~300x slower) -- so use gidDic to get local id
*** speed comparison from gil
gidvec.index() takes so long time.  Test for vec.index and dictionary import time import random vec = [] for c in
range(10000): vec.append(c) dic = { x:x for x in range(10000)} seq = range(10000) random.shuffle(seq) measure = time.time()
for c in seq: a = vec.index(c) measure = time.time() - measure print 'vec.index:', measure measure = time.time() for c in
seq: b = dic[c] measure = time.time() - measure print 'dic:', measure

vec.index: 1.80838108063 dic: 0.00332403182983

*** speed comparison in m1 model
10k cells, 1sec sim, 16 cores, with gidVec.index() = 153 sec 10k cells, 1sec sim, 16 cores, with gidDic = 25.9 sec = x5.9
speedup
** differences when using mpi with different number of nodes due to motor commands implementation
- not present when arm is off
- not present when proprio is off -> due to proprio -- not true, also present with propio off 
- joint angles different in 1 vs 16 cores
- not due to broadcasting error - same before and after
- difference in motor commands! - maybe due to timing?
- FOUND: error originates in these 2 lines used to speed up sim by removing past spikes from list:

#self.hostspiketimes = self.hostspiketimes[self.hostspiketimes > (h.t - 2*max(self.shtimewin,self.eltimewin))] # remove
#unncessary old spikes self.hostspikecells = self.hostspikecells[self.hostspiketimes > (h.t - 
2*max(self.shtimewin,self.eltimewin))] # remove unncessary old spikes

JUST HAD TO SWITCH AROUND TO AVOID SPIKETIMES GETTING DELETED BEFORE USING IT TO SEARCH SPIKECELLS!!

- still diffs when add RL

** differences when using mpi with different number of nodes due to RL (STDP BUG AND FIX)
- different num of spikes when using 1 vs >1 cores
- was only changing weights in worker0
- seems error related to STDP  -- also happens when RL off
- doesn't happen when STDP off
- also happens in cliff tutorial code
- can reproduce easily with this code: http://neuron.yale.edu/neuron/static/courses/cns2014/large-scale.zip , scale=4,
 duration=3, 1 vs 8 mpi cores 
- also tested in neurosim (zn) /u/salvadord/Documents/ISB/Models/large-scale/
- also happens when using scale=3, dur=3, 4 vs 12 cores (Spikes: 14031 vs 14003)
- compared output: difference in weightchanges (38/83311), spikes (28/14031) and lfp; rest the same:
        distances: [164138x1 double]
             EorI: [3000x1 int64]
          lfptime: [600x1 double]
            ylocs: [3000x1 double]
         cellpops: [3000x1 int64]
         stimdata: []
           delays: [164138x1 double]
      cellclasses: [3000x1 int64]
        cellnames: [3000x3 char]
      connweights: [15x15x4 double]
        connprobs: [15x15 double]
      connections: [164138x2 double]
            xlocs: [3000x1 double]
          weights: [164138x4 double]
          simcode: {7x1 cell}
    weightchanges: {83311x1 cell}
         stdpdata: [83311x3 double]
        spikedata: [14031x2 double]
            zlocs: [3000x1 double]
             lfps: [600x6 double]
*** chat with cliff
cliff I find differences in the number of spikes when using 1 core vs >1 core did u have this problem?  I tested the sim you
used for tutorial and also reproduced it there eg. 1 core = 19771 spikes; 8 cores = 19758 spikes Cliff Kerr hmm that's
strange -- i used to have that problem but it got fixed at some point, could've gotten broken again though...  it had to do
with the random seeds being initialized differently Salvador Dura so how did u fix? maybe I ahve old version hmm ok, I'll
check that I was thinking it was stdp related cause doesn't seem to happen when stdp off -- but need to check more thoroughly
was thinking maybe related to stdp happening between cells in different cores, but just speculation Cliff Kerr each cell
should have its own random number generator linked to gid but it's possible i haven't checked for stdp Salvador Dura so the
random generator error u had, was related to using different number of cores?  Cliff Kerr yeah Salvador Dura cause if I use
the same number of cores, the result is always the same ok it seems when stdp off, error doesnt happen Cliff Kerr
interesting...  Salvador Dura I'll check the rand gen and the stdp code, see if I can find anything Cliff Kerr anyway my
feeling is that it's probably not a big deal, i.e. each one is equally valid, but yeah agree they should match Salvador Dura
@equally valid - yeah probably, but just need for reproducibility of results -- small error could carry forward in time I
guess
sal:can reproduce easily with this code: http://neuron.yale.edu/neuron/static/courses/cns2014/large-scale.zip , scale=4, duration=3, 1 vs 8 mpi cores
cliff: i guess you could check that the stdp connections and weights are the same in the 1 and 8 core cases?

*** more systematic tests
**** scale=2, dur=2, 1 vs 2 cores
- differences in weightchanges:
conn    pre    post     weightchanges (1 core)                          weightchanges (2 cores) gid (1core) gid (2cores)
645	602	35	[0,2.63385014695182;1005,2.61453901661609]	[0,2.63385014695182]	[0,0]	[1,0]
646	672	35	[0,0.486465429624879;1005,0.467154299289152]	[0,0.486465429624879]	[0,0]	[1,0]
3326	532	178	[0,2.65632182511313;1005,2.64518027212770]	[0,2.65632182511313]	[0,0]	[1,0]
3540	639	188	[0,1.82277902626864;1005,1.81531061995854]	[0,1.82277902626864]	[0,0]	[1,0]

- weight decreases due to antiHebb learning
- spike times:
cell    spk time
602	540

35	514
35	540

672	540
672	1278.50000000000
672	1689.50000000000

- occurs when spk time same in pre and post
- fixed (do differences now) by changing stdp.mod :
if  ((tlastpost > -1) && (interval != 0))  -->  if  ((tlastpost > -1) && (interval > 0.0))
if  ((tlastpre > -1) && (interval != 0.0))  -->  if  ((tlastpre > -1) && (interval > 0.0)) 

**** tested using scale=4, dur=4, 1 vs 16 cores --> >10k weightchange diffs and 82 more spikes

**** test scale scale=2, dur=2, 1 vs 16 cores --> 22 wc diffs, 1 spike more:
conn    pre    post     weightchanges (1 core)                          weightchanges (2 cores) gid (1core) gid (2cores)
349	134	11	[0,2.86023987946172]	[0,2.86023987946172;1005,2.90268947422707]	[0,0]	[1,0]
654	358	22	[0,0.149294195666084;1005,0.305054352280365]	[0,0.149294195666084]	[0,0]	[2,0]
3246	536	106	[0,2.73408129675365]	[0,2.73408129675365;1005,2.73408129675365]	[0,0]	[4,0]
3278	1269	107	[0,1.74122404294975]	[0,1.74122404294975;1005,1.74122404359625]	[0,0]	[10,0]
6487	362	218	[0,1.34847151295259]	[0,1.34847151295259;1005,1.37991894621531]	[0,0]	[2,1]
7360	499	249	[0,1.79714956561962]	[0,1.79714956561962;1005,1.85738840800206]	[0,0]	[3,1]
8881	1203	300	[0,1.68536212703375]	[0,1.68536212703375;1005,1.74266308640579]	[0,0]	[9,2]
17022	9	578	[0,1.61835650498962]	[0,1.61835650498962;1005,1.62882444617930]	[0,0]	[0,4]
17023	22	578	[0,2.35002265490450]	[0,2.35002265490450;1005,2.36728137220437]	[0,0]	[0,4]
17024	29	578	[0,1.70413279263212]	[0,1.70413279263212;1005,1.70487236537541]	[0,0]	[0,4]
17025	121	578	[0,1.33952623608263]	[0,1.33952623608263;1005,1.34080810277188]	[0,0]	[0,4]
17028	202	578	[0,1.07834345749672]	[0,1.07834345749672;1005,1.07920271843487]	[0,0]	[1,4]
17029	217	578	[0,0.629349148726955]	[0,0.629349148726955;1005,0.648422981170065]	[0,0]	[1,4]
17032	325	578	[0,1.41251536458843]	[0,1.41251536458843;1005,1.41367524553380]	[0,0]	[2,4]
17033	363	578	[0,0.665475706621114]	[0,0.665475706621114;1005,0.666293060908807]	[0,0]	[2,4]
17034	397	578	[0,2.45872497666071]	[0,2.45872497666071;1005,2.47285521927279]	[0,0]	[3,4]
17036	434	578	[0,1.07763999597961]	[0,1.07763999597961;1005,1.07834349933459]	[0,0]	[3,4]
17037	493	578	[0,0.145238375107857]	[0,0.145238375107857;1005,0.146015866556552]	[0,0]	[3,4]
17038	525	578	[0,1.42405633633909]	[0,1.42405633633909;1005,1.42491559727724]	[0,0]	[4,4]
17043	849	578	[0,20.7127766032884]	[0,20.7127766032884;1005,20.7249386158134]	[0,0]	[6,4]
23626	896	827	[0,2.36270498436227]	[0,2.36270498436227;1005,2.36270498436295]	[0,0]	[7,6]
30949	1285	1221	[0,0.0225237576864728]	[0,0.0225237576864728;1005,0.0225237576892504]	[0,0]	[10,9]

- spike times:
---------------- (same t)
134	709
134	724.500000000000 *
134	1215
134	1507.50000000000
134	1522
134	1936.50000000000

11	704
11	724.500000000000 *
11	1220
11	1502
11	1522.50000000000
11	1932

-------------- (different t, but diff spikes)
358	761.500000000000 *
358	1264.50000000000
358	1559

(2 cores)
22	728
22	764 *
22	1267
22	1524
22	1548

(1 core)
22	728
22	756.500000000000
22	1267
22	1524
22	1548

---------------- (same t)
536	553.500000000000 *
536	570.500000000000
536	902 *
536	1198.50000000000

106	546.500000000000 *
106	902 *
106	1202

---------------- (same t)
362	728 *
362	1242
362	1505
362	1526
362	1936

218	728 *
218	1139
218	1216
218	1524.50000000000

*** tried modifying stdp.mod to increase interval
if  ((tlastpre > -1) && (interval > 0.01)) - 22 diffs
if  ((tlastpre > -1) && (interval > 0.1)) - 22 diffs 
if  ((tlastpre > -1) && (interval > 1)) - 26 diffs
if  ((tlastpre > -1) && (interval > 2.0)) - 26 diffs
if  ((tlastpre > -1) && (interval > 2.0)) - 13 diffs

*** found problem!
17.47 found problem: when pre is in different node and happens same time as post, the pre net_receive event sometimes arrives after post, so pre time is still previous spike time of that cell and thus stdp happens this is quite common since all spk times interval of 0.5 ms !

*** fixed problem!
20.44 found fix for stdp bug: instead of updating w directly use net_send() to update 1ms later and check for simultaneous
spike; tested with 10-sec 10k cell sim for 1 vs 10 cores and both identical; code here:
/u/salvadord/Documents/ISB/Models/large-scale/stdp.mod  

*** Code with fix for bug
COMMENT

STDP + RL weight adjuster mechanism

Original STDP code adapted from:
http://senselab.med.yale.edu/modeldb/showmodel.asp?model=64261&file=\bfstdp\stdwa_songabbott.mod

Adapted to implement a "nearest-neighbor spike-interaction" model (see 
Scholarpedia article on STDP) that just looks at the last-seen pre- and 
post-synaptic spikes, and implementing a reinforcement learning algorithm based
on (Chadderdon et al., 2012):
http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0047251

Modified by salvadord to avoid bug when simultaneous pre and post spikes occur in different nodes (with mpi)

Example Python usage:

from neuron import h

## Create cells
dummy = h.Section() # Create a dummy section to put the point processes in
ncells = 2
cells = []
for c in range(ncells): cells.append(h.IntFire4(0,sec=dummy)) # Create the cells

## Create synapses
threshold = 10 # Set voltage threshold
delay = 1 # Set connection delay
singlesyn = h.NetCon(cells[0],cells[1], threshold, delay, 0.5) # Create a connection between the cells
stdpmech = h.STDP(0,sec=dummy) # Create the STDP mechanism
presyn = h.NetCon(cells[0],stdpmech, threshold, delay, 1) # Feed presynaptic spikes to the STDP mechanism -- must have weight >0
pstsyn = h.NetCon(cells[1],stdpmech, threshold, delay, -1) # Feed postsynaptic spikes to the STDP mechanism -- must have weight <0
h.setpointer(singlesyn._ref_weight[0],'synweight',stdpmech) # Point the STDP mechanism to the connection weight

Version: 2013oct24 by cliffk

ENDCOMMENT

NEURON {
    POINT_PROCESS STDP : Definition of mechanism
    POINTER synweight : Pointer to the weight (in a NetCon object) to be adjusted.
    RANGE tauhebb, tauanti : LTP/LTD decay time constants (in ms) for the Hebbian (pre-before-post-synaptic spikes), and anti-Hebbian (post-before-pre-synaptic) cases. 
    RANGE potrate, deprate : Maximal adjustment (can be positive or negative) for Hebbian and anti-Hebbian cases (i.e., as inter-spike interval approaches zero).  This should be set positive for LTP and negative for LTD.
    RANGE RLwindhebb, RLwindanti : Maximum interval between pre- and post-synaptic events for an starting an eligibility trace.  There are separate ones for the Hebbian and anti-Hebbian events.
    RANGE useRLexp : Use exponentially decaying eligibility traces?  If 0, then the eligibility traces are binary, turning on at the beginning and completely off after time has passed corresponding to RLlen.
    RANGE RLlenhebb, RLlenanti : Length of the eligibility Hebbian and anti-Hebbian eligibility traces, or the decay time constants if the traces are decaying exponentials.
    RANGE RLpotrate, RLdeprate : Maximum gains to be applied to the reward or punishing signal by Hebbian and anti-Hebbian eligibility traces.  
    RANGE wmax : The maximum weight for the synapse.
    RANGE softthresh : Flag turning on "soft thresholding" for the maximal adjustment parameters.
    RANGE STDPon : Flag for turning STDP adjustment on / off.
    RANGE RLon : Flag for turning RL adjustment on / off.
    RANGE verbose : Flag for turning off prints of weight update events for debugging.
    RANGE tlastpre, tlastpost : Remembered times for last pre- and post-synaptic spikes.
    RANGE tlasthebbelig, tlastantielig : Remembered times for Hebbian anti-Hebbian eligibility traces.
    RANGE interval : Interval between current time t and previous spike.
    RANGE deltaw : The calculated weight change.
    RANGE newweight : New calculated weight.
}

ASSIGNED {
    synweight        
    tlastpre   (ms)    
    tlastpost  (ms)   
    tlasthebbelig   (ms)    
    tlastantielig  (ms)        
    interval    (ms)    
    deltaw
    newweight          
}

INITIAL {
    tlastpre = -1            : no spike yet
    tlastpost = -1           : no spike yet
    tlasthebbelig = -1      : no eligibility yet
    tlastantielig = -1  : no eligibility yet   
    interval = 0
    deltaw = 0
    newweight = 0
}

PARAMETER {
    tauhebb  = 10  (ms)   
    tauanti  = 10  (ms)    
    potrate = 1.0
    deprate = -1.0
    RLwindhebb = 10 (ms)
    RLwindanti = 10 (ms)
    useRLexp = 0   : default to using binary eligibility traces
    RLlenhebb = 100 (ms)
    RLlenanti = 100 (ms)
    RLpotrate = 1.0
    RLdeprate = -1.0
    wmax  = 15.0
    softthresh = 0
    STDPon = 1
    RLon = 1
    verbose = 0
}

NET_RECEIVE (w) {
     deltaw = 0.0 : Default the weight change to 0.

    : Hebbian weight update happens 1ms later to check for simultaneous spikes (otherwise bug when using mpi)
    if ((flag == -1) && (tlastpre != t-1)) {   
        w = 0
        deltaw = potrate * exp(-interval / tauhebb)   : Use the Hebbian decay to set the Hebbian weight adjustment. 
        if (softthresh == 1) { deltaw = softthreshold(deltaw) } : If we have soft-thresholding on, apply it.
        if (verbose > 0) { printf("Hebbian STDP event: t = %f ms; tlastpre = %f ms; interval = %f; deltaw = %f\n",t,tlastpre,interval,deltaw) } : Show weight update information if debugging on.
    }

    : Ant-hebbian weight update happens 1ms later to check for simultaneous spikes (otherwise bug when using mpi)
    else if ((flag == 1) && (tlastpost != t-1)) { :update weight 1ms later to check for simultaneous spikes (otherwise bug when using mpi)
        w = 0
        deltaw = deprate * exp(interval / tauanti) : Use the anti-Hebbian decay to set the anti-Hebbian weight adjustment.
        if (softthresh == 1) { deltaw = softthreshold(deltaw) } : If we have soft-thresholding on, apply it.
        if (verbose > 0) { printf("anti-Hebbian STDP event: t = %f ms; deltaw = %f\n",t,deltaw) } : Show weight update information if debugging on. 
    }
     
    : If we receive a non-negative weight value, we are receiving a pre-synaptic spike (and thus need to check for an anti-Hebbian event, since the post-synaptic weight must be earlier).
    if (w > 0) {           
        interval = tlastpost - t  : Get the interval; interval is negative
        if  ((tlastpost > -1) && (interval > 0.0)) { : If we had a post-synaptic spike and a non-zero interval...
            if (STDPon == 1) { : If STDP learning is turned on...
                net_send(1,1) : instead of updating weight directly, use net_send to check if simultaneous spike occurred (otherwise bug when using mpi)    
            }
            if ((RLon == 1) && (-interval <= RLwindanti)) { tlastantielig = t } : If RL and anti-Hebbian eligibility traces are turned on, and the interval falls within the maximum window for eligibility, remember the eligibilty trace start at the current time.
        }
        tlastpre = t : Remember the current spike time for next NET_RECEIVE.  
    
    : Else, if we receive a negative weight value, we are receiving a post-synaptic spike (and thus need to check for an anti-Hebbian event, since the post-synaptic weight must be earlier).    
    } else if (w < 0) {            
        interval = t - tlastpre : Get the interval; interval is positive
        if  ((tlastpre > -1) && (interval > 1.0)) { : If we had a pre-synaptic spike and a non-zero interval...
            if (STDPon == 1) { : If STDP learning is turned on...
                net_send(1,-1) : instead of updating weight directly, use net_send to check if simultaneous spike occurred (otherwise bug when using mpi)
            }
            if ((RLon == 1) && (interval <= RLwindhebb)) { tlasthebbelig = t } : If RL and Hebbian eligibility traces are turned on, and the interval falls within the maximum window for eligibility, remember the eligibilty trace start at the current time.
        }
        tlastpost = t : Remember the current spike time for next NET_RECEIVE.
    }
    adjustweight(deltaw) : Adjust the weight.
}

PROCEDURE reward_punish(reinf) {
    if (RLon == 1) { : If RL is turned on...
        deltaw = 0.0 : Start the weight change as being 0.
        deltaw = deltaw + reinf * hebbRL() : If we have the Hebbian eligibility traces on, add their effect in.   
        deltaw = deltaw + reinf * antiRL() : If we have the anti-Hebbian eligibility traces on, add their effect in.
        if (softthresh == 1) { deltaw = softthreshold(deltaw) }  : If we have soft-thresholding on, apply it.  
        adjustweight(deltaw) : Adjust the weight.
        if (verbose > 0) { printf("RL event: t = %f ms; deltaw = %f\n",t,deltaw) } : Show weight update information if debugging on.     
    }
}

FUNCTION hebbRL() {
    if ((RLon == 0) || (tlasthebbelig < 0.0)) { hebbRL = 0.0  } : If RL is turned off or eligibility has not occurred yet, return 0.0.
    else if (useRLexp == 0) { : If we are using a binary (i.e. square-wave) eligibility traces...
        if (t - tlasthebbelig <= RLlenhebb) { hebbRL = RLpotrate } : If we are within the length of the eligibility trace...
        else { hebbRL = 0.0 } : Otherwise (outside the length), return 0.0.
    } 
    else { hebbRL = RLpotrate * exp((tlasthebbelig - t) / RLlenhebb) } : Otherwise (if we re using an exponential decay traces)...use the Hebbian decay to calculate the gain.
      
}

FUNCTION antiRL() {
    if ((RLon == 0) || (tlastantielig < 0.0)) { antiRL = 0.0 } : If RL is turned off or eligibility has not occurred yet, return 0.0.
    else if (useRLexp == 0) { : If we are using a binary (i.e. square-wave) eligibility traces...
        if (t - tlastantielig <= RLlenanti) { antiRL = RLdeprate } : If we are within the length of the eligibility trace...
        else {antiRL = 0.0 } : Otherwise (outside the length), return 0.0.
    }
    else { antiRL = RLdeprate * exp((tlastantielig - t) / RLlenanti) } : Otherwise (if we re using an exponential decay traces), use the anti-Hebbian decay to calculate the gain.  
}

FUNCTION softthreshold(rawwc) {
    if (rawwc >= 0) { softthreshold = rawwc * (1.0 - synweight / wmax) } : If the weight change is non-negative, scale by 1 - weight / wmax.
    else { softthreshold = rawwc * synweight / wmax } : Otherwise (the weight change is negative), scale by weight / wmax.    
}

PROCEDURE adjustweight(wc) {
   synweight = synweight + wc : apply the synaptic modification, and then clip the weight if necessary to make sure its between 0 and wmax.
   if (synweight > wmax) { synweight = wmax }
   if (synweight < 0) { synweight = 0 }
}

*** Time differences
**** 1 core with fix
  Done; run time = 129.9 s; real-time ratio: 0.08.

Gathering spikes...
  Done; gather time = 27.0 s.
Minimum delay (time-step for queue exchange) is  10.0

Analyzing...
  Spikes: 189371 (1.89 Hz)
  Connections: 1113133 (525384 STDP; 111.31 per cell)
  Mean connection distance: 783.84 um
  Mean connection delay: 17.84 ms
Saving output as output1.0...
  Done; time = 28.2 s

Done; total time = 267.4 s.
**** 10 cores with fix 
  Done; run time = 33.7 s; real-time ratio: 0.30.

Gathering spikes...
  Done; gather time = 17.1 s.
Minimum delay (time-step for queue exchange) is  1.0

Analyzing...
  Spikes: 189371 (1.89 Hz)
  Connections: 1113133 (525384 STDP; 111.31 per cell)
  Mean connection distance: 783.84 um
  Mean connection delay: 17.84 ms
Saving output as output10.0...
  Done; time = 54.2 s

Done; total time = 118.2 s.
**** 1 core without fix (bug)
  Done; run time = 105.4 s; real-time ratio: 0.09.

Gathering spikes...
  Done; gather time = 71.0 s.
Minimum delay (time-step for queue exchange) is  10.0

Analyzing...
  Spikes: 131236 (1.31 Hz)
  Connections: 1113133 (525384 STDP; 111.31 per cell)
  Mean connection distance: 783.84 um
  Mean connection delay: 17.84 ms
Saving output as output1.0...
  Done; time = 55.1 s

Done; total time = 271.1 s.
**** 10 cores without fix (bug)
  Done; run time = 34.0 s; real-time ratio: 0.29.

Gathering spikes...
  Done; gather time = 23.2 s.
Minimum delay (time-step for queue exchange) is  1.0

Analyzing...
  Spikes: 123575 (1.24 Hz)
  Connections: 1113133 (525384 STDP; 111.31 per cell)
  Mean connection distance: 783.84 um
  Mean connection delay: 17.84 ms
Saving output as output10.0...
  Done; time = 56.8 s

Done; total time = 129.3 s.
* 15feb10 Sim working with STDP, RL + musculoskeletal arm in hpc (ma)
** end of output from running in 'ma'
Writing to MSM pipe: packetID=199.000000
[0.5, -0.5, 0.5, -0.5]
read from msm pipe: 184
[0.128276, 0.0939427, 0.118085, 0.0700224, 0.201749, 0.185767, 0.244255, 0.0703298, 0.154234, 0.141332, 0.135775, 0.107342, 0.145956, 0.10446, 0.101539, 0.126831, 0.154701, 0.0776188]
read from msm pipe: 19
[-0.175841, 1.41304]
Received packet 199.000000 from MSM: (0.128,0.094,0.118,0.070,0.202,0.186,0.244,0.070,0.154,0.141,0.136)
Received packet 199.000000 from MSM: (-0.176,1.413)
  t = 2.0 s (100%; time remaining: 0.0 s)

Writing to MSM pipe: packetID=200.000000
[0.5, -0.5, 0.5, -0.5]
read from msm pipe: 184
[0.128332, 0.0939427, 0.118054, 0.0700076, 0.201694, 0.185664, 0.244182, 0.0702832, 0.154242, 0.141379, 0.135819, 0.10737, 0.145849, 0.104454, 0.101537, 0.126407, 0.154472, 0.0776281]
read from msm pipe: 19
[-0.176098, 1.41247]
Received packet 200.000000 from MSM: (0.128,0.094,0.118,0.070,0.202,0.186,0.244,0.070,0.154,0.141,0.136)
Received packet 200.000000 from MSM: (-0.176,1.412)
  Done; run time = 78.8 s; real-time ratio: 0.03.

Gathering spikes...
  Done; gather time = 5.1 s.

Analyzing...
  Run time: 78.8 s (2-s sim; 2 scale; 1838 cells; 1 workers)
  Spikes: 25857 (7.03 Hz)
  Connections: 45993 (45693 STDP; 25.02 per cell)
  Mean connection distance: 794.83 um
  Mean connection delay: 9.95 ms
Saving output as data/m1ms...
  Done; time = 5.4 s
Plotting raster...
  Done; time = 1.8 s
Plotting connectivity matrix...
Plotting weight changes...

Done; total time = 398.9 s.
** output with mpi
 Done; run time = 9.1 s; real-time ratio: 0.22.

Gathering spikes...
  Done; gather time = 2.1 s.

Analyzing...
  Run time: 9.1 s (2-s sim; 2 scale; 1838 cells; 4 workers)
  Spikes: 25870 (7.04 Hz)
  Connections: 45993 (45693 STDP; 25.02 per cell)
  Mean connection distance: 794.83 um
  Mean connection delay: 9.95 ms
Saving output as data/m1ms...
  Done; time = 5.5 s
  Plotting raster despite using too many cores (4)

* TODO port msarm to M1 model and prepare final demo
** DONE add the input Proprioceptive population, which is actually really a set of netstims with location (NSLOCs), and connect them to layer 2 
** DONE reorganize definition of population/cell parameters
*** DONE set z location based on new yfrac property (0 to 1) for each population
*** DONE population and receptor names within cellpopdata module imported as p (ER2 -> p.ER2)
** DONE Add RL: weight changes at synapses, eligibility traces, stdp-like rule, keep track of target location and arm position (receive via udp every 10ms) to calculate error periodically,
*** DONE Make plexon input be optional 
*** DONE replace arminterface with arminterface_pipe.py - set an option so can use dummy virtual arm for testing!
*** DONE implement msarm.hoc (arm apparatus such as target location, arm position, error etc) in new python-based M1 model
*** DONE fix mpi bug - different motor commands for different nhosts (check if spikes diff as well!!!)
*** DONE RL and eligibility traces using George's PYNDL code
*** DONE plot weightchanges 
** TODO add interface to musculoskel arm (currently dummyArm) - 15 Feb 
*** DONE Assign SPI (spinal cord) subpopulations to different muscles (or maybe just random, which would make more realistic), convert from firing rates to muscle excitation (currently, just sum+threshold), and send udp packet with muscle excitations to arm every 10ms.
***  DONE Assign muscle lengths to the proprioceptive neurons and make them fire accordingly; requires updating muscle lengths every 10ms (via received udp messages)

*** TODO replace pc.post() with pc.py_alltoall() ?
*** DONE make DSC an izhi population and add connectivity to E5B
*** TODO check if can have plasticity between NSLOC and izhi
** TODO Add the training and testing wrappers and modularize further -  17 Feb
*** TODO Modularize parameters and pass as arguments using Bill's method
** TODO decide where plasticity will happen restrict learning to that subset of pops - 19 Feb
-should modify the connectivity and weights tuned to M1!?  
-maybe avoid by adding plastic connections ONLY between
proprioception to L2/3? and SPI to spinal cord interneurons; use spinal cord to project to muscles - see 15jan11
** TODO Encode target using PMd activity as input - 25 Feb 
*** Find good PMd data where target can be decoded
*** Convert into vector of spikes (bill) that can be easily played back (trial/trial basis)
*** Optionally use SSM, and have plasticity between SSM neurons (can argue equivalent to PMd activity !) 
- PMd poisson from neural field model/SSM?)  
- use SSM from Marius, and convert to Poisson(?) a la cliff - Train with SSM
noise for each of the targets 
** TODO Use evol alg to find optimum set of params (first with dummyArm, the musculoskel arm) - 5 Mar
** TODO Test real-time with 10k cells, PMd input and virtual arm using BMI in HPC - 10 Mar
** TODO Prepare final demo video - 20 Mar
*** TODO Fix visualization of virtual arm in hpc!!
*** TODO Make something like this:
[[file+sys:/u/salvadord/Documents/ISB/Models_linux/m1ms/gif/20150211_013249.png][fig]]
- NOTE: PMd input can be replaced with low-dim SSM representation (of PMd) and apply similar plasticity concept â€“ maybe
  can compare both methods -- if direct plasticity between bio+model neurons 
** TODO If have time (doubt it!) simulate perturbation and repair - 30 Mar
https://bbs.archlinux.org/viewtopic.php?pid=684936#p684936
