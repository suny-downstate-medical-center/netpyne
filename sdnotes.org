* 15may27 Modularized framework for NEURON/Python network simulations with MPI
** Overview
Using this modularized structure can select different cell types, populations, connectivities, etc. just by modifying the
parameters in params.py. 

An example is provided in params.py which switches from a single Hodgkin-Huxley population, randomly connected model
(mpiHHTut); to a multiple Izhikevich populations, yfrac-dependent connected M1 model.

To test this just modify the variable simType in params.py: 
simType = 'M1model' # 'mpiHHTut' 

*** Bill's description of what this repo should be
we should try to make this our main organizational code that can spin off multiple projects? -- would like a clean code center-org so that not so painful as it has been with our prior code base (which btw was all my fault and not sam's -- he inherited from me)
then any pushes back to this main center would have to be agreed by curator (you) and would generally involve just some small fix to a single file

** README with description of the different files
List of files:

- main.py: Main executable; calls functions from other modules.

- params.py: Contains all static parameters. It is imported as "p" from all other modules, so that params can be referenced from any file using p.paramName

- shared.py: Contains all the model shared variables and modules (except params.py). It is imported as "s" from all other file, so that any variable or module can be referenced from any file using s.varName

- sim.py: Simulation control functions (eg. runSim)

- network.py: Network related functions (eg. createCells)

- cell.py: contains cell and population classes 

- conn.py: contains class 'Conn' used to instantiate connections, and contains methods to connect cells (eg. random, yfrac-based)

- analysis.py: functions to plot and analyse data

- stimuli.py: functions and parameters for differnt types of neural stimulation

- izhi2007.mod: NMODL definition of Izhikevich 2007 neuron model

- evol.py: Functions to run evolutionary algorithms (using inspyred) to optimize model parameters

** Known issues, potential improvements, and alternative implementations (outdated - see TODO list at end of file)
*** TODO - Saving only happens at the end (instead of at fixed intervals)
*** TODO - Need to add a DEBUG mode or similar (like mpiHHTut had)
- currently have a verbose flag, that prints some additional info
- also have print messages along the code, which could be made optional
*** TODO - Check structure of data saved to file
- some nested lists with inhomogeneous dimensionality were converted to 'object' data types in order to be saved -- check if
  structure makes sense when reading from python/matlab
*** DONE - Some attributes/variables of the class 'Cell' and 'Pop' are not used but still initialized to [ ]
- maybe can find alternative using different constructors for different cell types
- fixed by using dictionary of tags - flexible for eahc type
*** DONE - Labels (eg. AMPA, IT, HH,...) are defined by assigning numeric values to variables
- can use dictionaries instead
- need to check pros and cons of each -- are dicts slower or have any limitations compared to lists/arrays ?
- changed to using dictionaries
*** TODO - stimuli.py not tested with this model
- left there cause thought could be useful for future
*** TODO - analysis.py still has many functions which havent been adapted to new structure
*** TODO - Some variables inherited from cliff still have too long names, eg. backgroundSpikevec
*** TODO - Lines too long, need to split using \
*** DONE - if increase p.backgroundNoise > 0.0 get memory error 
- had to store rnadom noise generator separately for each cell
*** DONE - Find a way to save lambda funcs (can't be pickled)
can use:
>>>import inspect 
>>>inspect.getsource(myfunc)
*** DONE - Clearing vector in simdata now gives error because also has python variables
for v in s.simdata.itervalues() -- fix error
separated vectors
*** TODO - 'Cell' class record method uses eval() which is unsafe
*** DONE - currently setup to record traces from all cells
*** DONE - bug when saving cell traces using multiple cores 
Gathering spikes...
>>> >>> >>> Traceback (most recent call last):
  File "main.py", line 46, in <module>
    runSeq()
  File "main.py", line 37, in runSeq
    s.sim.gatherData()
  File "sim.py", line 117, in gatherData
    for d in gather: tmp.extend(d[k]) 
KeyError: 'cellTraces_233'

- now saved using different structure 
- had to remove hoc objects that are not pickable


*** TODO - Load/save net+sim parameters from file
- load net and sim parameters file from mat?
- have different .py file to generate the params files

within params.py - have option to load from file, or set params and save to 2 files net and sim.mat
- maybe functions in sim.py? can be called from params?
*** DONE - Store net and sim params in dictionaries inside params.py
eg. p.net['ncells']
- facilitates saving to file (prev point)
- can use if key in dict:

- use regexp in submlime text to replace in all files:
Find What: p\.(\w+)
Replace With: p\.sim['$1']

*** TODO - Use dict of tags/attributes for pop params and for cells
eg. p.net['popParams'][i]['cellModel']
- can use if key in dict:
*** Define conn rules based on pair of tag/value for pre and post
eg. use tuple key: connProbs['name','IT','name','IT']  = (lambda x,y: 0.1*x+0.01/y) 
or dict of dict with tuple keys: connProbs['name','IT']['name','IT']  = (lambda x,y: 0.1*x+0.01/y) 
*** DONE - Add $Id$ hg info
- can do with https://mercurial.selenic.com/wiki/KeywordExtension
- but not recommended 
- bill wanted to do because cliff and I add last update and author info to files -- which is never updated correctly
- checked other github repos and they don't have it - just eg. Contributors
*** DONE - Rename main.py with init.py
*** DONE Remove popType and connType variables - infer from dict keys
*** DONE Remove popid from popParams - can use list index
*** TODO Replace topClass and subClass with projection-type, type (neurotransmitter involved?)
**** email to Ben
Hey Ben, Im working on some of the changes we discussed. I've replaced variables with dictionaries of tags/attributes. For now, I've kep the 'population' concept, although can replace in future version if makes sense. 

For both the 'population' and 'cell' objects you suggested replacing the 'topClass' and 'subClass' tags with 'projectionType' and 'cellType' if my notes are correct. I know projType for Exc cells will be 'IT', 'PT' or 'CT', but not sure what would be the best classification for Inh cells? Same thing for cellType, I think you mentioned neurotransmitters involved, but could you elaborate on what would be the list of possible values for both 'Exc' and 'Inh' cells/pops ?  

We can use the google chat or this google doc to bounce ideas back and forth (link points to new section ready to be filled in).

*** TODO Synapse
- synapses as list of objects inside each cell (postsynaptic) - netcon in pre is stub; netcon in post is real synapse
- netcon (neuron object) as part of synapse object

* 15dec28 Convert into python package
- PyNet ? NeuPyNE, NeuPyNet, netpyne !! PYthon-based NETwork development framework for the NEuron simulator
- make shared -> framework 
- from pynet import framework as f
- just need init.py and param.py file
- to add cells or conn functions use:
-- class newCellClass(PointNeuron): ... ;  f.newCellClass = newCellClass 
-- class newConnFunc(): ... ; f.newConnFunc = newConnFunc
- default simConfig
- from pynet import init ; init.createAndRun(netParams, simConfig)

* 16jan26 Possibly making more simulator-indep using NeuroML-based format
** NeuroML format 
- could represent all nml format using python dicts (instantiated net)
- additional abstract layer (connParams, netParams etc) - using more general format and then converted to nml
- eg. https://github.com/OpenSourceBrain/Thalamocortical/tree/master/neuroConstruct/generatedNeuroML2
- https://www.neuroml.org/getneuroml
- https://www.neuroml.org/tool_support
- https://github.com/NeuralEnsemble/libNeuroML
- https://github.com/NeuroML/pyNeuroML
- http://bioportal.bioontology.org/ontologies/CNO
- http://www.neuroconstruct.org/
- http://neuronvisio.org/


*** Issues
- Would like to keep simple declarative (python dicts based) specifications
- Want to make netpyne more NEURON-independent, both at specifications, and py instantiated network
- netpyne makes use of mod files, but neuroml requires detailed specification
- netpyne provides conversion from abstract specifications -> instantiated network, and support for multicompartment, and
  subcellular connectivity
- netpyne provides instantiation of NEURON objects, and parallel simulation of network
- netpyne can use NeuroML structure but using dictionaries instead of xml text - so easy to manipulate
- libneuroml and pynn - procedural, not so intuitive, and require internal definition of cell types etc (eg. IAF); whereas
  netpyne is 'declarative', more intuitive?, can define arbitrary cell props based on mechs and syns
- dictionary of equivalences NEURON<->NeuroML (eg. tau1, rise)

*** cells
NOTE: segment = sections/segment; segmentGroup = sectionList/section
- can have segmentGroups that consist of segmentGroups
- Neuron sections->segmentGroups
- Neuron 3d points -> segmnets
- Neuron nseg -> property tag numberInternalDivisions
- if have pointProcess in segment -> mapping of position along section and where pointprocess is placed

    <include href="nap.channel.nml"/>

    <include href="pas.channel.nml"/>

<cell id="SupAxAx">

        <notes>Cell: supaxax_0 exported from NEURON ModelView</notes>

        <morphology id="morphology_SupAxAx">

            <segment id="0" name="Seg0_comp_1">
                <proximal x="0.0" y="0.0" z="0.0" diameter="15.0"/>
                <distal x="0.0" y="10.0" z="0.0" diameter="15.0"/>
            </segment>

            <segment id="1" name="Seg1_comp_1">
                <parent segment="0"/>
                <distal x="-4.371139E-7" y="20.0" z="0.0" diameter="15.0"/>
            </segment>

 <segmentGroup id="prox_dend_soma">
                <include segmentGroup="comp_1"/>
                <include segmentGroup="comp_41"/>
                <include segmentGroup="comp_28"/>
                <include segmentGroup="comp_15"/>
                <include segmentGroup="comp_2"/>
            </segmentGroup>


	<biophysicalProperties id="biophys">

            <membraneProperties>
                
                <channelDensity condDensity="0.0 mS_per_cm2" id="ar_ModelViewParmSubset_1" ionChannel="ar__m00_25" segmentGroup="ModelViewParmSubset_1" erev="-40.0 mV" ion="ar"/>
                
                <channelDensity condDensity="0.1 mS_per_cm2" id="cal_ModelViewParmSubset_4" ionChannel="cal" segmentGroup="ModelViewParmSubset_4" ion="ca" erev="125.0 mV"/>
                
                <channelDensity condDensity="0.2 mS_per_cm2" id="cal_ModelViewParmSubset_5" ionChannel="cal" segmentGroup="ModelViewParmSubset_5" ion="ca" erev="125.0 mV"/>
                
                <channelDensity condDensity="0.0 mS_per_cm2" id="cat_ModelViewParmSubset_1" ionChannel="cat" segmentGroup="ModelViewParmSubset_1" ion="cat" erev="125.0 mV"/>
                
                <channelDensity condDensity="0.0 mS_per_cm2" id="k2_all" ionChannel="k2" ion="k" erev="-100.0 mV"/>
                
                <spikeThresh value="0.0 mV"/>

                <specificCapacitance value="1.0 uF_per_cm2"/>

                <initMembPotential value="-65.0 mV"/>


*** connections
<projection id="LTS_AxAx_sm" presynapticPopulation="CG_C04_LTS_sm" postsynapticPopulation="CG_C04_AxAx_sm" synapse="Inh_LTS_FS">
            <connection id="0" preCellId="../CG_C04_LTS_sm/5/SupLTSInter" postCellId="../CG_C04_AxAx_sm/0/SupAxAx" preSegmentId="112" preFractionAlong="0.26785243" postSegmentId="82" postFractionAlong="0.36041966"/>
            <connection id="1" preCellId="../CG_C04_LTS_sm/3/SupLTSInter" postCellId="../CG_C04_AxAx_sm/0/SupAxAx" preSegmentId="116" preFractionAlong="0.6782849" postSegmentId="91" postFractionAlong="0.99472666"/>
            <connection id="2" preCellId="../CG_C04_LTS_sm/6/SupLTSInter" postCellId="../CG_C04_AxAx_sm/0/SupAxAx" preSegmentId="112" preFractionAlong="0.42696908" postSegmentId="84" postFractionAlong="0.46009916"/>
            <connection id="3" preCellId="../CG_C04_LTS_sm/0/SupLTSInter" postCellId="../CG_C04_AxAx_sm/0/SupAxAx" preSegmentId="113" preFractionAlong="0.92599744" postSegmentId="83" postFractionAlong="0.60695267"/>
            <connection id="4" preCellId="../CG_C04_LTS_sm/9/SupLTSInter" postCellId="../CG_C04_AxAx_sm/0/SupAxAx" preSegmentId="113" preFractionAlong="0.5823235" postSegmentId="39" postFractionAlong="0.646692"/>
            <connection id="5" preCellId="../CG_C04_LTS_sm/6/SupLTSInter" postCellId="../CG_C04_AxAx_sm/0/SupAxAx" preSegmentId="113" preFractionAlong="0.16917303" postSegmentId="57" postFractionAlong="0.6089958"/>

*** synapses
<?xml version="1.0" encoding="ISO-8859-1"?>
<neuroml xmlns="http://www.neuroml.org/schema/neuroml2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.neuroml.org/schema/neuroml2 https://raw.github.com/NeuroML/NeuroML2/development/Schemas/NeuroML2/NeuroML_v2beta4.xsd" id="Syn_AMPA_L4SS_IN">

    <notes>ChannelML file describing a single synaptic mechanism</notes>

    <alphaSynapse id="Syn_AMPA_L4SS_IN" tau="0.8ms" gbase="2.94303552937e-07mS" erev="0.0mV">

        <notes>Synapse with syn scaling constant c = 1 nS (translating to max cond of 2.94304e-07 mS), time course: 0.8 ms and reversal potential: 0 mV.
        Automatically generated by command:  genSyn.py Syn_AMPA_L4SS_IN 0.8 1 0 </notes>
</alphaSynapse>

</neuroml>
*** population

        <population id="CG_C04_FRB_sm" component="L23PyrFRB_varInit" type="populationList" size="6">
           <annotation>
                <property tag="color" value="0.0 0.0 0.0"/>
            </annotation>
            <instance id="0">
                <location x="-739.27563" y="-798.43396" z="-440.9723"/>
            </instance>
            <instance id="1">
                <location x="975.8342" y="-870.85077" z="1090.1094"/>
            </instance>
            <instance id="2">
                <location x="-1012.162" y="-785.71173" z="1053.8684"/>
            </instance>
            <instance id="3">
                <location x="-1391.423" y="-776.4188" z="-32.483643"/>
            </instance>
            <instance id="4">
                <location x="149.5564" y="-790.7691" z="433.74915"/>
            </instance>
            <instance id="5">
                <location x="585.53955" y="-765.37933" z="819.1377"/>
            </instance>
        </population>


*** pulse generator (netstim?)
   <pulseGenerator id="DepCurr_L23FRB" delay="0.0s" duration="20.0s" amplitude="3.0E-10A"/>
    
    <pulseGenerator id="DepCurr_L23FRB__0" delay="0.0s" duration="20.0s" amplitude="3.37936E-10A"/>
** chat with Bill
summary of 3-hr meeting with Ben: 1) he really likes netpyne, 2) discussed how to add subcellular syn info (3 main methods: sectionlists, yfrac-based, path distance-based), 3) provided his unpublished code to convert sCRACM data to synapse density maps and said we can use in netpyne, 4) suggested making netpyne more NEURON/simulator-independent (similar to Kim Blackwell)

on this last point (simu-indep), I looked at NeuroML2 format, and some of the tools Padraig has built 2 interface it with Python and Neuron (eg. neuroconstruct, pyNeuroML, libNeuroML), and read Robert's reproducibility paper

I think it might be possible to make netpyne simulator-independent at the specs and instantiated network, using a NeuroML-like internal format (but using python dicts instead of xml so can manipulate data) -- and then keep final stage where its converted to Neuron simulatable objects

sent padraig an email to discuss the technical details of what they've already implemented and how netpyne could fit, and be useful to fill in missing tools in this whole story

an alternative is to keep it as a tool specific for Neuron, with its internal Neuron-based format for specs and network, and the possibility of exporting/importing from NeuroML and others (ie. its current status)

** chat with Padraig
- good to separate M1 model from netpyne
- similarities with pnn and libneuroml
- important of neuroml is conceptual structure
- libneuroml has cell types
- mapping from pyneuroml to mod files, but not the other way around

- standardization of abstract conn rules is above pynn and nueroml/pyneuroml
- eg 10 conn algorithms -> pynn -> neuroml
- morphology - segments, segment groups

- mod files would need to be translated into nueroml (not fully translated); alternative would be point to nueroml
  definition, convert via pyneuroml to Neuron mod
- setup.py to netpyne
- dot.travis.yml continuous integration server - run tests every time there is a commit to repository - make sure its consistent
  with latest version

- convert from Neuron model to NeuroML:
-- export specifications 
-- OSB converting to NeuroML2 cell morphology (pyneuroml.convert_to_neuroml2) - in future if already in neuroml dont need to
 define in Nueron/netpyne format 
-- Izhikevich (params) - abstract definiton
-- export to Nueroml2 positions and connectivity - no current tool to convert
-- https://github.com/OpenSourceBrain/Cerebellum3DDemo
-- http://www.opensourcebrain.org/docs#Converting_To_NeuroML2


- convert from NeuromML to Neuron:
-- java script to convert neuroml to mod and Neuron/py files - wait for better iteration
-- adapt java code to convert directly to netpyne
-- https://github.com/NeuroML/org.neuroml.export/blob/development/src/main/java/org/neuroml/export/neuron/NeuronWriter.java
-- https://github.com/NeuroML/org.neuroml.export/blob/development/src/main/java/org/neuroml/export/pynn/PyNNWriter.java
-- check param files hhtut izhitut updated so can padraig can modify
-- add load cell function in netpyne in neuroml format


- differences:
1) declarative
2) netpyne makes use of mod files, but neuroml requires detailed specification
3) netpyne provides conversion from abstract specifications -> instantiated network, and support for multicompartment, and
  subcellular connectivity
4) netpyne provides instantiation of NEURON objects, and parallel simulation of network

- options:
-- long-term: use Neuroml internally for instantiated network 
-- short-term:  Neuron-based and conversion to NeuroML; 

* 16jan27 Consolidate connectivity functions
** Full conn -> fullConn
- =probConn with prob = 1?
** combine convConn, divConn, and randConn?
- probFunc = optional param -- if not present, then:
- select function depending of param included? eg. 'convergence', 'divergence', 'probability'
** Random conn with N conns per postsyn cell (convergence) -> convConn
~= conv conn
- conv param allowed as function eg. uniform, gauss
- also allows for weight+delay as func
** Random conn with N conns per presyn cell (divergence) -> divConn
** Random conn with fixed, function (including distance-dep) prob, weight, delay -> probConn
*** fixed
number eg. 5
*** func
- uniform
*** func dist-dep
- function of yfrac
- function of 3d distance
- generalizable to func of 
-- (pre, post, dist) + '_' + (xfrac, yfrac, zfrac, x, y, z) = 18 variables
-- (dist) + '_' + (xznorm, xyznorm, xz, xyz) = 4 variables
-- total: 22 variables
- create dictionary with each variable associated to its value/variable/function -- don't evaluate to save
- enter as string, and convert to function
- other variables allowed: any that are defined in f.net.params[var] -- arbitrary
** implementation
- use **kwargs
- string based - converted to function, extract variables
- arguments weight and delay valid for all conn types; and can be functional

Options to implement func:
*** lambda with kwargs - NO
prob = lambda(**d): d['pre_ynorm']*0.5
*** lambda with args - NO!
prob = lambda(*d): d[3]*0.5
*** string
prob = 'pre_ynorm*0.5'
prob = 'post_xyznorm*0.5
prob = 'uniform()'
prob = 'normal(10,5)'
prob = 'uniform(1,5)'
- functions allow all of python random functions 
- internal implementation:
-- identifiy variables (pre, post or dist x,y,z,2d or 3d; plus any arbitrary defined in netParams)
-- define dict mapping variable name to lambda function returning actual variable using preCell and postCell as args
-- convert string to lambda function with variables as arguments
-- call lambda function with args as dict with each entry mapped to lambda func that returns the variable
*** efficiency
- calculate all delay, prob, weight funcs together at the beginning
- calcualte weights+delays for all possible conns despite some will not be used?
- alternative might be more comput costly (calling 1 by 1), and repeated code
- use map(lambda, list)
- calculate final list of weights,probs,delays and pass to specific conn func

*** errors
- arguments by reference using lambda func only works for 'delay' if 'convergence' func loops over preCellsTags and postCells
  -- even though they have nothing to do with each other!! whats going on? python bug? Im missing something?!

** comparison to PyNN
*** class AllToAllConnector(allow_self_connections=True, safe=True, callback=None)[source]
=fullConn
*** class OneToOneConnector(safe=True, callback=None)[source]
=conn rule specifying cell ids
*** class FixedProbabilityConnector(p_connect, allow_self_connections=True, rng=None, safe=True, callback=None)[source]
=probConn
*** class FromListConnector(conn_list, column_names=None, safe=True, callback=None)[source]
=conn rule specifying cell ids
*** class FromFileConnector(file, distributed=False, safe=True, callback=None)[source]
=conn rule specifying cell ids
*** class ArrayConnector(array, safe=True, callback=None)[source]
=conn rule specifying cell ids
*** class FixedNumberPreConnector(n, allow_self_connections=True, with_replacement=False, rng=None, safe=True, callback=None)
=divConn
*** class DistanceDependentProbabilityConnector(d_expression, allow_self_connections=True, rng=None, safe=True, callback=None)[source]
= probConn with dist-dep func

*** class IndexBasedProbabilityConnector(index_expression, allow_self_connections=True, rng=None, safe=True, callback=None)[sour
= conn rule specifying cell ids
*** class SmallWorldConnector(degree, rewiring, allow_self_connections=True, n_connections=None, rng=None, safe=True, callback=N
not implemented
*** class CSAConnector(cset, safe=True, callback=None)[source]
not implemented
** comparison to NEST
*** ConvergentConnect
Connect many source nodes to one target node.
=convConn
*** DivergentConnect
Connect one source node to many target nodes.
= divConn
*** RandomConvergentConnect
Randomly connect one source node to many target nodes.
= convConn with uniform func
*** RandomDivergentConnect
Randomly connect one source node to many target nodes.
= divConn with uniform func
*** BinomialConvergentConnect
Connect a target to a binomial number of sources.
??

* 16feb18 Changing folder structure and adding setup.py
** file structure
- root
-- examples/: param and run files
-- netpyne/: actual package
-- doc/: documentation
-- setup.py: required for pip install
-- other root files
** OK how to add $PYTHONPATH in setup.py?
** OK Make sure all examples and tuts work
- examples - ok
- tutorial examples - ok
- claus - ok
- M1Network -ok
** OK Update documentation
** OK Update README

* 16feb25 Adding STDP and RL
** old stdp code
if s.usestdp and ([s.cellpops[pregid],s.cellpops[pstgid]] in s.plastConns): # If using STDP and these pops are set to be plastic connections
            if sum(abs(s.stdprates[s.EorI[pregid],:]))>0 or sum(abs(s.RLrates[s.EorI[pregid],:]))>0: # Don't create an STDP connection if the learning rates are zero
                for r in range(s.nreceptors): # Need a different STDP instances for each receptor
                    if newcon.weight[r]>0: # Only make them for nonzero connections
                        stdpmech = h.STDP(0,sec=s.dummies[pstid]) # Create STDP adjuster
                        stdpmech.hebbwt = s.stdprates[s.EorI[pregid],0] # Potentiation rate
                        stdpmech.antiwt = s.stdprates[s.EorI[pregid],1] # Depression rate
                        stdpmech.wmax = s.maxweight # Maximum synaptic weight
                        precon = s.pc.gid_connect(pregid,stdpmech); precon.weight[0] = 1 # Send presynaptic spikes to the STDP adjuster
                        pstcon = s.pc.gid_connect(pstgid,stdpmech); pstcon.weight[0] = -1 # Send postsynaptic spikes to the STDP adjuster
                        h.setpointer(s.connlist[-1]._ref_weight[r],'synweight',stdpmech) # Associate the STDP adjuster with this weight
                        s.stdpmechs.append(stdpmech) # Save STDP adjuster
                        s.precons.append(precon) # Save presynaptic spike source
                        s.pstcons.append(pstcon) # Save postsynaptic spike source
                        s.stdpconndata.append([pregid,pstgid,r]) # Store presynaptic cell ID, postsynaptic, and receptor
                        if s.useRL: # using RL
                            stdpmech.RLon = 1 # make sure RL is on
                            stdpmech.RLhebbwt = s.RLrates[s.EorI[pregid],0] # Potentiation rate
                            stdpmech.RLantiwt = s.RLrates[s.EorI[pregid],1] # Depression rate
                            stdpmech.tauhebb = stdpmech.tauanti = s.stdpwin # stdp time constant(ms)
                            stdpmech.RLwindhebb = stdpmech.RLwindhebb = s.eligwin # RL eligibility trace window length (ms)
                            stdpmech.useRLexp = s.useRLexp # RL 
                            stdpmech.softthresh = s.useRLsoft # RL soft-thresholding
                        else:
                            stdpmech.RLon = 0 # make sure RL is off
** how to update at intervals
*** why needed?
- periodic saves (eg. of weights)
- update virtual arm apparatus
- run RL on syns based on critic signal
- calculate LFP

*** option 1: run sim for short periods of time (not efficient?)
while round(h.t) < s.duration:
        s.pc.psolve(min(s.duration,h.t+s.loopstep)
*** option 2: finitialize handler?
** netpyne format
- within conn rule

- One set of STDP params for each conn rule:
STDPparams = {'hebbwt': , 'antiwt':, 'wmax':, 'RLon': , 'RLhebbwt', 'RLantiwt', 'tauhebb', 'RLwindhebb', 'useRLexp', 'softthresh'

  stdpmech.RLon = 1 # make sure RL is on
                            stdpmech.RLhebbwt = s.RLrates[s.EorI[pregid],0] # Potentiation rate
                            stdpmech.RLantiwt = s.RLrates[s.EorI[pregid],1] # Depression rate
                            stdpmech.tauhebb = stdpmech.tauanti = s.stdpwin # stdp time constant(ms)
                            stdpmech.RLwindhebb = stdpmech.RLwindhebb = s.eligwin # RL eligibility trace window length (ms)
                            stdpmech.useRLexp = s.useRLexp # RL 
                            stdpmech.softthresh = s.useRLsoft # RL soft-thresholding
'plasticity': {'mech': 'STDP', 'params': STDPparams}

- Single set of STDP params for all:
'plasticity':  'STDP'

** revisiting STDP mod implementation
*** stdp.m1ms
COMMENT

STDP + RL weight adjuster mechanism

Original STDP code adapted from:
http://senselab.med.yale.edu/modeldb/showmodel.asp?model=64261&file=\bfstdp\stdwa_songabbott.mod

Adapted to implement a "nearest-neighbor spike-interaction" model (see 
Scholarpedia article on STDP) that just looks at the last-seen pre- and 
post-synaptic spikes, and implementing a reinforcement learning algorithm based
on (Chadderdon et al., 2012):
http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0047251

Example Python usage:

from neuron import h

## Create cells
dummy = h.Section() # Create a dummy section to put the point processes in
ncells = 2
cells = []
for c in range(ncells): cells.append(h.IntFire4(0,sec=dummy)) # Create the cells

## Create synapses
threshold = 10 # Set voltage threshold
delay = 1 # Set connection delay
singlesyn = h.NetCon(cells[0],cells[1], threshold, delay, 0.5) # Create a connection between the cells
stdpmech = h.STDP(0,sec=dummy) # Create the STDP mechanism
presyn = h.NetCon(cells[0],stdpmech, threshold, delay, 1) # Feed presynaptic spikes to the STDP mechanism -- must have weight >0
pstsyn = h.NetCon(cells[1],stdpmech, threshold, delay, -1) # Feed postsynaptic spikes to the STDP mechanism -- must have weight <0
h.setpointer(singlesyn._ref_weight[0],'synweight',stdpmech) # Point the STDP mechanism to the connection weight

Version: 2013oct24 by cliffk

ENDCOMMENT

NEURON {
    POINT_PROCESS STDP : Definition of mechanism
    POINTER synweight : Pointer to the weight (in a NetCon object) to be adjusted.
    RANGE tauhebb, tauanti : LTP/LTD decay time constants (in ms) for the Hebbian (pre-before-post-synaptic spikes), and anti-Hebbian (post-before-pre-synaptic) cases. 
    RANGE hebbwt, antiwt : Maximal adjustment (can be positive or negative) for Hebbian and anti-Hebbian cases (i.e., as inter-spike interval approaches zero).  This should be set positive for LTP and negative for LTD.
    RANGE RLwindhebb, RLwindanti : Maximum interval between pre- and post-synaptic events for an starting an eligibility trace.  There are separate ones for the Hebbian and anti-Hebbian events.
    RANGE useRLexp : Use exponentially decaying eligibility traces?  If 0, then the eligibility traces are binary, turning on at the beginning and completely off after time has passed corresponding to RLlen.
    RANGE RLlenhebb, RLlenanti : Length of the eligibility Hebbian and anti-Hebbian eligibility traces, or the decay time constants if the traces are decaying exponentials.
    RANGE RLhebbwt, RLantiwt : Maximum gains to be applied to the reward or punishing signal by Hebbian and anti-Hebbian eligibility traces.  
    RANGE wmax : The maximum weight for the synapse.
    RANGE softthresh : Flag turning on "soft thresholding" for the maximal adjustment parameters.
    RANGE STDPon : Flag for turning STDP adjustment on / off.
    RANGE RLon : Flag for turning RL adjustment on / off.
    RANGE verbose : Flag for turning off prints of weight update events for debugging.
    RANGE tlastpre, tlastpost : Remembered times for last pre- and post-synaptic spikes.
    RANGE tlasthebbelig, tlastantielig : Remembered times for Hebbian anti-Hebbian eligibility traces.
    RANGE interval : Interval between current time t and previous spike.
    RANGE deltaw : The calculated weight change.
    RANGE newweight : New calculated weight.
}

ASSIGNED {
    synweight        
    tlastpre   (ms)    
    tlastpost  (ms)   
    tlasthebbelig   (ms)    
    tlastantielig  (ms)        
    interval    (ms)    
    deltaw
    newweight          
}

INITIAL {
    tlastpre = -1            : no spike yet
    tlastpost = -1           : no spike yet
    tlasthebbelig = -1      : no eligibility yet
    tlastantielig = -1  : no eligibility yet   
    interval = 0
    deltaw = 0
    newweight = 0
}

PARAMETER {
    tauhebb  = 10  (ms)   
    tauanti  = 10  (ms)    
    hebbwt = 1.0
    antiwt = -1.0
    RLwindhebb = 10 (ms)
    RLwindanti = 10 (ms)
    useRLexp = 0   : default to using binary eligibility traces
    RLlenhebb = 100 (ms)
    RLlenanti = 100 (ms)
    RLhebbwt = 1.0
    RLantiwt = -1.0
    wmax  = 15.0
    softthresh = 0
    STDPon = 1
    RLon = 1
    verbose = 1
}

NET_RECEIVE (w) {
     deltaw = 0.0 : Default the weight change to 0.

    : Hebbian weight update happens 1ms later to check for simultaneous spikes (otherwise bug when using mpi)
    : if (verbose > 0)  { printf("flag %f\n",flag) }

    if ((flag == -1) && (tlastpre != t-1)) {   
        w = 0 : should be set to 0 for anti-hebb to work, but then there is weird error
        deltaw = hebbwt * exp(-interval / tauhebb) : Use the Hebbian decay to set the Hebbian weight adjustment. 
        if (softthresh == 1) { deltaw = softthreshold(deltaw) } : If we have soft-thresholding on, apply it.
        if (verbose > 0) { printf("Hebbian STDP event: t = %f ms; tlastpre = %f; w = %f; deltaw = %f\n",t,tlastpre,w,deltaw) } : Show weight update information if debugging on.
        }

    : Ant-hebbian weight update happens 1ms later to check for simultaneous spikes (otherwise bug when using mpi)
    else if ((flag == 1) && (tlastpost != t-1)) { :update weight 1ms later to check for simultaneous spikes (otherwise bug when using mpi)
        w = 0 : should be set to 0 for anti-hebb to work, but then there is weird error
        deltaw = antiwt * exp(interval / tauanti) : Use the anti-Hebbian decay to set the anti-Hebbian weight adjustment.
        if (softthresh == 1) { deltaw = softthreshold(deltaw) } : If we have soft-thresholding on, apply it.
        if (verbose > 0) { printf("anti-Hebbian STDP event: t = %f ms; deltaw = %f\n",t,deltaw) } : Show weight update information if debugging on. 
        }

    : If we receive a non-negative weight value, we are receiving a pre-synaptic spike (and thus need to check for an anti-Hebbian event, since the post-synaptic weight must be earlier).
    if (w >= 0) {           
        interval = tlastpost - t  : Get the interval; interval is negative
        if  ((tlastpost > -1) && (interval > 1.0)) { : If we had a post-synaptic spike and a non-zero interval...
            if (STDPon == 1) { : If STDP learning is turned on...
                if (verbose > 0) {printf("net_send(1,1)\n")}
                net_send(1,1) : instead of updating weight directly, use net_send to check if simultaneous spike occurred (otherwise bug when using mpi)
            }
            if ((RLon == 1) && (-interval <= RLwindanti)) { tlastantielig = t } : If RL and anti-Hebbian eligibility traces are turned on, and the interval falls within the maximum window for eligibility, remember the eligibilty trace start at the current time.
        }
        tlastpre = t : Remember the current spike time for next NET_RECEIVE.  
    
    : Else, if we receive a negative weight value, we are receiving a post-synaptic spike (and thus need to check for a Hebbian event, since the pre-synaptic weight must be earlier).    
    } else {            
        interval = t - tlastpre : Get the interval; interval is positive
        if  ((tlastpre > -1) && (interval > 1.0)) { : If we had a pre-synaptic spike and a non-zero interval...
            if (STDPon == 1) { : If STDP learning is turned on...
                if (verbose > 0) {printf("net_send(1,-1)\n")}
                net_send(1,-1) : instead of updating weight directly, use net_send to check if simultaneous spike occurred (otherwise bug when using mpi)
            }
            if ((RLon == 1) && (interval <= RLwindhebb)) { 
                tlasthebbelig = t} : If RL and Hebbian eligibility traces are turned on, and the interval falls within the maximum window for eligibility, remember the eligibilty trace start at the current time.
        }
        tlastpost = t : Remember the current spike time for next NET_RECEIVE.
    }
    adjustweight(deltaw) : Adjust the weight.
}

PROCEDURE reward_punish(reinf) {
    if (RLon == 1) { : If RL is turned on...
        deltaw = 0.0 : Start the weight change as being 0.
        deltaw = deltaw + reinf * hebbRL() : If we have the Hebbian eligibility traces on, add their effect in.   
        deltaw = deltaw + reinf * antiRL() : If we have the anti-Hebbian eligibility traces on, add their effect in.
        if (softthresh == 1) { deltaw = softthreshold(deltaw) }  : If we have soft-thresholding on, apply it.  
        adjustweight(deltaw) : Adjust the weight.
        if (verbose > 0) { printf("RL event: t = %f ms; reinf = %f; RLhebbwt = %f; RLlenhebb = %f; tlasthebbelig = %f; deltaw = %f\n",t,reinf,RLhebbwt,RLlenhebb,tlasthebbelig, deltaw) } : Show weight update information if debugging on.     
    }
}

FUNCTION hebbRL() {
    if ((RLon == 0) || (tlasthebbelig < 0.0)) { hebbRL = 0.0  } : If RL is turned off or eligibility has not occurred yet, return 0.0.
    else if (useRLexp == 0) { : If we are using a binary (i.e. square-wave) eligibility traces...
        if (t - tlasthebbelig <= RLlenhebb) { hebbRL = RLhebbwt } : If we are within the length of the eligibility trace...
        else { hebbRL = 0.0 } : Otherwise (outside the length), return 0.0.
    } 
    else { hebbRL = RLhebbwt * exp((tlasthebbelig - t) / RLlenhebb) } : Otherwise (if we're using an exponential decay traces)...use the Hebbian decay to calculate the gain.
      
}

FUNCTION antiRL() {
    if ((RLon == 0) || (tlastantielig < 0.0)) { antiRL = 0.0 } : If RL is turned off or eligibility has not occurred yet, return 0.0.
    else if (useRLexp == 0) { : If we are using a binary (i.e. square-wave) eligibility traces...
        if (t - tlastantielig <= RLlenanti) { antiRL = RLantiwt } : If we are within the length of the eligibility trace...
        else {antiRL = 0.0 } : Otherwise (outside the length), return 0.0.
    }
    else { antiRL = RLantiwt * exp((tlastantielig - t) / RLlenanti) } : Otherwise (if we're using an exponential decay traces), use the anti-Hebbian decay to calculate the gain.  
}

FUNCTION softthreshold(rawwc) {
    if (rawwc >= 0) { softthreshold = rawwc * (1.0 - synweight / wmax) } : If the weight change is non-negative, scale by 1 - weight / wmax.
    else { softthreshold = rawwc * synweight / wmax } : Otherwise (the weight change is negative), scale by weight / wmax.    
}

PROCEDURE adjustweight(wc) {
   synweight = synweight + wc : apply the synaptic modification, and then clip the weight if necessary to make sure it's between 0 and wmax.
   if (synweight > wmax) { synweight = wmax }
   if (synweight < 0) { synweight = 0 }
}

*** stdp.cliff
COMMENT

STDP + RL weight adjuster mechanism

Original STDP code adapted from:
http://senselab.med.yale.edu/modeldb/showmodel.asp?model=64261&file=\bfstdp\stdwa_songabbott.mod

Adapted to implement a "nearest-neighbor spike-interaction" model (see 
Scholarpedia article on STDP) that just looks at the last-seen pre- and 
post-synaptic spikes, and implementing a reinforcement learning algorithm based
on (Chadderdon et al., 2012):
http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0047251

Example Python usage:

from neuron import h

## Create cells
dummy = h.Section() # Create a dummy section to put the point processes in
ncells = 2
cells = []
for c in range(ncells): cells.append(h.IntFire4(0,sec=dummy)) # Create the cells

## Create synapses
threshold = 10 # Set voltage threshold
delay = 1 # Set connection delay
singlesyn = h.NetCon(cells[0],cells[1], threshold, delay, 0.5) # Create a connection between the cells
stdpmech = h.STDP(0,sec=dummy) # Create the STDP mechanism
presyn = h.NetCon(cells[0],stdpmech, threshold, delay, 1) # Feed presynaptic spikes to the STDP mechanism -- must have weight >0
pstsyn = h.NetCon(cells[1],stdpmech, threshold, delay, -1) # Feed postsynaptic spikes to the STDP mechanism -- must have weight <0
h.setpointer(singlesyn._ref_weight[0],'synweight',stdpmech) # Point the STDP mechanism to the connection weight

Version: 2013oct24 by cliffk

ENDCOMMENT

NEURON {
    POINT_PROCESS STDP : Definition of mechanism
    POINTER synweight : Pointer to the weight (in a NetCon object) to be adjusted.
    RANGE tauhebb, tauanti : LTP/LTD decay time constants (in ms) for the Hebbian (pre-before-post-synaptic spikes), and anti-Hebbian (post-before-pre-synaptic) cases. 
    RANGE hebbwt, antiwt : Maximal adjustment (can be positive or negative) for Hebbian and anti-Hebbian cases (i.e., as inter-spike interval approaches zero).  This should be set positive for LTP and negative for LTD.
    RANGE RLwindhebb, RLwindanti : Maximum interval between pre- and post-synaptic events for an starting an eligibility trace.  There are separate ones for the Hebbian and anti-Hebbian events.
    RANGE useRLexp : Use exponentially decaying eligibility traces?  If 0, then the eligibility traces are binary, turning on at the beginning and completely off after time has passed corresponding to RLlen.
    RANGE RLlenhebb, RLlenanti : Length of the eligibility Hebbian and anti-Hebbian eligibility traces, or the decay time constants if the traces are decaying exponentials.
    RANGE RLhebbwt, RLantiwt : Maximum gains to be applied to the reward or punishing signal by Hebbian and anti-Hebbian eligibility traces.  
    RANGE wmax : The maximum weight for the synapse.
    RANGE softthresh : Flag turning on "soft thresholding" for the maximal adjustment parameters.
    RANGE STDPon : Flag for turning STDP adjustment on / off.
    RANGE RLon : Flag for turning RL adjustment on / off.
    RANGE verbose : Flag for turning off prints of weight update events for debugging.
    RANGE tlastpre, tlastpost : Remembered times for last pre- and post-synaptic spikes.
    RANGE tlasthebbelig, tlastantielig : Remembered times for Hebbian anti-Hebbian eligibility traces.
    RANGE interval : Interval between current time t and previous spike.
    RANGE deltaw : The calculated weight change.
    RANGE newweight : New calculated weight.
}

ASSIGNED {
    synweight        
    tlastpre   (ms)    
    tlastpost  (ms)   
    tlasthebbelig   (ms)    
    tlastantielig  (ms)        
    interval    (ms)    
    deltaw
    newweight          
}

INITIAL {
    tlastpre = -1            : no spike yet
    tlastpost = -1           : no spike yet
    tlasthebbelig = -1      : no eligibility yet
    tlastantielig = -1  : no eligibility yet   
    interval = 0
    deltaw = 0
    newweight = 0
}

PARAMETER {
    tauhebb  = 10  (ms)   
    tauanti  = 10  (ms)    
    hebbwt = 1.0
    antiwt = -1.0
    RLwindhebb = 10 (ms)
    RLwindanti = 10 (ms)
    useRLexp = 0   : default to using binary eligibility traces
    RLlenhebb = 100 (ms)
    RLlenanti = 100 (ms)
    RLhebbwt = 1.0
    RLantiwt = -1.0
    wmax  = 15.0
    softthresh = 0
    STDPon = 1
    RLon = 1
    verbose = 0
}

NET_RECEIVE (w) {
     deltaw = 0.0 : Default the weight change to 0.

    : Hebbian weight update happens 1ms later to check for simultaneous spikes (otherwise bug when using mpi)
    if ((flag == -1) && (tlastpre != t-1)) {   
        w = -2
        deltaw = hebbwt * exp(-interval / tauhebb) : Use the Hebbian decay to set the Hebbian weight adjustment. 
        if (softthresh == 1) { deltaw = softthreshold(deltaw) } : If we have soft-thresholding on, apply it.
        if (verbose > 0) { printf("Hebbian STDP event: t = %f ms; deltaw = %f\n",t,deltaw) } : Show weight update information if debugging on.
        }

    : Ant-hebbian weight update happens 1ms later to check for simultaneous spikes (otherwise bug when using mpi)
    else if ((flag == 1) && (tlastpost != t-1)) { :update weight 1ms later to check for simultaneous spikes (otherwise bug when using mpi)
        w = -2
        deltaw = antiwt * exp(interval / tauanti) : Use the anti-Hebbian decay to set the anti-Hebbian weight adjustment.
        if (softthresh == 1) { deltaw = softthreshold(deltaw) } : If we have soft-thresholding on, apply it.
        if (verbose > 0) { printf("anti-Hebbian STDP event: t = %f ms; deltaw = %f\n",t,deltaw) } : Show weight update information if debugging on. 
        }

    : If we receive a non-negative weight value, we are receiving a pre-synaptic spike (and thus need to check for an anti-Hebbian event, since the post-synaptic weight must be earlier).
    if (w >= 0) {           
        interval = tlastpost - t  : Get the interval; interval is negative
        if  ((tlastpost > -1) && (interval > 1.0)) { : If we had a post-synaptic spike and a non-zero interval...
            if (STDPon == 1) { : If STDP learning is turned on...
                net_send(1,1) : instead of updating weight directly, use net_send to check if simultaneous spike occurred (otherwise bug when using mpi)
            }
            if ((RLon == 1) && (-interval <= RLwindanti)) { tlastantielig = t } : If RL and anti-Hebbian eligibility traces are turned on, and the interval falls within the maximum window for eligibility, remember the eligibilty trace start at the current time.
        }
        tlastpre = t : Remember the current spike time for next NET_RECEIVE.  
    
    : Else, if we receive a negative weight value, we are receiving a post-synaptic spike (and thus need to check for an anti-Hebbian event, since the post-synaptic weight must be earlier).    
    } else {            
        interval = t - tlastpre : Get the interval; interval is positive
        if  ((tlastpre > -1) && (interval > 1.0)) { : If we had a pre-synaptic spike and a non-zero interval...
            if (STDPon == 1) { : If STDP learning is turned on...
                net_send(1,-1) : instead of updating weight directly, use net_send to check if simultaneous spike occurred (otherwise bug when using mpi)
            }
            if ((RLon == 1) && (interval <= RLwindhebb)) { tlasthebbelig = t } : If RL and Hebbian eligibility traces are turned on, and the interval falls within the maximum window for eligibility, remember the eligibilty trace start at the current time.
        }
        tlastpost = t : Remember the current spike time for next NET_RECEIVE.
    }
    adjustweight(deltaw) : Adjust the weight.
    if (verbose>=1) { printf("netreceive(): t=%f ms; w=%f;  flag=%f; tlastpre=%f; tlastpost=%f, interval=%f; RLwindhebb=%f; tlasthebbelig=%f; RLwindanti=%f; tlastantielig=%f;\n", 
                                            t,       w,     flag,    tlastpre,    tlastpost,     interval,   RLwindhebb,    tlasthebbelig,    RLwindanti,    tlastantielig) } : Show all information 
}

PROCEDURE reward_punish(reinf) {
    if (RLon == 1) { : If RL is turned on...
        deltaw = 0.0 : Start the weight change as being 0.
        deltaw = deltaw + reinf * hebbRL() : If we have the Hebbian eligibility traces on, add their effect in.   
        deltaw = deltaw + reinf * antiRL() : If we have the anti-Hebbian eligibility traces on, add their effect in.
        if (softthresh == 1) { deltaw = softthreshold(deltaw) }  : If we have soft-thresholding on, apply it.  
        adjustweight(deltaw) : Adjust the weight.
        if (verbose>=2) { printf("reward_punish(): t=%f ms; delta=%f; w=%f\n", t, deltaw, synweight) } : Show weight update information if debugging on.
        if (verbose>=3) { printf("reward_punish(): t=%f ms; delta=%f; w=%f; reinf=%f; hebbRL=%f; antiRL=%f; softthresh=%i\n", t, deltaw, synweight, reinf, hebbRL(), antiRL(), softthresh) } : Show all information
    }
}

FUNCTION hebbRL() {
    if ((RLon == 0) || (tlasthebbelig < 0.0)) {  : If RL is turned off or eligibility has not occurred yet, return 0.0.
        hebbRL = 0.0  
        if (verbose > 2) { printf("hebbRL(): off; t=%f ms; hebbRL=%f; RLon=%f; tlasthebbelig=%f\n", t, hebbRL, RLon, tlasthebbelig) } : Show all information
        } 
    else if (useRLexp == 0) { : If we are using a binary (i.e. square-wave) eligibility traces...
        if (t - tlasthebbelig <= RLlenhebb) { hebbRL = RLhebbwt } : If we are within the length of the eligibility trace...
        else { hebbRL = 0.0 } : Otherwise (outside the length), return 0.0.
        if (verbose > 2) { printf("hebbRL(): square; t=%f ms; hebbRL=%f; tlasthebbelig=%f; RLlenhebb=%f\n", t, hebbRL, tlasthebbelig, RLlenhebb) } : Show all information
    } 
    else { hebbRL = RLhebbwt * exp((tlasthebbelig - t) / RLlenhebb) } : Otherwise (if we're using an exponential decay traces)...use the Hebbian decay to calculate the gain.
    if (verbose > 2) { printf("hebbRL(): exp; t=%f ms; hebbRL=%f; RLhebbwt=%f; tlasthebbelig=%f; RLlenhebb=%f\n", t, hebbRL, RLhebbwt, tlasthebbelig, RLlenhebb) } : Show all information  
}

FUNCTION antiRL() {
    if ((RLon == 0) || (tlastantielig < 0.0)) {  : If RL is turned off or eligibility has not occurred yet, return 0.0.
        antiRL = 0.0 
        if (verbose>=3) { printf("antiRL(): off; t=%f ms; antiRL=%f; RLon=%f; tlastantielig=%f\n", t, antiRL, RLon, tlastantielig) } : Show all information
    }
    else if (useRLexp == 0) { : If we are using a binary (i.e. square-wave) eligibility traces...
        if (t - tlastantielig <= RLlenanti) { antiRL = RLantiwt } : If we are within the length of the eligibility trace...
        else {antiRL = 0.0 } : Otherwise (outside the length), return 0.0.
        if (verbose>=3) { printf("antiRL(): square; t=%f ms; antiRL=%f; tlastantielig=%f; RLlenanti=%f\n", t, antiRL, tlastantielig, RLlenanti) } : Show all information
    }
    else { antiRL = RLantiwt * exp((tlastantielig - t) / RLlenanti) } : Otherwise (if we're using an exponential decay traces), use the anti-Hebbian decay to calculate the gain.
    if (verbose>=3) { printf("antiRL(): exp; t=%f ms; antiRL=%f; RLantiwt=%f; tlastantielig=%f; RLlenanti=%f\n", t, antiRL, RLantiwt, tlastantielig, RLlenanti) } : Show all information
}

FUNCTION softthreshold(rawwc) {
    if (rawwc >= 0) { softthreshold = rawwc * (1.0 - synweight / wmax) } : If the weight change is non-negative, scale by 1 - weight / wmax.
    else { softthreshold = rawwc * synweight / wmax } : Otherwise (the weight change is negative), scale by weight / wmax.
}

PROCEDURE adjustweight(wc) {
   synweight = synweight + wc : apply the synaptic modification, and then clip the weight if necessary to make sure it's between 0 and wmax.
   if (synweight > wmax) { synweight = wmax }
   if (synweight < 0) { synweight = 0 }
   if (verbose>=3) { printf("adjustweight(): t=%f ms; synweight=%f; wc=%f; wmax=%f\n", t, synweight, wc, wmax) } : Show all information
}

*** netpynesimplestdp.mod
- if use stdp.m1ms:
-- only hebb events at the beginning
-- RL not working cause tlasthebbelig doesn't update 

- if use stdp.cliff:
-- both stdp and RL happen - but correctly??
-- only hebb - so maybe anti-hebb not working
-- if critic = -1 

- problem might be netpyne?

*** m1ms model
- if use stdp.cliff:
-- seems like too many hebb events?
-- RL works (with critic =1 or -1) - but might be wrong due to hebb events?

- if use stdp.m1ms:
-- Hebbian works (no anti-Hebbian?)
-- RL works (with critic =1 or -1)


*** found bug and fixed (skip instead of w)
- use separate 'skip' variable to skip the 2nd set of conditions; instead of using the 'w' var, since otherwise 'w' gets
  fixed to that value for following events

*** need to fix so -1 critic RL also works - fixed
- was due to soft threshold being on -- reduces -1 effect if close to min weight; and reduces +1 effect if close to max
  weight

*** check antihebb learning
- fixed bug: if  ((tlastpost > -1) && (-interval > 1.0))  (interval had to be -1)

* 16mar04 Adding subcellular synaptic conn distribution
** sectionList
- need during runtim? for connectivity purposes?
- option 1: can include section attribute named 'sectionList' and add name, but could take longer to set properties if have to search all
- option 2: can include as dict in sectionLists in cellProp, and then add all sections inside of each sectionList dict; but would
  change the consistency of the generic implementation (cell.py etc)
- option 3: can add additional dict sectionLitst in cellProp, simply including list of sections (need to return additional
  dic from util.py function)
- best options seem 1 or 3
- Need to create sectionList at runtime? useful?

-- iterating over sectionList
from neuron import h
​
s = h.Section(name='s')
a = h.Section(name='a')
d = h.Section(name='d')
​
sl1 = h.SectionList()
sl1.append(sec=s)
​
sl2 = h.SectionList()
sl2.append(sec=a)
sl2.append(sec=d)
​
section_lists = h.List('SectionList')
print 'There are %d SectionLists' % section_lists.count()
​
for i in xrange(int(section_lists.count())):
    print 'SectionList %d has the following sections: %r' % (i + 1, [str(sec.hname()) for sec in section_lists.o(i)])

--- Note that this iterates over all SectionList objects, not just those associated with a particular cell.
--- Alternatively, itertools.chain.from_iterable
--- https://docs.python.org/2/library/itertools.html#itertools.chain.from_iterable

*** NeuroML implements as option 3:
 <segmentGroup id="prox_dend_soma">
                <include segmentGroup="comp_1"/>
                <include segmentGroup="comp_41"/>
                <include segmentGroup="comp_28"/>
                <include segmentGroup="comp_15"/>
                <include segmentGroup="comp_2"/>
            </segmentGroup>

*** Netpyne implementation
- Option 3
cellRule = {'label': 'PYRrule', 'conditions': {'cellType': 'PYR'},  'secs': {}, 'secLists': {}} 
...
cellRule['secLists']['all'] = ['soma', 'dend']

- Can't define properties of section lists in netpyne
- Neuron section list object not created - just python version
- Can import cell with sectionlists
- Can use sectionlists in connectivity

- Modified importCell so it reads sectionLists with original variable names; and modified input arguments so now pass
  cellRule as 1st arg -- so can add 'secs' and 'secLists' to cellRule dict

TODO:
- update tut_import.py - DONE
- update documentation - DONE
- update claus - DONE
- update M1Network - DONE

** Discussion with Ben
- define subcellular location of synapses:
1) named sectionlists of sublists - apicatuft, obliques
2) radial distribution, fraction yfrac, normalized, cortical depth, where dendrites fall in layers (cx centered, not cell
 centered)
3) path distance from soma 
-- plus combination of above
-- 1st, 2nd order branches differences cannot be specified directly, but can create sectionlists 
eg. 1st 50um apical trunk no spines - subsets that are spiny vs non-spiny

2 METHODS:
A) 2-step implementation: 1) unitary conns, 2) contacts (subcellular conn)
B) axo-dendritic density overlap - you don't know unitary without calculating subcellular
-- HBP approach - axonal density is function of proj from L2->L5 + dendritic density, even if cells not realistic, calculate
weight+prob

if we imagine a hierarch struc where a 'unitaryConn' object contains a list of 'contacts' (~= Neuron Netcons) and 'synapses' (Neuron Synapses)
this unitaryConn would have a specific pre and post-cell id
but it may be the case, that the synapse is used as the target of many presyn cells
(at least in Neuron terms and how we usually build models now)
which means the 'synapse' would have to be outside of the 'unitaryConn' and just be referenced by name or whatever
I'll just point out that this doesn't make all that much sense to me (despite being the way you do it)

- 2 levels of instantiation - abstract (no specific models, not simulatable, cellular); and specific (subcellular)
- from 1st - every neuron has to be assigned and implementation; and every connection has to be implemented
- thats what happens right now but abstract instantiation is not saved
- 2nd step consists of instantiating subcellular info - cell morphology + subcellular conn (could be separate)
- 1st pass) cellular instatiation step (includes cell+conns); 2nd pass) subcellular step; 3rd pass) choose simulator pick
  Neuron object for each cell
- In 3rd level decide where to place h.Netcons and h.Synapses 

- conns = unitary conns - presyn, type (AMPA), weight (somatic response for 1 AP presyn cell ~0.2 mV EPSP), delay?
- in connParams have subcellular conn info - but not added to cell objects, only once create simulatable individual cells,
  wire it up 

- just 3 levels : specifications -> cellular -> simulator instantiation
- Neurons instantiation separate from python structure - linked by cell id
- for each unitary connection, check cell model of presyn and postsyn and decide if use NetCons, Synapses etc 

** Current implementation
- Cell (object)
-- conns (list of dicts)
--- hNetcon
--- preGid
--- weight
--- threshold
--- sec
--- syn

-- secs (dict of dicts)
--- geom
--- topol
--- mechs
--- pointps
--- syns (dict)
---- hSyn
---- _loc
---- _type
---- tau
---- e

** Pros/Cons of making conns indep of cells 
- pros:
-- easier to search for conns, do analysis etc
-- conceptually make more sense (Ben, Bill)
-- consistent with NueroML

- cons:
-- synapses separate from cell too? associate via gid? prev models and Neuron standard is syns inside cell, conns outside; harder to check syns 
-- make sure conns for each cell in same node -- seems easy since will happen naturally
-- easier to find conns of a given cell


** Possible structure (with contacts inside each unitary conn):
- net (object of class Network)
-- cells (list of objects of class Cell)
-- conns (list of dicts)
--- preGid
--- postGid
--- contacts (list of dicts)
---- hNetcon
---- weight
---- threshold
---- sec
---- syn

- Advantage is that would have equivalent top level connections indepdently of subcellular info (morphology).
- Advantage: Need to know all unitary connections before can actually implement the subcellular details - distribution
  depends on total number of input conns

- Disadvantage is that have more complex hierarchical structure, more difficult to search, if have simple single contacts
  then overcomplicated, and doesnt match neuroml 

** Alternative structure (with single list of contacts):
- net (object of class Network)
-- cells (list of objects of class Cell)
-- conns (list of dicts)
--- preGid
--- postGid
--- hNetcon
--- weight
--- threshold
--- sec
--- syn

for unitary conns - find unique preGid/postGid (eg. print list(set(zip(*myList)[1])))

** Alternative structure (with contacts inside, but as a class)
- net (object of class Network)
-- cells (list of objects of class Cell)
-- conns (list of object of class Connection)
--- preGid
--- postGid
--- contacts (list of dicts)
---- hNetcon
---- weight
---- threshold
---- sec
---- syn

Advantage - can have subcelullar methods inside

** Structure with proper nomenclature for cellConns, synConns, synMechs 
- net (object of class Network)
-- cells (list of objects of class Cell)
-- cellConns (list of object of class CellConnection)
--- preGid
--- postGid
--- synConns (list of dicts)
---- hNetcon
---- weight
---- threshold
---- sec
---- synMech

** Choice of cellConns, synConns, synMechs 

- 'cellConns' = unitary connection between 2 cells (can contain many synapses) = non-existent (Neuron) = non-existent (NeuroML)
= 'connection' (HBP)

- 'synConns': individual synaptic contacts made between single pre and post cell (each connection can contain many) =
  'h.NetCon' (Neuron) = 'connections' (NeuroML) = 'synapse' (HBP)

- 'synMechs': postsynaptic mechanism (receptor-like), usually one per connection = eg. 'h.ExpSyn' or 'h.AMPA' (Neuron) =
  eg. 'alphaSynapse' (NeuroML) = 'synaptic mechanism' (HBP)

** neuroml conn structure
- projections: between populations; pre, post and synapse
- connection: pregid, postgid, presegment, postsegment, prefraction, postfraction
- synapse: mechanism associated to cell; tau, gbase, erev

<projection id="LTS_AxAx_sm" presynapticPopulation="CG_C04_LTS_sm" postsynapticPopulation="CG_C04_AxAx_sm" synapse="Inh_LTS_FS">

<connection id="0" preCellId="../CG_C04_LTS_sm/5/SupLTSInter" postCellId="../CG_C04_AxAx_sm/0/SupAxAx"
            preSegmentId="112" preFractionAlong="0.26785243" postSegmentId="82" postFractionAlong="0.36041966"/>

<neuroml xmlns="http://www.neuroml.org/schema/neuroml2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.neuroml.org/schema/neuroml2 https://raw.github.com/NeuroML/NeuroML2/development/Schemas/NeuroML2/NeuroML_v2beta4.xsd" id="Syn_AMPA_L4SS_IN">

    <notes>ChannelML file describing a single synaptic mechanism</notes>

    <alphaSynapse id="Syn_AMPA_L4SS_IN" tau="0.8ms" gbase="2.94303552937e-07mS" erev="0.0mV">

        <notes>Synapse with syn scaling constant c = 1 nS (translating to max cond of 2.94304e-07 mS), time course: 0.8 ms and reversal potential: 0 mV.
        Automatically generated by command:  genSyn.py Syn_AMPA_L4SS_IN 0.8 1 0 </notes>
</alphaSynapse>

** Ben's sCRACM code
*** insertSyn
- vecstim
- netcon
- expsyn

*** uniformSynapseLocations
- total length
- list of secs
- sec lens

- find total length, divide by num syns, find absolute locs, find local secs and locs for each syn (use list with cum lengths
  and corresponding section)

*** pointFromLoc
- section, loc
- return anatomical point x,y,z

*** loadratio
- load file wiht synaptic dist ratios - rel syn strength for 10x30 grid 

*** setup_grid
create grid with 10 cols, 30 rows

*** calculateGridSigma
 vector of local synaptic strength at each grid point, e.g. ratio peak_experimental / peak_uniform

*** distanceFromGrid
// arg 1: x
// arg 2: y
// arg 3: Vector to hold the distances

*** interpolateSegmentSigma
- arg 1: SectionList to receive synapses, e.g. spiny
- arg 2: Vector to be filled with the calculated sigma
- Note: the dendrites must be fully enclosed by the grid (i.e. there must be 4 nearest grid points surrounding every segment)

- for each section loc:
-- find x,y pos
-- find 4 closest grid points and their sigmas (syn strengths)
-- bilinear interpolation of sigma

*** mappedSynapseLocations
- arg 1: SectionList for which to calculate sigma
- arg 2: Vector of sigmas for each segment
- arg 3: SectionList to be filled
- arg 4: Vector of x-vals to be filled

- Load ratio (vals between 0-15) of syn strength  in 10x30 grid 
- Obtain norm sigma values based on ratio
- Calculate sigma via interpolation for every segment location
- Calculate synapses to insert in each segment

*** radialSynapseLocations
- arg 1: SectionList that can accept synapses (e.g. spiny)
- arg 2: sigma_uniform (e.g. 1.5/8)
- arg 3: y_min
- arg 4: y_max
- arg 5: SectionList to carry synapses, 1 for each synapse (e.g. synsecs)
- arg 6: Vector of x-values, 1 for each synapse (e.g. synxs)

- uniform distibution of synapse based on radial distance from soma
- specify y range
- calculate num synapses based on section length / nseg
- store section and loc of each syn

*** distributeSynapse
- arg 1: SectionList that can accept synapses (e.g. spiny)
- arg 2: sigma_uniform (e.g. 1.5/8)
- arg 3: mode: 0 = uniform, 1 = non-uniform aka mapped, 2 = non-uniform based on laminar depth
- arg 4: SectionList to carry synapses, 1 for each synapse (e.g. synsecs)
- arg 5: Vector of x-values, 1 for each synapse (e.g. synxs)
- arg 6: optional, for mode 2: y_min
- arg 7: optional, for mode 2: y_max

- wrapper: selects 1 of 3 modes and passes in arguments


** netpyne implementation
- check number of presyn cells connecting to post (cellCons)
- check syn distribution pattern and morphology of post
- need to calculate num of synConns based on weight?? or fixed weight for synConn (divide cellConn weight by num of synConns?)
- create synConns and synMechs 

- Is it worth having CellConn as class with SynConn attribute and methods? 
-- only 5 syns/cell
-- need to know all cellconns before start synconns, but method cannot be inside cellconn cause need to check all cellconns
-- have to call method createSubCellConn if params includes subCell - do once for each conn rule (from network.py)
-- subcellular syn dist shouldn't be replicated on each CellConn, just once on conn rule

- createConns
-- for each rule:
--- probConn/convConn
---- cellConns.append(CellConn) (but no subcellular)
-- for all cellConns:
---  cellConns.addSubcellular 

- but needs subcell params from rule!! so either 
-- need to be stored in each cellConn / pointer to f.net.params -- shouldn't occupy extra space since pointer (can remove
after so not saved?)

- do we need subcellular info for each conn rule?! or just for each cell type and synMech?! Ben mentioned 'after logic conns,
  create subcellular based on presyn+postsyn cell type"

- weight + delay a property of CellConn or SynConn ?! both?

- how to create extra synMechs needed? identical properties to cellprop syn mechs?

- maybe there's no need for cellconns vs synconns? 
-- if subcellular info: create temporal cellconns, then synconns (from synconns can generate cellconns after)
-- if no subcellular info: create synconns directly

- or create cellconns and synconns as independent lists (redundant)

- maybe create separate rules for subcellular distribution; needed because:
-- conn data as func of yfrac (eg. [0.1 - 0.2])
-- syn dist for presyn layer/type (eg. L2/3)
-- wouldn't make sense to repeat for each yfrac-based conn rule (or cell type rule), plus need all 

- maybe add subcellular distribution to cell prop rules:
-- for each cell prop, create conditions of subcellular distribution eg. ['conditions': {'yfrac': [0.1-0.4]}]
-- default: assume uniform distribution

- where to put properties of synapses?
-- can add to sections in properties 
-- can just add generic, by setting '_loc': 'generic' ? -- but still inside a section! :/
-- just make algorithm look for synmechs in all sections, and use same params to replicate
-- maybe move 'synMechs' out, to same level as 'secs' ? 
-- add to sectionList !?

** sCRACM (Petreanu 2009; Suter,2015)
- inject ChR2 in certain presyn axons (eg. L2/3)
- short pohotostimulation 1ms 2mW in specific grid (12x24, 50um) location
- depolarizes axons; use TTX (blocked Na+ and K+ ->no AP)
- axon terminal Ca2+ channels open -> glutamate release
- measure EPSC in soma

- provides a two-dimensional ‘image’ of the distribution of specific input within the dendritic arbors of the recorded cell

- EPSCsCRACM amplitudes depend on the density of ChR2-positive axons, the fraction of axons that make synapses with the
  recorded neuron, the strength of the synapses, and their electrotonic distance from the soma

- sCRACM maps were normalized to the largest pixels within a map and thus represent the relative strength of input within the dendritic tree.

- Average sCRACM map of layer 2/3 inputs to M1-CSPs (n = 23 neurons). L, Input profiles by soma depth. M, Location of perisomatic input from layer 2/3 relative to soma position, plotted as a function of soma depth. For each profile, the input depth was calculated as the center of mass across the perisomatic pixels.

[[file+sys:/u/salvadord/Documents/ISB/Models/netpyne_repo/gif/20160313_212734.png][fig]]

** questions for ben
*** always have to specify num contacts or distribution?
-- Yes, or distribution
-- Ben: if full model the could calculate exactly; but since scaled down, we want syns per conn to be correct eg. 5
-- assume in M1 model, realistic density, but reduced volume -- experiments found ~5 for PT->PT not in motor cx
-- likely that there is data 
-- does it vary significantly? Thalamocortical could be very different; assume every proj has 4-6 contacts as measured
-- select a fixed value eg 5. and value strength/weight of each synConn


*** Weight+delay in cellConn or synConn or both?
-- if data from unitary conn EPSP, the cellConn, but need to calculate weight/synConn (h.NetCon)
-- allow weights both at cellConn and synConn level
-- if weight * 2 makes the synapse twice as strong?
-- can know max conductance, and temp response
-- Lefort used EPSP mV in soma for cellConn -- need to know how to calculate synConn -- is there a way to do this
 analytically?
-- he did in scracm code- assume syn density is correct, electrotonic difference made different between measured and simualated -- multiply by factor difference, resimulate and compare again
-- syns close to soma were fine; syns far away, original map had understimated response of far away syns, and rescaled far
 away syns
-- pattern of syn density for cell -- function of yfrac -- only need to calculate for original scracm map, and output should
 be rule
-- but for cellConn -> 5 synConns get 1mV in soma when activated simultaneously -- but will be distributed along dendrites so
 different transmission delays -- difficult to calculate accurately
-- most models dont distribute syns over dendrite with realistic syn density

-- delay could be identical for each synConn, or add small distance-based delay
-- delay would vary due to extra distance traveled through unmyelinated axon (1 m/s) -- 1.1ms diff for different pyramidal
 neurons - can omit for now - euclidean distance between cell bodies - condVelocity = 1m/s
-- minDelay value = 2ms -- too high! set to maybe 0.5 ms or 1ms -- max(0.5, 3d distance based) ; for closeby cells, axon goes
 down ~100um (fat axon), collaterals branch off, come back up 100 or 200um ; localDelay = 0.5ms
-- for long-range conns use longer delays - eg. 4 ms - kind of aritraty seems noise 

- Bill: have to normalize by position based on a transfer function between locations and soma
-- can use someting like ted's multifreq transfer func program to get tha map
-- yes have to scale baesd on loc and based on freq of input -- eg a high freq (short) input like AMPA has less effect on soma than a slow eg NMDA
-- was looking at paper on that recently but is just for passive case
-- jnsci15:1669.pdf The morphoelectrotonic transform: a graphical approach to dendritic function
/u/billl/articles/jnsci15:1669.pdf
-- reshaping tree based on electrical distance
-- another old paper --   author =    "Jaffe, DB and Carnevale, NT",
 title =    "Passive normalization of synaptic integration influenced by dendritic architecture",
/u/billl/articles/jnphys82:3268.pdf
-- http:/www.neuron.yale.edu/phpbb/viewtopic.php?f=8&t=2404&p=9487&hilit=frequency+response#p9487 
-- calculate the space constant in response to a AC current // lamda_AC(f) = 1/2*sqrt(diam/PI*f*Ra*Cm)
-- think he has a little package for this but not finding now
http://www.neuron.yale.edu/phpbb/viewtopic.php?f=15&t=313&p=870&hilit=frequency+response#p870
a 'frequency tool'
-- also depends on the Rm and on active conductances, 
eg an EPSP can end up being terminated by K chans or can be primarily and active response so that the actual gsyn is only a small piece

*** Syn dist specific to postsyn mech? depends on presyn cell props,loc?
-- Specific to eg. AMPA/NMDA, or just exc vs inh?
-- we dont have specific data on differnt receptors -- assume all exc are both AMPA and NMDA, and have a conductance ratio
 between them - has been measured (maybe ratio different in tuft vs basal, but ignore for now); allow to customize ratio
- depends on presyn cell type and layer (eg. L2/3 exc vs L5B IT vs L5B PT)
-- M1 L2/3 -> SPI sCRACM map
-- Petreanu barrel cortex L2/3 or L4 -> yfrac sCRACM map
-- long range inputs sCRACM maps (both Ben and Petreanu)


*** Why need to know num of conns before start? Can have prob dist of synapse, and map on a cell-by-cell basis, adapt
  probabilities based on current num contacts
-- wouldn't be exact since probability based; but need final distribution to match ratios


*** The non-uniform mapped / distance from soma-based would be given in the form of 30x10 map, distribution across segments?
-- exp data is in 30x10 map format; distr across segments would vary depending on cell morphology
-- netpyne should be a 30x10 length density
-- num of syns/um 
-- within given pixel stimulated with blue light, pixel = 50x50 um, num of syns/um/dendrite - homogeneous within 50x50um 
-- convert scracm map -> map of how many syns per length of dendrite at each region of the map (at each pixel)
-- need to know how much dendrite in that pixel, and how many sysn were coactivated to get soma response
-- his method: put fixed number of [of syns in] dendrite, and then adjusted weight of these syns
-- couldnt really separate weights from num of synapses -- started with plausible weight and num of syns 
-- length density for a specific assumption of conductances (used to convert map)
-- input to netpyne should be free from Neuron peculiarities -- relates to somehting experimentally -- num of syn per length
 of dendrite and strength of each of thsoe syns as a peak conductance
- 2 types of map: 1) num syns/um of dendrite, 2) conductance of syns/um dendrite (probably uniform everywhere) 
- remain within bounds that exp plausible - eg. now num of spines in a dend tree (eg max 20k)
- L5->L5 somatic epsp unitary conns 0.2 0.5 mv for 5 syns/conn --> each syn has g that will result in 0.1 mV epsp soma
-- but will depend on location eg apical tuft won't give you value
-- 5 number comes mostly from counting dyns in basal -- but maybe also in apical tuft but weren't undetected (90% came from
 basals)
-- so probably ok to assume most syns are in basal not apical tuft
-- in his model he calculated conduc value for standard synapse that gives 0.1 or 0.2 mV (assume uniform over all arbor), so
 need to vary num of contacts and location

*** Other formats apart from length density map and conductance map (50um and 10x30 map,aligned to pia, centerd on soma):
-- for STR assume they get same input and infer similar density map for STR cells -- convert using dendritic density of STR
cells
-- simpler way: syn length density maps are also radial functions -- if account for how much dendrite there is, the x
dimension of map may not contain any info -- so rule is based on 1d map (radial function) - 30x1 map - function of yfrac (in
50 um bins)
-- could be averaged or represent individual neurons -- for scracm map doesnt make sense to average 
-- sectionLists - scracm has 50um resoulution but actually more like 100um resoulution -- if you look at dends, 1st 50um of
apical trunk have no syns; 1st 20um of root basal dont have any syns (just few) -- at a scale where scracm doesnt reach there
might be no syns
-- so where scracm doesnt reach can use sectionList to complement and tell u there are no syns thre -- eg. spiny sectionList
contains all sections except where they were no spines/syns - so set density to 0 
-- in neuron if u didnt reconstruct eveyr spine, you account for that by increasing cm -- in detailed model I'm using --
compensated by increasing membrane area 
- syn density maps are not common - so need other way to specify for rest -- more common data in literature,
  anatomical/categorical statements eg. this interneuron targets apical tuft -- but no specific numeric values (details not
  known) -- usually always anatomical 
- he can send SPI syn length density map -- SEND EMAIL!



** comments by ben
If you want to see which dendrites are on basal, apical, etc. then better to look at the profiles sorted by soma depth, i.e. where you can see each individual neuron's input collapsed to a radial profile.

[5:17] 
Or a soma-aligned average map.

[5:18] 
The former is in my paper. The latter I have as figs.

[5:19] 
In my paper I also show analysis of where the "perisomatic" input is centered, relative to the soma - generally above the soma with an offset of ~50 um, but depends on projection and on soma depth.

[5:19] 
One consistent finding was that while the basals do get input from all sources, it's a bit weaker below the soma (note that there are basals above the soma too).

[5:21] 
The sCRACM technique probably won't work well for local L5->L5 connections (Taro tried this with Rabies - not mapping, but
LED flash - and said the input was too weak). But for L5-L5 connections we can turn to pair recording studies with full
reconstructions of dendrites and axons - such as published by Markram et al 1997 (methinks), with Sakmann.

There is substantial variability within each projection - seen clearly in the example Salva just pasted. Some CSP get strong L2/3 input, while others don't - even if their soma depth is similar.

[5:29] 
So my thought was to take each actual map and apply the inferred synapse density onto reconstructions at approximately matched soma depths. Do this for each projection.

[5:29] 
For the L2/3 -> CSP data set, I have reconstructions and maps in the same neuron, for a subset of the data set. For the other projections, I don't have reconstructions.

[5:30] 
So the idea would be to take each mapped neuron, use it's soma depth to find the reconstruction with closest matching soma depth, and instantiate that.

[5:31] 
Or alternatively (and probably better), take each reconstructed neuron, and then apply synapses to it according to every projection - where for each projection, you find the map whose soma depth best matches the reconstructed neuron.

[5:32] 
Another approach I started working on is to parameterize each projection's pattern as a function of soma depth, so that there is a formula M_i(somadepth) for each projection i, which lets you determine the synapse distribution for neuron's at any depth.

[5:34] 
However, because the sCRACM maps don't tell you synapse density (but rather, synaptic strength measured at soma under strange pharmacological conditions), before you can calculate a formula for the whole projection, you'd need to simulate each map to infer the synapse density. Unless ... it turns out that there is a nice analytic way to convert the input maps into synapse densities, i.e. without simulating each one. From the few simulations I've done, this might actually be possible.


** Features implemented with adhoc solution -- need to be fixed
*** GENERAL
*** default synMech placed in soma - where to define? make syns separate like neuroml
- don't create synMechs until needed by connections -- just specify params? but need to store somewhere
- can look up in f.net.params using tags['propList'] but probably slow

- in Cell class have pointer to f.net.params from synMechs but dont create new python/neuron object
- place synapse together with connection instead of cell? confusing since many conns can project to single synapse

-  In neuroml, syns are defined independently, and associated with connections - do same thing:

netParams['synMechParams'] = {'NMDA': {'mod': 'ExpSyn', 'tau': 0.1, 'e': 0}}
cell.secs['soma']['synMechs'][0]['label': 'NMDA', 'loc': 0.5, 'hSyn': ]

- place synMechs outside of sec? might be slower to find; plus synMechs are pointps so 'belong' to section

- no need to add in netParams, specified in connRule, and created together with connections
- when create conn check if synMech exists in that section, ie. has same 'label' and 'loc', if not, then create

- make addSyn function

- comparison of searching inside list vs accessing dict (~20x faster, for 1M conns: 0.75 sec vs 0.03sec; for 100M conns: 75
  sec vs 4 sec):
-- but have to add time of searching for specific location too

timeit.timeit("b=next((item for item in a if item['label']=='ampa'), None)", setup="a=[{'label':'gabab','v':10},{'label':'gaba','v':10},{'label':'nmda','v':10},{'label':'ampa','v':10}]", number=1000000)
Out[13]: 0.7533509731292725

timeit.timeit("b=a['ampa']", setup="a={'gabab':{'v':10},'gaba':{'v':10},'nmda':{'v':10},'ampa':{'v':10}}", number=1000000)
Out[18]: 0.038023948669433594

- NEED TO IMPORT SYNAPSES INTO SYNMECHPARAMS

*** independent scale conn weight for each cell model 
- where to store?
- useful feature
- maybe by default should be stored by cell model
- allow both options (same variable)
*** move conns and stims out of Cell class
- make stims be normal populations?
- stims from S2 projection could make 2000 syns into single cell!
- maybe place netstim part of stim outside of cell, but keep netcon inside
- maybe keep conns inside cell for now? seems to make things easier eg. have all synConns of that cell ready to distribute


*** CONN RULE
*** conn rule with list of synMechs
- eg. [AMPA, NMDA]
- weightFraction or weightRatio - eg. 
- synWeightFraction = [0.9, 0.1]
*** synsPerConn as distribution
- allows functional - seems to be gauss around 5 (E->) or 1 (I->)

*** weight/delay of conn and syns
- allow to provide single weight -- find way to estimate weight of syn contacts -- check 16mar24 entry with papers to read!
- allow to provide list of synweights -- one per synConn (eg. 5 values) by convention assign starting from pia
- allow functional only for single value (otherwise code would get overcomplicated)
- maybe allow argument that represents location of synapse (not of cell) ??

*** SUBCELL RULE
*** create 1st conns, then syns 
- 2 steps, so can distribute syns 
- create temporary cellConns or keep?
- need somewhere to store unitary weight? or when convert to subcellular lose?
- 1) create synConns but don't assign locs/delays/weights; 2) for each cell distribute syns, based on sep subcellular rules
-- maybe add subcellular distribution to cell prop rules:
--- for each cell prop, create conditions of subcellular distribution eg. ['conditions': {'yfrac': [0.1-0.4]}]
--- default: assume uniform distribution
--- wouldn't make sense to repeat for each yfrac-based conn rule, plus need all 

- create num synConns in 1st pass, and then replace if needed based on subcelluar rules

- only do 2nd pass if any subcellular rules (can't depend of numSyns cause could be 1, but still need to distribute)
*** distribute syns in sectionList or list of sectionLists
- add suport for list of sectionLists - or even combination?!
*** syn distribution specification
- 2d syn density map
- 1d syn density map (yfrac)
- apply 1d or 2d map only to certain sectionList, eg. spiny
- categorical data - eg. by sectionLists + distribution function (uniform, gauss)


** Meeting with Ben (March 18)
*** Comments from Ben
- conceptual framework makes sense
- HBP approach - axodendritic approach vs. know unitary and subcellular = refinement
- 2 netcons to same synapse - what happens if input at same timestep ? coincident spiking
- 1st pass + 2nd pass - approves
- network model indep of subcellular info
- single synapse could represent a projection between 
- unitary conn from preCell A could project to postCell B and C (so not totally accurate in terms of anatomy)
- Do we need subcellular map for each presyn and postyn cell type, or per conn rule
-- only pero conn rule if you average maps; but could also use indiv cell maps for each cell model
-- upper and deeper SPI cells scracm maps suggests they would have different input-output relations in networks 
-- for a given  density map could end with different syn density (and input-output relation) by applying to diff morphologies 
-- yfrac dep of subcellular conn 
-- also variabilty 
-- CSP morphology very consistent for diff cortical depths; difference is in linker segments (eg 8% vs 12%) so not big diff
-- CSTR differences based on yfrac - within L5A and L5B - dont know if intrinsic diffs in CSTR

- Make 3 CSP models - upper, middle, lower - 100 um apart -- get data from 10 cells for each and fit -- then test if can
  replace each of them and still get consistent results or very different (1 membrane model into 3 diff morphologies)

- For IT have upper layer, L5A, L5B, and L6 -- CSTR give you L5A, L5B, and have data for IT upper layers

- IT cells - corticortical (corticocollosal; not exclusive) in L2/3; corticostriatal mostly in L5 (also corticocortical; not
  exclusive); not all 1 class (eg. project to S2 and M1, non-overlapping, intrinsics are different) 
- Naoki looked at IT L/3, L4 and L5 -- different intrinsic? no consistent answer

- cellConns vs synConns needed? 
-- single S2 prjection can make 2000-3000 synapses /contacts into single cell

** Estimating synConn weights from cellConn weight
*** Discussion with Ben+Bill
**** Weight+delay in cellConn or synConn or both? (Ben)
-- if data from unitary conn EPSP, the cellConn, but need to calculate weight/synConn (h.NetCon)
-- allow weights both at cellConn and synConn level
-- if weight * 2 makes the synapse twice as strong?
-- can know max conductance, and temp response
-- Lefort used EPSP mV in soma for cellConn -- need to know how to calculate synConn -- is there a way to do this
 analytically?
-- he did in scracm code- assume syn density is correct, electrotonic difference made different between measured and simualated -- multiply by factor difference, resimulate and compare again
-- syns close to soma were fine; syns far away, original map had understimated response of far away syns, and rescaled far
 away syns
-- pattern of syn density for cell -- function of yfrac -- only need to calculate for original scracm map, and output should
 be rule
-- but for cellConn -> 5 synConns get 1mV in soma when activated simultaneously -- but will be distributed along dendrites so
 different transmission delays -- difficult to calculate accurately
-- most models dont distribute syns over dendrite with realistic syn density

-- delay could be identical for each synConn, or add small distance-based delay
-- delay would vary due to extra distance traveled through unmyelinated axon (1 m/s) -- 1.1ms diff for different pyramidal
 neurons - can omit for now - euclidean distance between cell bodies - condVelocity = 1m/s
-- minDelay value = 2ms -- too high! set to maybe 0.5 ms or 1ms -- max(0.5, 3d distance based) ; for closeby cells, axon goes
 down ~100um (fat axon), collaterals branch off, come back up 100 or 200um ; localDelay = 0.5ms
-- for long-range conns use longer delays - eg. 4 ms - kind of aritraty seems noise 

**** Bill
- Bill: have to normalize by position based on a transfer function between locations and soma
-- can use someting like ted's multifreq transfer func program to get tha map
-- yes have to scale baesd on loc and based on freq of input -- eg a high freq (short) input like AMPA has less effect on soma than a slow eg NMDA
-- was looking at paper on that recently but is just for passive case
-- jnsci15:1669.pdf The morphoelectrotonic transform: a graphical approach to dendritic function
/u/billl/articles/jnsci15:1669.pdf
-- reshaping tree based on electrical distance
-- another old paper --   author =    "Jaffe, DB and Carnevale, NT",
 title =    "Passive normalization of synaptic integration influenced by dendritic architecture",
/u/billl/articles/jnphys82:3268.pdf
-- http:/www.neuron.yale.edu/phpbb/viewtopic.php?f=8&t=2404&p=9487&hilit=frequency+response#p9487 
-- calculate the space constant in response to a AC current // lamda_AC(f) = 1/2*sqrt(diam/PI*f*Ra*Cm)
-- think he has a little package for this but not finding now
http://www.neuron.yale.edu/phpbb/viewtopic.php?f=15&t=313&p=870&hilit=frequency+response#p870
a 'frequency tool'
-- also depends on the Rm and on active conductances, 
eg an EPSP can end up being terminated by K chans or can be primarily and active response so that the actual gsyn is only a small piece

*** TO READ or check out!
**** Mark15
-Pathway specific values for the parameter “utilization of synaptic efficacy” (U, analogous to the probability of
neurotransmitter release) were unified from various experimental studies of synaptic transmission in juvenile rat
somatosensory cortex (Le Bé et al., 2007; Brémaud et al., 2007; Feldmeyer, 2006; Koester and Johnston, 2005; Markram et al.,
1997; Silver et al., 2003).

- The axonal conduction delay for each synaptic contact was computed using the axonal path distance from the soma, and a AP
  conduction velocity of 300 μm/ms, based on experimental estimates (Stuart et al., 1997). Furthermore, experimentally
  measured ratios of NMDA and AMPA conductances were used in order to model their relative contribution to unitary the EPSC
  (Feldmeyer, 2006; Myme et al., 2003; Rinaldi et al., 2007; Silver et al., 2003; Wang and Gao, 2009). 
**** Reim15
- interbouton interval: 1-10 um
- syns/bouton: 1 (2 low prob)
- bouton density: ~0.2/um
- syns/conn: E->E/I ~5 , I->E/I-> ~15
**** Zado95
- attenuation in and out - graphical rep 
**** Huys06
**** Lond02
**** Kome09
**** Jaff99
[[file+sys:/u/salvadord/Documents/ISB/Models/netpyne_repo/gif/20160324_194357.png][fig]] - pyr L5 cell
**** http://www.neuron.yale.edu/phpbb/viewtopic.php?f=8&t=2404&p=9487&hilit=frequency+response#p9487
**** http://www.neuron.yale.edu/phpbb/viewtopic.php?f=15&t=313&p=870&hilit=frequency+response#p870
- what is 
> the significance of this Z transfer for neural communication? 

Very simple. Transfer impedance is the best predictor of the 
effect of synaptic location on synaptic efficacy. This is 
a consequence of these two facts: 
1. Peak depolarization at the synaptic trigger zone is the 
primary determinant of whether or not an epsp will trigger 
a spike. This is easily shown by computational modeling. 
2. Most synapses act like current sources, not voltage sources. 
Also easily shown by computational modeling. 

Therefore, despite everything you might find in textbooks, hear 
in the classroom, or read in most journal articles, voltage 
attenuation is not a useful predictor of the effect of synaptic 
location on synaptic efficacy. The best predictor is transfer 
impedance, which tells you how strongly a current, injected at 
one point in the cell, will affect membrane potential throughout 
the cell. See 
Jaffe, D.B. and Carnevale, N.T. Passive normalization of 
synaptic integration influenced by dendritic architecture. 
Journal of Neurophysiology 82:3268-3285, 1999. 

So if you want to understand how the distribution of synaptic 
inputs over the surface of a cell will affect the spiking 
output of that cell, study the spatial variation of 
transfer impedance from a reference point located at the 
cell's spike trigger zone (since transfer impedance between 
any two points is independent of the direction of signal 
propagation, the transfer impedance from any point to the 
soma is the same as from the soma to that point). 

**** https://github.com/davidcsterratt/dcs-hoc

- https://www.neuron.yale.edu/phpBB/viewtopic.php?f=8&t=2264
PointProcessDistributor.hoc
http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002545

* 16may19 Meeting with Padraig
** mod 
- most channels already exist in NeuroML2
- converting NeuroML2 -> mod is possible
** github
- waffle - organize issues
- pull request to release

** neuroml -> netpyne
- if make changes then post comment or pull request in show case:
  https://github.com/OpenSourceBrain/NetPyNEShowcase/tree/master/NetPyNE
* 16jun01 Setting up Travis
** example code
 Framework for running automated tests on OSB using Travis-CI, see https://github.com/OpenSourceBrain/osb-model-validation

sudo: false

addons:
  apt:
    packages:
       # Requirements for Brian
    - python-numpy 
    - python-scipy 
    - python-matplotlib 
    - python-sympy

language: python
python: 2.7

virtualenv:
    system_site_packages: true

env:
    - OMV_ENGINE=PyNEURON
    - OMV_ENGINE=jNeuroML
    - OMV_ENGINE=jNeuroML_NEURON
    - OMV_ENGINE=jNeuroML_validate

install: 
    - pip install git+https://github.com/OpenSourceBrain/osb-model-validation
    
    # Brian required by PyNEURON script also...
    - omv install Brian
    # Need to pre install NEURON so nrnivmodl can be run targeting mod files in a different directory
    - omv install NEURON
    - cd NEURON/test
    - /home/travis/neuron/nrn/x86_64/bin/nrnivmodl ../mod.files
    - ls -alt
    - cd ../..

script:
    - omv all -V
    
    
    
** useful repos
https://github.com/openworm/org.geppetto.simulator.external/blob/master/.travis.yml
https://github.com/NeuralEnsemble/PyNN/blob/master/ci/install_neuron.sh
https://github.com/OpenSourceBrain/SmithEtAl2013-L23DendriticSpikes/blob/master/.travis.yml

* 16jun15 New format for figures
** Possible formats
*** list of dict
figs=[] 

simConfig['analysis'].append({'func': 'plotRaster', 
 'include': ['all', 120, 'E1', ('L2', 56), ('L5', [4,5,6]), ('L6', range(5,20))], # all, gid, pop, pop rel index
 'maxSpikes':3e8, 
 'overlaySpikeHist': True,
 'syncLines': True, 
 'orderBy':'ynorm'|'y'|'pop'|'cellType',
 'figId': 1,  # figs with same figId will be converted to subplots
 'saveData': 'data2.pkl',
 'saveName': 'fig1.png'})

simConfig['analysis'].append({'func': 'plotSpikeHist', 
 'include': ['all', 120, 'E1', ('L2', 56), ('L5', [4,5,6]), ('L6', range(5,20))], # all, gid, pop, pop rel index
 'binsize': 5,
 'overlay': True,  # else separate subplots
 'style': 'line'|'bar'|'scatter',
 'yaxis': 'rate'|'count', 
 'figId': 1,  # figs with same figId will be converted to subplots
 'saveData': 'data1.pkl,
 'saveFig': 'fig1.png'})


simConfig['analysis'].append({'func': 'plotTraces',
 'include': ['all', 120, 'E1', ('L2', 56), ('L5', [4,5,6]), ('L6', range(5,20))], # all, gid, pop, pop rel index
 (automatically added to recordCells)
 'overlay': True,  # else separate subplots
 'oneFigPer': 'cell'|'trace',
 'saveData': 'data1.pkl,
 'saveFig': 'fig1.png'})

*** just dict
simConfig['analysis']['plotRaster']={
 'include': ['all', 120, 'E1', ('L2', 56), ('L5', [4,5,6]), ('L6', range(5,20))], # all, gid, pop, pop rel index 
 'maxSpikes':3e8, 
 'overlaySpikeHist': True,
 'syncLines': True, 
 'orderBy':'ynorm'|'y'|'pop'|'cellType',
 'figId': 1,  # figs with same figId will be converted to subplots
 'saveData': 'data2.pkl',
 'saveName': 'fig1.png'})

simConfig['analysis']['plotConnMatrix']= True OR {'values': 'weight'| 'numConns'| ' |'probability'| 'convergence', 'divergence', 
 'groupBy': 'cell'|'pop',
 'saveData': 'data1.pkl,
 'saveFig': 'fig1.png'})




** Equivalent to calling function
can use same args for calling function or for simConfig (use **kwargs)
** plotRaster y-axis -- possible code to show actual y values instead of indices
    # code to make y-axis show actual values instead of ids (difficult to make work in a generic way for all cases)
    '''maxY = max(y2ind.values())
    minY = min(y2ind.values())
    # if  maxy >= 20: base = 5
    # elif maxy >= 10: base = 2
    # elif maxy > 1: base = 1
    # elif maxy >= 0.1: base = 0.1
    # else: base = 0.001
    base=10
    upperY = base * ceil(float(maxY)/base)
    lowerY = base * floor(float(minY)/base)
    yAddUpper = int(upperY - maxY)
    yAddLower = int (minY-lowerY)
    for i in range(yAddUpper): y2ind.update({yAddUpper: len(y2ind)+1})
    for i in range(yAddLower): y2ind.update({yAddLower: min(y2ind.values())-1})
    ystep = base #int(len(y2ind)/base)
    #ystep = base * round(float(ystep)/base)
    yticks(y2ind.values()[::ystep], y2ind.keys()[::ystep])'''

* 16Jun16 Parallelizing creation of cells and connections
** Email from mike hines
Parallel NEURON idioms:
Information exchange during setup
Random numbers
Debugging
Michael Hines
CodeJam 2014
​
     Information exchange during setup
Results must be independent of
Number of processors
Distribution of cells
​
 Information exchange during setup
Results must be independent of
Number of processors
Distribution of cells
A process is often interested in all the objects with
a particular property.
​
 Information exchange during setup
Results must be independent of
Number of processors
Distribution of cells
A process is often interested in all the objects with
a particular property.
But it generally does not know where the objects are.
And the process that owns the object does not
know who is interested in it.
​
 Information exchange during setup
Results must be independent of
Number of processors
Distribution of cells
A process is often interested in all the objects with
a particular property.
But it generally does not know where the objects are.
And the process that owns the object does not
know who is interested in it.
There is not enough memory in any one process to hold
a map of which ranks hold which objects.
​
 Example: MPI_ISend/Recv spike exchange
Cells do not know which ranks are interested in its spikes.
​
 Example: MPI_ISend/Recv spike exchange
Cells do not know which ranks are interested in its spikes.
​
Example: Source/Target connectivity
Reciprocal synapse connection description.
(mitral_gid, mdend_index, xm, granule_gid, gdend_index, xg, ...)
​
Construct a mitral => all the tuples with that mitral_gid.
Granules don t know enough for construction of the tuples.
Construct a granule => gather all the tuples with that
granule_gid.
​
 Basic exchange:
dest = ParallelContext.py_alltoall(src)
src and dest are a list of nhost pickleable objects.
src[j] on the ith rank will be copied to dest[i] on the jth rank.
Likely identical to mpi4py.MPI comm.alltoall(src, dest).
​
1
​
2
​
3
​
1
​
2
​
3
​
 Basic exchange:
dest = ParallelContext.py_alltoall(src)
src and dest are a list of nhost pickleable objects.
src[j] on the ith rank will be copied to dest[i] on the jth rank.
Likely identical to mpi4py.MPI comm.alltoall(src, dest).
Essentially a wrapper for:
MPI_Alltoallv(s, scnt, sdispl, MPI_CHAR,
r, rcnt, rdispl, MPI_CHAR, comm);
along with a preliminary
MPI_all2all(scnt, 1, MPI_INT, rcnt, 1, MPI_INT, comm);
in order to calculate rcnt and rdispl.
​
 But:
No one knows who holds what.
No room for anyone to have a global map.
​
 But:
No one knows who holds what.
No room for anyone to have a global map.
​
Solution: A rendezvous rank function:
rank = rendezvous(property)
usually
rank = gid % nhost
​
 But:
No one knows who holds what.
No room for anyone to have a global map.
​
Solution: A rendezvous rank function:
rank = rendezvous(property)
usually
rank = gid % nhost
1) Everyone sends the keys they own to the rendezvous rank.
2) Everyone sends the keys they want to the rendezvous rank.
3) The rendezvous rank sends back to the owners,
which ranks want which keys.
4) The owners send the objects to the ranks that want them.
​
 Usually simplification is possible:
If the objects are small.
1) Everyone sends the keys and objects
they own to the rendezvous rank.
2) Everyone sends the keys they want to the rendezvous rank.
3) The rendezvous rank sends the objects to the ranks that
want them.
​
 Usually simplification is possible:
If rendezvous(property) is known to be the source rank for
all the keys (a priori or by verifying with an all_reduce).
1) Everyone sends the keys they want to the owner ranks.
2) The owners send the objects to the ranks that want them.
​
 Usually simplification is possible:
If rendezvous(property) is known to be the destination rank
for all the keys (a priori or by verifying with an all_reduce).
1) The owners send the objects to the ranks that want them.
​
 What about RANDOM?
Results must be independent of
Number of processors
Distribution of cells
​
 What about RANDOM?
Results must be independent of
Number of processors
Distribution of cells
Associate a random stream with a cell.
Reproducible
Independent
Restartable
​
 What about RANDOM?
Results must be independent of
Number of processors
Distribution of cells
Associate a random stream with a cell.
Reproducible
Independent
Restartable
Use cryptographic transformation of several integers.
run number
stream number (cell gid)
stream pick index
​
 Use cryptographic transformation of several integers.
run number
stream number (cell gid)
stream pick index
Had been using MCellRan4
but only two integers to define x(n1, n2)
​
 Use cryptographic transformation of several integers.
run number
stream number (cell gid)
stream pick index
Had been using MCellRan4
but only two integers to define x(n1, n2)
Thanks! to Eilif Muller for suggesting:
Parallel Random Numbers: As Easy as 1, 2, 3
Salmon et al. SC11 (2011)
D. E. Shaw Research, New York, NY 10036, USA
We introduce several counter based PRNGs: some based on
cryptographic standards (AES, Threefish) and some completely
new (Philox). All our PRNGs pass rigorous statistical tests
(including TestU01 s BigCrush) and produce at least 2^64
unique parallel streams of random numbers, each with period
2^128 or more.
http://www.deshawresearch.com/resources_random123.html
​
 Use cryptographic transformation of several integers.
run number
stream number (cell gid)
stream pick index
Random123:
Eight integers define x(n1, ..., n8)
But we use 5 (three for the stream number).
Philox variant
​
 Use cryptographic transformation of several integers.
run number
stream number (cell gid)
stream pick index
Random123:
Eight integers define x(n1, ..., n8)
But we use 5 (three for the stream number).
Philox variant
Good performance
10 million picks
ACG 0.329s
MLCG 0.681s
MCellRan4 0.150s
numpy.random.rand(n) 0.233s
Random123 0.201s
​
(Mersenne Twister)
​
 from neuron import h
r = h.Random()
r.Random123(1,2,3)
r.negexp(1)
​
 from neuron import h
r = h.Random()
r.Random123(1,2,3)
r.negexp(1)
​
1e+06
​
1e+06
​
800000
​
995000
​
600000
​
990000
​
400000
​
985000
0
​
0.005 0.01 0.015
​
200000
​
n=100000000
0
dx = .01
0
1
2
y = h.Vector(n).setrand(r)
y = y.histogram(0,5,dx).rotate( 1,0)
x = y.c().indgen(dx/2,dx)
g = h.Graph()
y.line(g, x)
​
3
​
4
​
5
​
 nrnran123.h (abridged)
all generator instances share the global index
extern void nrnran123_set_globalindex(uint32_t gix);
extern nrnran123_State*
nrnran123_newstream(uint32_t id1, uint32_t id2);
extern uint32_t nrnran123_ipick(nrnran123_State*);
uniform 0 to 2^32 1
extern double nrnran123_dblpick(nrnran123_State*);
uniform open interval (0,1)
minimum value is 2.3283064e 10
max value is 1 min
​
 extern double nrnran123_negexp(nrnran123_State*);
mean 1.0
min value is 2.3283064e 10
max is 22.18071
​
 extern double nrnran123_negexp(nrnran123_State*);
mean 1.0
min value is 2.3283064e 10
max is 22.18071
​
 log(1/2^32) 22.18071
 log(2/2^32) 21.487563
 log(10/2^32) 19.878125
 log(11/2^32) 19.782815
exp( 5)*2^32 28939262
​
 log(28939262/2^32) 5.0000000001
 log(28939263/2^32) 4.99999996
​
 extern double nrnran123_negexp(nrnran123_State*);
mean 1.0
min value is 2.3283064e 10
max is 22.18071
​
stateless (though the global index is still used)
extern nrnran123_array4x32
nrnran123_iran(uint32_t seq, uint32_t id1, uint32_t id2);
​
 Debugging
Results must be independent of
Number of processors
Distribution of cells
​
 Debugging
Results must be independent of
Number of processors
Distribution of cells
1) GID and time of first spike difference.
​
 Debugging
Results must be independent of
Number of processors
Distribution of cells
1) GID and time of first spike difference.
2) All spikes delivered to synapses of that Cell?
​
 Debugging
Results must be independent of
Number of processors
Distribution of cells
1) GID and time of first spike difference.
2) All spikes delivered to synapses of that Cell?
3) When and what is the first state difference?
h.load_file( prcellstate.hoc )
if pc.gid_exists(gid):
h.prcellgid(gid)

* 16jul11 Modify network instance
** sim.net.modifyCells
** sim.net.modifyConns
** sim.net.modifyStims
* 16jul15 Use dot notation
** new classes Dict and ODict
** ~25% slower
*** old dicts
Creating simulation of 23 cell populations for 0.1 s on 1 hosts...
  Number of cells on node 0: 4768 
  Done; cell creation time = 3.07 s.
Making connections...
  Number of connections on node 0: 9536 
  Done; cell connection time = 1.28 s.

Running...
0 
  Done; run time = 125.21 s; real-time ratio: 0.00.

Gathering spikes...
  Done; gather time = 1.91 s.

Analyzing...
  Run time: 125.21 s
  Simulated time: 0.1 s; 4768 cells; 1 workers
  Spikes: 2120 (4.45 Hz)
  Connections: 9536 (2.00 per cell)
162.0 89.4 820
IT_L23   2.20985431331  Hz
89.0 89.4 113
PV_L23   8.80996218645  Hz
97.0 89.4 113
SOM_L23   9.60186889984  Hz
69.0 89.4 431
IT_L4   1.79074728663  Hz
72.0 89.4 475
IT_L5A   1.69551395267  Hz
111.0 89.4 540
IT_L5B   2.29927914492  Hz
751.0 89.4 540
PT_L5B   15.5563841246  Hz
169.0 89.4 248
PV_L5   7.6225012629  Hz
235.0 89.4 248
SOM_L5   10.5993360756  Hz
83.0 89.4 496
IT_L6   1.8717976474  Hz
95.0 89.4 496
CT_L6   2.14241899401  Hz
81.0 89.4 124
PV_L6   7.30677635852  Hz
106.0 89.4 124
SOM_L6   9.56195424695  Hz
Plotting recorded cell traces ...
  Done; plotting time = 0.61 s

Total time = 132.20 s



*** new dot Dicts
Creating simulation of 23 cell populations for 0.1 s on 1 hosts...
  Number of cells on node 0: 4768 
  Done; cell creation time = 4.08 s.
Making connections...
  Number of connections on node 0: 9536 
  Done; cell connection time = 1.55 s.

Running...
0 
  Done; run time = 123.59 s; real-time ratio: 0.00.

Gathering spikes...
  Done; gather time = 3.34 s.

Analyzing...
  Run time: 123.59 s
  Simulated time: 0.1 s; 4768 cells; 1 workers
  Spikes: 2120 (4.45 Hz)
  Connections: 9536 (2.00 per cell)
162.0 89.4 820
IT_L23   2.20985431331  Hz
89.0 89.4 113
PV_L23   8.80996218645  Hz
97.0 89.4 113
SOM_L23   9.60186889984  Hz
69.0 89.4 431
IT_L4   1.79074728663  Hz
72.0 89.4 475
IT_L5A   1.69551395267  Hz
111.0 89.4 540
IT_L5B   2.29927914492  Hz
751.0 89.4 540
PT_L5B   15.5563841246  Hz
169.0 89.4 248
PV_L5   7.6225012629  Hz
235.0 89.4 248
SOM_L5   10.5993360756  Hz
83.0 89.4 496
IT_L6   1.8717976474  Hz
95.0 89.4 496
CT_L6   2.14241899401  Hz
81.0 89.4 124
PV_L6   7.30677635852  Hz
106.0 89.4 124
SOM_L6   9.56195424695  Hz
Plotting recorded cell traces ...
  Done; plotting time = 0.93 s

Total time = 133.78 s
* 16jul19 Allen Brain example
** emails
---
Hi Salvador,
 
Thank you very much for talking to us today.  That was helpful.
 
As a next step for us, I wonder if I could ask you to give a quick tutorial to a larger group of folks here at the Allen Institute.  We have a meeting with several more people planned for Wednesday, July 20, at 3 pm Pacific time.  Would you be able to talk to us then?
 
I am thinking that perhaps you could speak for 20 minutes or so, and then do 10 minutes of Q&A.
 
It would be most helpful if for this tutorial you could walk us through a specific example of NetPyNE workflow applied to a question that’s of interest to us.  It doesn’t have to be a fully finished example – could be pseudo-code in part.  We would just really benefit from seeing how you are doing these operations.
 
Here’s the example I have in mind.
1. Let’s say you have 5 or so neuron types, each represented by a particular cell model and a morphology.  Let’s build a model consisting of 10,000 neurons that are replicas of these 5 models.
 
2. Distribute the 10,000 cells in space.
 
3. Connect the neurons using cell-type specific connectivity rules (let’s say, probabilistic rules based on distances between somata).
 
4. Establish feedforward inputs into the 10,000 cells representing spike trains incoming from other parts of the brain.  Use arbitrary spike trains (e.g., experimental recordings), if possible.
 
5. Save the constructed system to a file.  Read the file into NetPyNE and run the simulation. 
 
6. Visualize the output.
 
Do you think it’s feasible?  Sorry for a short notice, and please do let me know if this is too much to ask :).
 
Many thanks,
 
Anton.

--- 
Hi Anton,

Yes, I think its feasible. 

Were you interested in any particular cell models / number of compartments? any ones available in hoc or python (eg. from ModelDB) can be directly imported. Of course 10k cells with very detailed morphologies might take a while to simulate. In our M1 sim we combine Izhikevich point neurons, 5-compartment, and full >170 compartment cells. Let me know if you'd be interested in seeing an example of this. 

Any requirements in terms of subcellular connectivity? Want single soma to soma synapse, or multiple synapses per cell-to-cell connection? Currently can provide specific section/location for each synapse, or can choose to distribute uniformly across a set of sections or sectionList (also about to release feature to distribute synapses over dendritic tree based on more complex patterns, eg. 1D or 2D density maps). 

I'll let you know if I have any issues, but otherwise talk to you Wednesday 3pm (pacific time). 

Thanks again for your interest.
Salva

--- 
Sounds great, Salvador.  Thank you very much.
 
We typically use models with a few hundred compartments.  They all can be found here:
http://celltypes.brain-map.org/
They are also available on ModelDB.
 
Let’s not worry about actually running a simulation with 10,000 cells.  We are just curious to see the workflow and get an idea about the scale of the problem.  If you can estimate how long it will take to run the model-building part, how long it would take to simulate it, and how large are the files in which you would save the model details, that would be great, but don’t worry if it turns out that estimating those numbers is not straightforward.
 
For the connectivity, we are using multiple synapses per connection (let’s assume, five synapses per connection on average).  Synapses should be distributed over dendritic tree, with rules depending on target and source cell types.  For example, something like “for this connection type, place synapses on the soma and dendrites within 100 um of path distance from the soma”.  Again, please don’t worry about actually instantiating all this.  We would just like to see an example of your code that does that.
 
One additional thought we have is that we could ask you for the code from such a tutorial after we talk on Wednesday.  That way we could start playing around with NetPyNE in a meaningful way.  Hope that’s OK.
 
Thanks, and looking forward to chatting soon!  Best,
 
Anton.

** results
*** 300x1200x300
create_save.py:

Creating network of 9 cell populations on 1 hosts...
  Number of cells on node 0: 6477 
  Done; cell creation time = 11.53 s.
Making connections...
  Number of connections on node 0: 4160680 
  Done; cell connection time = 617.51 s.
Adding stims...
  Number of stims on node 0: 32385 
  Done; cell stims creation time = 3.49 s.

Gathering data...
  Done; gather time = 193.44 s.

Analyzing...
  Cells: 6477
  Connections: 4193065 (647.38 per cell)
Saving output as Allen.json  ... 
Finished saving!

- size: 970Mb

load_run.py:

Loading file Allen.json ... 
  Done; file loading time = 56.78 s
Loading simConfig...
  simConfig not found in file Allen.json
Loading netParams...
Loading net...
  Created 6477 cells
  Added NEURON objects to 6477 cells
  Done; re-instantiate net time = 75.16 s
Loading simData...
  simData not found in file Allen.json
  Recording  V_soma from cell  0
  Recording  V_dend6 from cell  0
  Recording  V_soma from cell  6045
  Recording  V_dend6 from cell  6045

*** 380x120x380
create_save.py:

Creating network of 9 cell populations on 1 hosts...
  Number of cells on node 0: 10392 
  Done; cell creation time = 17.84 s.
Making connections...
  Number of connections on node 0: 9647815 
  Done; cell connection time = 1625.43 s.
Adding stims...
  Number of stims on node 0: 51960 
  Done; cell stims creation time = 6.23 s.

Gathering data...
  Done; gather time = 563.89 s.

Analyzing...
  Cells: 10392
  Connections: 9699775 (933.39 per cell)
Saving output as Allen.json  ... 
Finished saving!

- size: 2.0Gb (crashed)

*** 380x120x380 (less conns)
create_save.py:

Creating network of 9 cell populations on 1 hosts...
  Number of cells on node 0: 10392 
  Done; cell creation time = 18.68 s.
Making connections...
  Number of connections on node 0: 6329300 
  Done; cell connection time = 1388.36 s.
Adding stims...
  Number of stims on node 0: 51960 
  Done; cell stims creation time = 6.06 s.

Gathering data...
  Done; gather time = 353.89 s.

Analyzing...
  Cells: 10392
  Connections: 6381260 (614.06 per cell)
Saving output as Allen.json  ... 
Finished saving!

- size: 1.4Gb (crashed)

load_run.py:

Loading file Allen_10k.json ... 
  Done; file loading time = 99.93 s
Loading simConfig...
  simConfig not found in file Allen_10k.json
Loading netParams...
Loading net...
  Created 10392 cells
  Created 6381260 connections
  Created 51960 stims
  Added NEURON objects to 10392 cells
  Done; re-instantiate net time = 116.31 s
Loading simData...
  simData not found in file Allen_10k.json

Running...
  Done; run time = 32.55 s; real-time ratio: 0.00.

Gathering data...
  Done; gather time = 751.81 s.

Analyzing...
  Cells: 10392
  Connections: 6381260 (614.06 per cell)
  Spikes: 0 (0.00 Hz)
  Simulated time: 0.0 s; 1 workers
  Run time: 32.55 s
  Done; saving time = 0.11 s.
Plotting raster...
No spikes available to plot raster
Plotting recorded cell traces ...
Plotting 2D representation of network cell locations and connections...

*** 380x120x380 (less conns, with subcell)

* 16jul20 Matplotlib errors
- http://stackoverflow.com/questions/4130355/python-matplotlib-framework-under-macosx
- fixed by adding 'backend: Agg' to ~/.matplotlib/matplotlibrc
- actually just deactivated

* 16aug20 Fixing memory leak when running batch
** links
- http://chase-seibert.github.io/blog/2013/08/03/diagnosing-memory-leaks-python.html
- http://stackoverflow.com/questions/11891755/find-all-references-to-an-object-in-python/11891904#11891904
- http://stackoverflow.com/questions/10446839/does-dictionarys-clear-method-delete-all-the-item-related-objects-from-memory
- http://stackoverflow.com/questions/7101404/how-can-i-release-memory-after-creating-matplotlib-figures
- https://pymotw.com/2/gc/
** testing different cleaning methods

- added after iteration:
print 'Memory usage: %s' % resource.getrusage(resource.RUSAGE_SELF).ru_maxrss

- memory increases in master node after iter
master: 89 mb -> 362 -> 569 -> 800 -> 993 -> 1190
slaves: 90 -> 139 ...

- trying gc.collect() - same

- tried: replaceItemObj([cell.__dict__ for cell in sim.net.cells], 'h', None)
lowered mem, but crashed -- need to gid_clear before

- with gid_clear before, increasing but less
98 -> 180 -> 230 

- clear recorded stuff
89 -> 180 -> 230 -> 280

- trying: 
import objgraph
objgraph.show_most_common_types()

function                   11471
Dict                       10633
list                       8925
dict                       6759
tuple                      2616
wrapper_descriptor         1880
weakref                    1748
builtin_function_or_method 1288
method_descriptor          1194
type                       1094

function                   11471
Dict                       10658
list                       8929
dict                       6761
tuple                      2616
wrapper_descriptor         1880
weakref                    1748
builtin_function_or_method 1288
method_descriptor          1194
type                       1094

function                   11471
Dict                       10597
list                       8917
dict                       6755
tuple                      2616
wrapper_descriptor         1880
weakref                    1748
builtin_function_or_method 1288
method_descriptor          1194
type                       1094
Dict                       63291
list                       19046

function                   11471
dict                       6786
tuple                      2616
wrapper_descriptor         1880
weakref                    1748
builtin_function_or_method 1288
method_descriptor          1194
type                       1094
Setting stimulation (NetCon) weight to 0.02
Memory usage: 181530624
Memory usage: 140632064
Memory usage: 140087296
Memory usage: 140316672


function                   11471
list                       11433
Dict                       10658
dict                       9270
tuple                      2481
wrapper_descriptor         1895
weakref                    1752
builtin_function_or_method 1288
method_descriptor          1196
type                       1094

function                   11471
list                       11421
Dict                       10597
dict                       9264
tuple                      2481
wrapper_descriptor         1895
weakref                    1752
builtin_function_or_method 1288
method_descriptor          1196
type                       1094

function                   11471
list                       11429
Dict                       10633
dict                       9268
tuple                      2481
wrapper_descriptor         1895
weakref                    1752
builtin_function_or_method 1288
method_descriptor          1196
type                       1094
Dict                       113384
list                       31602

function                   11471
dict                       9303
tuple                      2481
wrapper_descriptor         1895
weakref                    1752
builtin_function_or_method 1288
method_descriptor          1196
type                       1094
Setting stimulation (NetCon) weight to 0.03
Memory usage: 234979328
Memory usage: 140632064
Memory usage: 140087296
Memory usage: 140316672



- clear allSimData and allCells

function                   11471
Dict                       10597
list                       8917
dict                       6755
tuple                      2616
wrapper_descriptor         1880
weakref                    1748
builtin_function_or_method 1288
method_descriptor          1194
type                       1094

function                   11471
Dict                       10658
list                       8929
dict                       6761
tuple                      2616
wrapper_descriptor         1880
weakref                    1748
builtin_function_or_method 1288
method_descriptor          1194
type                       1094

function                   11471
Dict                       10633
list                       8925
dict                       6759
tuple                      2616
wrapper_descriptor         1880
weakref                    1748
builtin_function_or_method 1288
method_descriptor          1194
type                       1094
Dict                       63291
list                       19011

function                   11471
dict                       6785
tuple                      2616
wrapper_descriptor         1880
weakref                    1748
builtin_function_or_method 1288
method_descriptor          1194
type                       1094
Setting stimulation (NetCon) weight to 0.02
Memory usage: 183537664
Memory usage: 140525568
Memory usage: 140050432
Memory usage: 140353536


function                   11471
list                       11421
Dict                       10597
dict                       9264
tuple                      2481
wrapper_descriptor         1895
weakref                    1752
builtin_function_or_method 1288
method_descriptor          1196
type                       1094

function                   11471
list                       11429
Dict                       10633
dict                       9268
tuple                      2481
wrapper_descriptor         1895
weakref                    1752
builtin_function_or_method 1288
method_descriptor          1196
type                       1094

function                   11471
list                       11433
Dict                       10658
dict                       9270
tuple                      2481
wrapper_descriptor         1895
weakref                    1752
builtin_function_or_method 1288
method_descriptor          1196
type                       1094
Dict                       115886
list                       31567

function                   11471
dict                       9302
tuple                      2481
wrapper_descriptor         1895
weakref                    1752
builtin_function_or_method 1288
method_descriptor          1196
type                       1094
Setting stimulation (NetCon) weight to 0.03
Memory usage: 233951232
Memory usage: 140353536
Memory usage: 140525568
Memory usage: 140050432



- remove allCells and simDAta objects themselves

Memory usage: 183980032
Dict                       52598
list                       16498
function                   11471
dict                       5529
tuple                      2616
wrapper_descriptor         1880
weakref                    1748
builtin_function_or_method 1288
method_descriptor          1194
type                       1094

Memory usage: 232386560
Dict                       105193
list                       29054
function                   11471
dict                       8046
tuple                      2481
wrapper_descriptor         1895
weakref                    1752
builtin_function_or_method 1288
method_descriptor          1196
type                       1094


- objects in sim:
 'allSimData', 'simData', 'net', 'cfg'

- if no gather, then only increases 2mb / iteration

- only happens when multiple cores! related to gather 

- leakage when pc.py_alltoall -- need to clear vars inside func

- small leakage when saving - think reduced by clearing vars

- huge leakge with plotSpikeHist

* 16nov23 Adding support for gap junctions
** useful links
http://www.neuron.yale.edu/neuron/static/new_doc/modelspec/programmatic/network/parcon.html?highlight=gap%20junction
https://senselab.med.yale.edu/ModelDB/ShowModel.cshtml?model=97917
https://senselab.med.yale.edu/ModelDB/ShowModel.cshtml?model=97917

** example from padraig
if (isCellOnNode("SampleCellGroup", 1)) {
    a_SampleCellGroup[1].Soma { elecsyn_NetConn_SampleCellGroup_SampleCellGroup_ElectSyn_A[0] = new ElectSyn(0.5) }
    elecsyn_NetConn_SampleCellGroup_SampleCellGroup_ElectSyn_A[0].weight = 1.0
    pnm.pc.target_var(&elecsyn_NetConn_SampleCellGroup_SampleCellGroup_ElectSyn_A[0].vgap, 100000000)
    pnm.pc.source_var(&a_SampleCellGroup[1].Soma.v(0.5), 200000000)
}
if (isCellOnNode("SampleCellGroup", 0)) {
    a_SampleCellGroup[0].Soma { elecsyn_NetConn_SampleCellGroup_SampleCellGroup_ElectSyn_B[0] = new ElectSyn(0.5) }
    elecsyn_NetConn_SampleCellGroup_SampleCellGroup_ElectSyn_B[0].weight = 1.0
    pnm.pc.target_var(&elecsyn_NetConn_SampleCellGroup_SampleCellGroup_ElectSyn_B[0].vgap, 200000000)
    pnm.pc.source_var(&a_SampleCellGroup[0].Soma.v(0.5), 100000000)
}

** issues
- bidirectional
- requires creating synMechs both in presyn and postsyn
- requires creating conns from pre->post and post->pre
- need to do at the network.py level so can call createConn func for both cells
- requires specifying sec and loc of source cell as well as of target cell -- add preSec and preLoc

- create a temporal list with the presyn cells and ids, and create the synMech, target_var and source_var with the
  appropriate ids after connections have been created. 
- check that it plays well with subcellular distributions
- check that no duplicates are created 

* 16oct26 Elliptic cylinder and ellipsoid shapes
  if sim.net.params.shape == 'cylinder':
            # Use the x,z random vales 
            rho = randLocs[:,0] # use x rand value as the radius rho in the interval [0, 1)
            phi = 2 * pi * randLocs[:,2] # use z rand value as the angle phi in the interval [0, 2*pi) 
            x = (1 + sqrt(rho) * cos(phi))/2.0
            z = (1 + sqrt(rho) * sin(phi))/2.0
            randLocs[:,0] = x
            randLocs[:,2] = z
    
        elif sim.net.params.shape == 'ellipsoid':
            # Use the x,y,z random vales 
            rho = np.power(randLocs[:,0], 1.0/3.0) # use x rand value as the radius rho in the interval [0, 1); cuberoot
            phi = 2 * pi * randLocs[:,1] # use y rand value as the angle phi in the interval [0, 2*pi) 
            costheta = (2 * randLocs[:,2]) - 1 # use z rand value as cos(theta) in the interval [-1, 1); ensures uniform dist 
            theta = arccos(costheta)  # obtain theta from cos(theta)
            x = (1 + rho * cos(phi) * sin(theta))/2.0
            y = (1 + rho * sin(phi) * sin(theta))/2.0
            z = (1 + rho * cos(theta))/2.0 
            randLocs[:,0] = x
            randLocs[:,1] = y
            randLocs[:,2] = z

* 16oct27 Netstims and artif cells as cell populations
- change tutorials
- if artificial cells (spike generators with no section), 'cellModel' refers to point process mech name (can be overriden if
  cellRule with that name)
- check if cellModel=rule, otherwise check if pointprocess, otherwise error 
- use try except to set params
- create oneToOne connectivity -- connect in order 
- backward compatibility issues:
-- netstim pop now requires numCells (default to numCells: 1 ??)
-- connection should be oneToOne (default is fullConn)

- cant check if rules exist for particular cellModel, since could be applied based on other features (eg. yfrac); so have to
  make condition of point process make prioritary: 1st check if cellModel==point process -> PointCell; otherwise CompartCell

* 17Apr05 Error checking
** popParams
- cellModel: required, arbitrary value or pointprocess; 
-- if arbitrary then create compartCell() and use cellParams
-- if pointtprocess then create pointCell() and don't need cellParams

- cellType: not required, but recommended; arbitrary value; used to associate population with cellParam rules

- numCells, density or gridSpacing - at least 1 required
-- numCells: fixed number of cells (integer)
-- density: num cells per mm3 (float)
-- gridSpacing: fixed spacing between cells (um)

- xRange, yRange, zRange: optional, absolute allowed range to place cells; check within network size
- xnormRange, ynormRange, znormRange: optional, normalized allowed range to place cells; check within 0,1

- for NetStims:
rate - Firing rate in Hz (note this is the inverse of the NetStim interval property).
noise - Fraction of noise in NetStim (0 = deterministic; 1 = completely random).
number - Max number of spikes generated (default = 1e12)
seed - Seed for randomizer (optional; defaults to value set in simConfig.seeds[‘stim’])

- check netParams network dimensions:
-- netParams.sizeX, sizeY, sizeZ - net dimensions in um; check not 0 or negative
-- shape - check either 'cuboid', 'cylinder' or 'ellipsoid'

** cellParams
- conds: required and needs to be a dict eg. ('conds': {'pop': ['PYR2','PYR3'], 'x':[100,200]})

-- keys: attributes/tags of cell (cell.tags)
--- declared in popParams: eg. cellType, cellModel, any arbitrary 
--- popLabel
--- x, y, z
--- xnorm, ynorm, znorm 

-- values:
--- popLabel, cellModel, arbitrary attributes: warning if doensn't exist in popParams; single string or list of strings
--- x, y, z: should be within 0,sizeX etc -- check format is single value of 2-value list:  
--- xnorm, ynorm, znorm: should be within range 0,1

- secs
-- geom: required; either pt3d or L+diam
-- topol: required if len(secs)>1; has to be dict; with 3 keys:
--- parentSec: string which should be in keys of secs
--- parentX: 0-1
--- childX: 0-1

-- mechs: not required, check mech and properties exist using utils.mechVarList()

-- ions: not required, check mech and properties exist using utils.mechVarList()

-- pointps: not required; 
-- required key 'mod' wiht pointp label; check exists using utils.mechVarlist()
-- 'loc' also required; has to be between 0 and 1
-- 'vref' and 'synList' optional

- spikeGenLoc: not rquired; between 0 and 1

** stimTargetParams
- source: needs to be one of the keys/labels in netParams.stimSourceParams

** connParams
- preConds - same as cellParams conds
- postConds - same as cellParams conds

- sec: optional; uses 'soma' by default, 1st section available; check if section exists in at least 1 cell type -- cellParams (otherwise
  need to 'calculate' postConds and might not make sense in error checking stage)

- loc: optional; defaults to 0.5; has to be [0,1]; 
-- can be a list if synMechs is a list, or synsPerConn > 1
-- size of list = len(synMechs) or synsPerConn
-- each item in list in range [0,1]
-- if both len(synMechs) and synsPerConn>1, loc can be a 2D list (e.g. for 2 synMechs and synsPerConn = 3: [[0.2, 0.3, 0.5], [0.5, 0.6, 0.7]])

- weight: optional; any arbitrary positive value; single value, list or 2d list (see loc above)

- delay: optional; any arbitrary positive value; single value, list or 2d list (see loc above)

- synMech: optional; defaults to synMechParams[0]; can be single string or list; items have to be a key in netParams.synMechParams

- synsPerConn: optional, defaults to 1; has to be >=1

- probability: optional; [0,1]

- convergence/divergence: optional; positive integer

- connFunc: deprecated

- string-based functions - see valid expressions in documentation


** todo
*** flags
cfg.checkErrors - true or false (affects simFuncs initialize())
cfg.checkErrorsVerbose 
- True - prints evrything, passed and failed
- False - only failed, including warnings (nothing for passed)
*** add extra tests for numeric values eg. numCells
*** error messages not capitalized
XNormRange -> xnormRange etc
*** stop if an error happens
sys.exit

* 17Apr07 GUI
** gantt chart
- start before sept
- have minor demo (pics) by Oct so can include in grant -- maybe move standalone to later
- import cells should be together with netPArams UI
- should all fit within avail budget -- if not, give us tasks that we can do

** gantt chart
*** infrastructure
- improv design - required 
- migrate to npm - started, dependencies managed, needs to happen and easier to maintain, required
- update to latest jupyter - doesn't need to happen
- improve interaction - need to understand
- sync mechs - almost 0
- decouple components - postpone until see if required, maybe refactor in future
- refactor + bug fixing - cell builder issue
*** standalone application - nice to have
*** transition - will become smaller
*** NetPyNE UI
netPAramsUI + simConfigUI - for chickens
*** Network support
- map geppetoo - required
- performance to load bigger models - 10k
- visualization - simplify 3 different levels
- advance - remove 
- ability to simulate large nets
- visualize results - focus on netpyne/matplotlib, and use Neuron-UI voltage trace
*** Support for parallel simulation
- run from commandline 
- maybe don't need - just use to sketch out
*** embed python UI into Geppetto
- nice to have, but not essential
*** bug fixing

** new proposal
hourly rate: $75/hr - gross 
days = estimate at 4.5hr/day
managing - 15%

- simulate large nets + visualize nets - related to mpi, reduce 
- transition from high -> instantite - room for simplification
- project - 55
- design - linear

* 17Apr13 convert to python3
** doc
https://docs.python.org/2/library/2to3.html
** command
2to3 --output-dir=python3-version/mycode -W -n python2-version/mycode
** output of 2to3
Salvador-Duras-MacBook-Pro% 2to3 --output-dir=netpyne_py3 -W -n netpyne
WARNING: --write-unchanged-files/-W implies -w.
lib2to3.main: Output in 'netpyne_py3' will mirror the input directory 'netpyne' layout.
RefactoringTool: Skipping optional fixer: buffer
RefactoringTool: Skipping optional fixer: idioms
RefactoringTool: Skipping optional fixer: set_literal
RefactoringTool: Skipping optional fixer: ws_comma
RefactoringTool: No changes to netpyne/__init__.py
RefactoringTool: Writing converted netpyne/__init__.py to netpyne_py3/__init__.py.
RefactoringTool: Refactored netpyne/analysis.py
--- netpyne/analysis.py	(original)
+++ netpyne/analysis.py	(refactored)
@@ -17,7 +17,7 @@
 from numbers import Number
 import math
 
-import sim
+from . import sim
 
 import warnings
 warnings.filterwarnings("ignore")
@@ -40,7 +40,7 @@
         sim.timing('start', 'plotTime')
 
         # Call analysis functions specified by user
-        for funcName, kwargs in sim.cfg.analysis.iteritems():
+        for funcName, kwargs in sim.cfg.analysis.items():
             if kwargs == True: kwargs = {}
             elif kwargs == False: continue
             func = getattr(sim.analysis, funcName)  # get pointer to function
@@ -50,12 +50,12 @@
         if sim.cfg.timing:
             
             sim.timing('stop', 'plotTime')
-            print('  Done; plotting time = %0.2f s' % sim.timingData['plotTime'])
+            print(('  Done; plotting time = %0.2f s' % sim.timingData['plotTime']))
             
             sim.timing('stop', 'totalTime')
-            sumTime = sum([t for k,t in sim.timingData.iteritems() if k not in ['totalTime']])
+            sumTime = sum([t for k,t in sim.timingData.items() if k not in ['totalTime']])
             if sim.timingData['totalTime'] <= 1.2*sumTime:  # Print total time (only if makes sense)         
-                print('\nTotal time = %0.2f s' % sim.timingData['totalTime'])
+                print(('\nTotal time = %0.2f s' % sim.timingData['totalTime']))
 
 
 ######################################################################################################################################################
@@ -72,22 +72,22 @@
 ## Save figure data
 ######################################################################################################################################################
 def _saveFigData(figData, fileName=None, type=''):
-    if not fileName or not isinstance(fileName, basestring):
+    if not fileName or not isinstance(fileName, str):
         fileName = sim.cfg.filename+'_'+type+'.pkl'
 
     if fileName.endswith('.pkl'): # save to pickle
         import pickle
-        print('Saving figure data as %s ... ' % (fileName))
+        print(('Saving figure data as %s ... ' % (fileName)))
         with open(fileName, 'wb') as fileObj:
             pickle.dump(figData, fileObj)
 
     elif fileName.endswith('.json'):  # save to json
         import json
-        print('Saving figure data as %s ... ' % (fileName))
+        print(('Saving figure data as %s ... ' % (fileName)))
         with open(fileName, 'w') as fileObj:
             json.dump(figData, fileObj)
     else: 
-        print 'File extension to save figure data not recognized'
+        print('File extension to save figure data not recognized')
 
 
 import numpy
@@ -129,10 +129,10 @@
     """
 
     if x.ndim != 1:
-        raise ValueError, "smooth only accepts 1 dimension arrays."
+        raise ValueError("smooth only accepts 1 dimension arrays.")
 
     if x.size < window_len:
-        raise ValueError, "Input vector needs to be bigger than window size."
+        raise ValueError("Input vector needs to be bigger than window size.")
 
 
     if window_len<3:
@@ -140,7 +140,7 @@
 
 
     if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:
-        raise ValueError, "Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'"
+        raise ValueError("Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'")
 
 
     s=numpy.r_[x[window_len-1:0:-1],x,x[-1:-window_len:-1]]
@@ -173,7 +173,7 @@
 ######################################################################################################################################################
 def getCellsInclude(include):
     allCells = sim.net.allCells
-    allNetStimLabels = sim.net.params.stimSourceParams.keys()
+    allNetStimLabels = list(sim.net.params.stimSourceParams.keys())
     cellGids = []
     cells = []
     netStimLabels = []
@@ -194,7 +194,7 @@
         elif isinstance(condition, int):  # cell gid 
             cellGids.append(condition)
         
-        elif isinstance(condition, basestring):  # entire pop
+        elif isinstance(condition, str):  # entire pop
             if condition in allNetStimLabels:
                 netStimLabels.append(condition)
             else:
@@ -260,7 +260,7 @@
     if len(cellGids) > 0:
         gidColors = {cell['gid']: popColors[cell['tags']['pop']] for cell in cells}  # dict with color for each gid
         try:
-            spkgids,spkts = zip(*[(spkgid,spkt) for spkgid,spkt in zip(sim.allSimData['spkid'],sim.allSimData['spkt']) if spkgid in cellGids])
+            spkgids,spkts = list(zip(*[(spkgid,spkt) for spkgid,spkt in zip(sim.allSimData['spkid'],sim.allSimData['spkt']) if spkgid in cellGids]))
         except:
             spkgids, spkts = [], []
         spkgidColors = [gidColors[spkgid] for spkgid in spkgids]
@@ -294,8 +294,8 @@
     numCellSpks = len(spkts)
     numNetStims = 0
     for netStimLabel in netStimLabels:
-        netStimSpks = [spk for cell,stims in sim.allSimData['stims'].iteritems() \
-            for stimLabel,stimSpks in stims.iteritems() for spk in stimSpks if stimLabel == netStimLabel]
+        netStimSpks = [spk for cell,stims in sim.allSimData['stims'].items() \
+            for stimLabel,stimSpks in stims.items() for spk in stimSpks if stimLabel == netStimLabel]
         if len(netStimSpks) > 0:
             lastInd = max(spkinds) if len(spkinds)>0 else 0
             spktsNew = netStimSpks 
@@ -314,7 +314,7 @@
         ylabelText = ylabelText + 'NetStims'
 
     if numCellSpks+numNetStims == 0:
-        print 'No spikes available to plot raster'
+        print('No spikes available to plot raster')
         return None
 
     # Time Range
@@ -323,14 +323,14 @@
     elif timeRange is None:
         timeRange = [0,sim.cfg.duration]
     else:
-        spkinds,spkts,spkgidColors = zip(*[(spkind,spkt,spkgidColor) for spkind,spkt,spkgidColor in zip(spkinds,spkts,spkgidColors) 
-        if timeRange[0] <= spkt <= timeRange[1]])
+        spkinds,spkts,spkgidColors = list(zip(*[(spkind,spkt,spkgidColor) for spkind,spkt,spkgidColor in zip(spkinds,spkts,spkgidColors) 
+        if timeRange[0] <= spkt <= timeRange[1]]))
 
     # Limit to maxSpikes
     if (len(spkts)>maxSpikes):
-        print('  Showing only the first %i out of %i spikes' % (maxSpikes, len(spkts))) # Limit num of spikes
+        print(('  Showing only the first %i out of %i spikes' % (maxSpikes, len(spkts)))) # Limit num of spikes
         if numNetStims: # sort first if have netStims
-            spkts, spkinds, spkgidColors = zip(*sorted(zip(spkts, spkinds, spkgidColors)))
+            spkts, spkinds, spkgidColors = list(zip(*sorted(zip(spkts, spkinds, spkgidColors))))
         spkts = spkts[:maxSpikes]
         spkinds = spkinds[:maxSpikes]
         spkgidColors = spkgidColors[:maxSpikes]
@@ -446,7 +446,7 @@
  
     # save figure
     if saveFig: 
-        if isinstance(saveFig, basestring):
+        if isinstance(saveFig, str):
             filename = saveFig
         else:
             filename = sim.cfg.filename+'_'+'raster.png'
@@ -499,7 +499,7 @@
     if yaxis == 'rate': yaxisLabel = 'Avg cell firing rate (Hz)'
     elif yaxis == 'count': yaxisLabel = 'Spike count'
     else:
-        print 'Invalid yaxis value %s', (yaxis)
+        print('Invalid yaxis value %s', (yaxis))
         return
 
     # time range
@@ -520,7 +520,7 @@
         # Select cells to include
         if len(cellGids) > 0:
             try:
-                spkinds,spkts = zip(*[(spkgid,spkt) for spkgid,spkt in zip(sim.allSimData['spkid'],sim.allSimData['spkt']) if spkgid in cellGids])
+                spkinds,spkts = list(zip(*[(spkgid,spkt) for spkgid,spkt in zip(sim.allSimData['spkid'],sim.allSimData['spkt']) if spkgid in cellGids]))
             except:
                 spkinds,spkts = [],[]
         else: 
@@ -531,8 +531,8 @@
         numNetStims = 0
         if 'stims' in sim.allSimData:
             for netStimLabel in netStimLabels:
-                netStimSpks = [spk for cell,stims in sim.allSimData['stims'].iteritems() \
-                for stimLabel,stimSpks in stims.iteritems() for spk in stimSpks if stimLabel == netStimLabel]
+                netStimSpks = [spk for cell,stims in sim.allSimData['stims'].items() \
+                for stimLabel,stimSpks in stims.items() for spk in stimSpks if stimLabel == netStimLabel]
                 if len(netStimSpks) > 0:
                     lastInd = max(spkinds) if len(spkinds)>0 else 0
                     spktsNew = netStimSpks 
@@ -590,7 +590,7 @@
  
     # save figure
     if saveFig: 
-        if isinstance(saveFig, basestring):
+        if isinstance(saveFig, str):
             filename = saveFig
         else:
             filename = sim.cfg.filename+'_'+'spikeHist.png'
@@ -660,7 +660,7 @@
         # Select cells to include
         if len(cellGids) > 0:
             try:
-                spkinds,spkts = zip(*[(spkgid,spkt) for spkgid,spkt in zip(sim.allSimData['spkid'],sim.allSimData['spkt']) if spkgid in cellGids])
+                spkinds,spkts = list(zip(*[(spkgid,spkt) for spkgid,spkt in zip(sim.allSimData['spkid'],sim.allSimData['spkt']) if spkgid in cellGids]))
             except:
                 spkinds,spkts = [],[]
         else: 
@@ -672,8 +672,8 @@
         numNetStims = 0
         if 'stims' in sim.allSimData:
             for netStimLabel in netStimLabels:
-                netStimSpks = [spk for cell,stims in sim.allSimData['stims'].iteritems() \
-                    for stimLabel,stimSpks in stims.iteritems() for spk in stimSpks if stimLabel == netStimLabel]
+                netStimSpks = [spk for cell,stims in sim.allSimData['stims'].items() \
+                    for stimLabel,stimSpks in stims.items() for spk in stimSpks if stimLabel == netStimLabel]
                 if len(netStimSpks) > 0:
                     lastInd = max(spkinds) if len(spkinds)>0 else 0
                     spktsNew = netStimSpks 
@@ -736,7 +736,7 @@
  
     # save figure
     if saveFig: 
-        if isinstance(saveFig, basestring):
+        if isinstance(saveFig, str):
             filename = saveFig
         else:
             filename = sim.cfg.filename+'_'+'spikePSD.png'
@@ -786,7 +786,7 @@
         sim.setupRecording()
         sim.simulate()
 
-    tracesList = sim.cfg.recordTraces.keys()
+    tracesList = list(sim.cfg.recordTraces.keys())
     tracesList.sort()
     cells, cellGids, _ = getCellsInclude(include)
     gidPops = {cell['gid']: cell['tags']['pop'] for cell in cells}
@@ -833,7 +833,7 @@
                 if 'cell_'+str(gid) in sim.allSimData[trace]:
                     fullTrace = sim.allSimData[trace]['cell_'+str(gid)]
                     if isinstance(fullTrace, dict):
-                        data = [fullTrace[key][int(timeRange[0]/recordStep):int(timeRange[1]/recordStep)] for key in fullTrace.keys()]
+                        data = [fullTrace[key][int(timeRange[0]/recordStep):int(timeRange[1]/recordStep)] for key in list(fullTrace.keys())]
                         lenData = len(data[0])
                         data = np.transpose(array(data))
                     else:
@@ -862,7 +862,7 @@
     # Plot one fig per trace for each population
     elif oneFigPer == 'popTrace':
         allPopGids = invertDictMapping(gidPops)
-        for popLabel, popGids in allPopGids.iteritems():
+        for popLabel, popGids in allPopGids.items():
             plotFigPerTrace(popGids)
 
     try:
@@ -879,12 +879,12 @@
  
     # save figure
     if saveFig: 
-        if isinstance(saveFig, basestring):
+        if isinstance(saveFig, str):
             filename = saveFig
         else:
             filename = sim.cfg.filename+'_'+'traces.png'
         if len(figs) > 1:
-            for figLabel, figObj in figs.iteritems():
+            for figLabel, figObj in figs.items():
                 plt.figure(figObj.number)
                 plt.savefig(filename[:-4]+figLabel+filename[-4:])
         else:
@@ -898,7 +898,7 @@
 def invertDictMapping(d):
     """ Invert mapping of dictionary (i.e. map values to list of keys) """
     inv_map = {}
-    for k, v in d.iteritems():
+    for k, v in d.items():
         inv_map[v] = inv_map.get(v, [])
         inv_map[v].append(k)
     return inv_map
@@ -951,7 +951,7 @@
             # weighNorm
             if cvar == 'weightNorm':
                 for cellPost in cellsPost:
-                    cellSecs = cellPost.secs.values() if includeAxon else [s for s in cellPost.secs.values() if 'axon' not in s['hSec'].hname()] 
+                    cellSecs = list(cellPost.secs.values()) if includeAxon else [s for s in list(cellPost.secs.values()) if 'axon' not in s['hSec'].hname()] 
                     for sec in cellSecs:
                         if 'weightNorm' in sec:
                             secs.append(sec['hSec'])
@@ -963,8 +963,8 @@
             # numSyns
             elif cvar == 'numSyns':
                 for cellPost in cellsPost:
-                    cellSecs = cellPost.secs if includeAxon else {k:s for k,s in cellPost.secs.iteritems() if 'axon' not in s['hSec'].hname()}
-                    for secLabel,sec in cellSecs.iteritems():
+                    cellSecs = cellPost.secs if includeAxon else {k:s for k,s in cellPost.secs.items() if 'axon' not in s['hSec'].hname()}
+                    for secLabel,sec in cellSecs.items():
                         nseg=sec['hSec'].nseg
                         nsyns = [0] * nseg
                         secs.append(sec['hSec'])
@@ -974,7 +974,7 @@
 
                 cvals = np.array(cvals)
 
-        if not secs: secs = [s['hSec'] for cellPost in cellsPost for s in cellPost.secs.values()]
+        if not secs: secs = [s['hSec'] for cellPost in cellsPost for s in list(cellPost.secs.values())]
         # if not includeAxon:         
         #     secs = [sec for sec in secs if 'axon' not in sec.hname()]
 
@@ -998,7 +998,7 @@
         if showSyns:
             synColor='red'
             for cellPost in cellsPost:
-                for sec in cellPost.secs.values():
+                for sec in list(cellPost.secs.values()):
                     for synMech in sec['synMechs']:
                         morph.mark_locations(h, sec['hSec'], synMech['loc'], markspec=synStyle, color=synColor, markersize=synSiz)
                   
@@ -1007,7 +1007,7 @@
 
         # save figure
         if saveFig: 
-            if isinstance(saveFig, basestring):
+            if isinstance(saveFig, str):
                 filename = saveFig
             else:
                 filename = sim.cfg.filename+'_shape.png'
@@ -1024,7 +1024,7 @@
             ivprops = {'colorSecs': 1, 'colorSyns':2 ,'style': '.', 'siz':10}
         
         for cell in [c for c in sim.net.cells if c.tags['pop'] in includePost]:
-            for sec in cell.secs.values():
+            for sec in list(cell.secs.values()):
                 if 'axon' in sec['hSec'].hname() and not includeAxon: continue
                 sec['hSec'].push()
                 secList.append()
@@ -1045,7 +1045,7 @@
         fig.show(0) # show real diam
             # save figure
         if saveFig: 
-            if isinstance(saveFig, basestring):
+            if isinstance(saveFig, str):
                 filename = saveFig
             else:
                 filename = sim.cfg.filename+'_'+'shape.ps'
@@ -1136,7 +1136,7 @@
     else:
         cellsPost, cellGidsPost, netStimPopsPost = getCellsInclude(includePost) 
 
-    if isinstance(synMech, basestring): synMech = [synMech]  # make sure synMech is a list
+    if isinstance(synMech, str): synMech = [synMech]  # make sure synMech is a list
     
     # Calculate matrix if grouped by cell
     if groupBy == 'cell': 
@@ -1144,7 +1144,7 @@
             connMatrix = np.zeros((len(cellGidsPre), len(cellGidsPost)))
             countMatrix = np.zeros((len(cellGidsPre), len(cellGidsPost)))
         else: 
-            print 'Conn matrix with groupBy="cell" only supports features= "weight", "delay" or "numConns"'
+            print('Conn matrix with groupBy="cell" only supports features= "weight", "delay" or "numConns"')
             return fig
         cellIndsPre = {cell['gid']: ind for ind,cell in enumerate(cellsPre)}
         cellIndsPost = {cell['gid']: ind for ind,cell in enumerate(cellsPost)}
@@ -1273,7 +1273,7 @@
     # Calculate matrix if grouped by numeric tag (eg. 'y')
     elif groupBy in sim.net.allCells[0]['tags'] and isinstance(sim.net.allCells[0]['tags'][groupBy], Number):
         if not isinstance(groupByInterval, Number):
-            print 'groupByInterval not specified'
+            print('groupByInterval not specified')
             return
   
         # group cells by 'groupBy' feature (eg. 'y') in intervals of 'groupByInterval')
@@ -1294,7 +1294,7 @@
 
 
         if len(groupsPre) < 2 or len(groupsPost) < 2: 
-            print 'groupBy %s with groupByInterval %s results in <2 groups'%(str(groupBy), str(groupByInterval))
+            print('groupBy %s with groupByInterval %s results in <2 groups'%(str(groupBy), str(groupByInterval)))
             return
         groupIndsPre = {group: ind for ind,group in enumerate(groupsPre)}
         groupIndsPost = {group: ind for ind,group in enumerate(groupsPost)}
@@ -1361,7 +1361,7 @@
 
     # no valid groupBy
     else:  
-        print 'groupBy (%s) is not valid'%(str(groupBy))
+        print('groupBy (%s) is not valid'%(str(groupBy)))
         return
 
     if groupBy != 'cell':
@@ -1418,8 +1418,8 @@
                 plt.plot(array([ipop,ipop])-0.5,array([0,len(popsPost)])-0.5,'-',c=(0.7,0.7,0.7))
 
             # Make pretty
-            h.set_xticks(range(len(popsPost)))
-            h.set_yticks(range(len(popsPre)))
+            h.set_xticks(list(range(len(popsPost))))
+            h.set_yticks(list(range(len(popsPre))))
             h.set_xticklabels(popsPost)
             h.set_yticklabels(popsPre)
             h.xaxis.set_ticks_position('top')
@@ -1463,10 +1463,10 @@
             plt.tight_layout()
 
         elif groupBy == 'cell':
-            print 'Error: plotConn graphType="bar" with groupBy="cell" not implemented'
+            print('Error: plotConn graphType="bar" with groupBy="cell" not implemented')
 
     elif graphType == 'pie':
-        print 'Error: plotConn graphType="pie" not yet implemented'
+        print('Error: plotConn graphType="pie" not yet implemented')
 
 
     #save figure data
@@ -1478,7 +1478,7 @@
  
     # save figure
     if saveFig: 
-        if isinstance(saveFig, basestring):
+        if isinstance(saveFig, str):
             filename = saveFig
         else:
             filename = sim.cfg.filename+'_'+'conn_'+feature+'.png'
@@ -1536,7 +1536,7 @@
     if showConns:
         for postCell in cells:
             for con in postCell['conns']:  # plot connections between cells
-                if not isinstance(con['preGid'], basestring) and con['preGid'] in cellGids:
+                if not isinstance(con['preGid'], str) and con['preGid'] in cellGids:
                     posXpre,posYpre = next(((cell['tags']['x'],cell['tags'][ycoord]) for cell in cells if cell['gid']==con['preGid']), None)  
                     posXpost,posYpost = postCell['tags']['x'], postCell['tags'][ycoord] 
                     color='red'
@@ -1566,7 +1566,7 @@
  
     # save figure
     if saveFig: 
-        if isinstance(saveFig, basestring):
+        if isinstance(saveFig, str):
             filename = saveFig
         else:
             filename = sim.cfg.filename+'_'+'2Dnet.png'
@@ -1603,13 +1603,13 @@
     
     if 'nte' not in dir(h): 
         try: 
-            print ' Warning: support/nte.mod not compiled; attempting to compile from %s via "nrnivmodl support"'%(root)
+            print(' Warning: support/nte.mod not compiled; attempting to compile from %s via "nrnivmodl support"'%(root))
             os.system('cd ' + root + '; nrnivmodl support')
             from neuron import load_mechanisms
             load_mechanisms(root)
-            print ' Compilation of support folder mod files successful'
+            print(' Compilation of support folder mod files successful')
         except:
-            print ' Error compiling support folder mod files'
+            print(' Error compiling support folder mod files')
             return
 
     h.load_file(root+'/support/nte.hoc') # nTE code (also requires support/net.mod)
@@ -1632,7 +1632,7 @@
         numNetStims = 0
         for netStimPop in netStimPops:
             if 'stims' in sim.allSimData:
-                cellStims = [cellStim for cell,cellStim in sim.allSimData['stims'].iteritems() if netStimPop in cellStim]
+                cellStims = [cellStim for cell,cellStim in sim.allSimData['stims'].items() if netStimPop in cellStim]
                 if len(cellStims) > 0:
                     spktsNew = [spkt for cellStim in cellStims for spkt in cellStim[netStimPop] ]
                     spkts.extend(spktsNew)
@@ -1658,7 +1658,7 @@
         numNetStims = 0
         for netStimPop in netStimPops:
             if 'stims' in sim.allSimData:
-                cellStims = [cellStim for cell,cellStim in sim.allSimData['stims'].iteritems() if netStimPop in cellStim]
+                cellStims = [cellStim for cell,cellStim in sim.allSimData['stims'].items() if netStimPop in cellStim]
                 if len(cellStims) > 0:
                     spktsNew = [spkt for cellStim in cellStims for spkt in cellStim[netStimPop] ]
                     spkts.extend(spktsNew)
@@ -1737,7 +1737,7 @@
         numNetStims = 0
         for netStimPop in netStimPops:
             if 'stims' in sim.allSimData:
-                cellStims = [cellStim for cell,cellStim in sim.allSimData['stims'].iteritems() if netStimPop in cellStim]
+                cellStims = [cellStim for cell,cellStim in sim.allSimData['stims'].items() if netStimPop in cellStim]
                 if len(cellStims) > 0:
                     spktsNew = [spkt for cellStim in cellStims for spkt in cellStim[netStimPop] ]
                     spkts.extend(spktsNew)
@@ -1763,7 +1763,7 @@
         numNetStims = 0
         for netStimPop in netStimPops:
             if 'stims' in sim.allSimData:
-                cellStims = [cellStim for cell,cellStim in sim.allSimData['stims'].iteritems() if netStimPop in cellStim]
+                cellStims = [cellStim for cell,cellStim in sim.allSimData['stims'].items() if netStimPop in cellStim]
                 if len(cellStims) > 0:
                     spktsNew = [spkt for cellStim in cellStims for spkt in cellStim[netStimPop] ]
                     spkts.extend(spktsNew)
@@ -1808,7 +1808,7 @@
      
         # save figure
         if saveFig: 
-            if isinstance(saveFig, basestring):
+            if isinstance(saveFig, str):
                 filename = saveFig
             else:
                 filename = sim.cfg.filename+'_'+'2Dnet.png'
@@ -1841,7 +1841,7 @@
         # create data matrix
         wcs = [x[-1][-1] for x in sim.allweightchanges] # absolute final weight
         wcs = [x[-1][-1]-x[0][-1] for x in sim.allweightchanges] # absolute weight change
-        pre,post,recep = zip(*[(x[0],x[1],x[2]) for x in sim.allstdpconndata])
+        pre,post,recep = list(zip(*[(x[0],x[1],x[2]) for x in sim.allstdpconndata]))
         ncells = int(max(max(pre),max(post))+1)
         wcmat = np.zeros([ncells, ncells])
 
RefactoringTool: Writing converted netpyne/analysis.py to netpyne_py3/analysis.py.
RefactoringTool: Refactored netpyne/batch.py
--- netpyne/batch.py	(original)
+++ netpyne/batch.py	(refactored)
@@ -8,7 +8,7 @@
 
 
 import datetime
-from itertools import izip, product
+from itertools import product
 from popen2 import popen2
 from time import sleep
 import imp
@@ -22,11 +22,11 @@
 def runJob(script, cfgSavePath, netParamsSavePath):
     from subprocess import Popen, PIPE
 
-    print '\nJob in rank id: ',pc.id()
+    print('\nJob in rank id: ',pc.id())
     command = 'nrniv %s simConfig=%s netParams=%s' % (script, cfgSavePath, netParamsSavePath) 
-    print command+'\n'
+    print(command+'\n')
     proc = Popen(command.split(' '), stdout=PIPE, stderr=PIPE)
-    print proc.stdout.read()
+    print(proc.stdout.read())
 
 
 class Batch(object):
@@ -40,7 +40,7 @@
         self.runCfg = {}
         self.params = []
         if params:
-            for k,v in params.iteritems():
+            for k,v in params.items():
                 self.params.append({'label': k, 'values': v})
     
     def save(self, filename):
@@ -54,14 +54,14 @@
             os.mkdir(folder)
         except OSError:
             if not os.path.exists(folder):
-                print ' Could not create', folder
+                print(' Could not create', folder)
 
         dataSave = {'batch': self.__dict__}
         if ext == 'json':
             import json
             #from json import encoder
             #encoder.FLOAT_REPR = lambda o: format(o, '.12g')
-            print('Saving batch to %s ... ' % (filename))
+            print(('Saving batch to %s ... ' % (filename)))
             with open(filename, 'w') as fileObj:
                 json.dump(dataSave, fileObj, indent=4, sort_keys=True)
 
@@ -74,7 +74,7 @@
                 os.mkdir(self.saveFolder)
             except OSError:
                 if not os.path.exists(self.saveFolder):
-                    print ' Could not create', self.saveFolder
+                    print(' Could not create', self.saveFolder)
 
             # save Batch dict as json
             targetFile = self.saveFolder+'/'+self.batchLabel+'_batch.json'
@@ -102,14 +102,14 @@
                     elif p['group'] == True: 
                         groupedParams = True
 
-                labelList, valuesList = zip(*[(p['label'], p['values']) for p in self.params if p['group'] == False])
+                labelList, valuesList = list(zip(*[(p['label'], p['values']) for p in self.params if p['group'] == False]))
                 valueCombinations = list(product(*(valuesList)))
-                indexCombinations = list(product(*[range(len(x)) for x in valuesList]))
+                indexCombinations = list(product(*[list(range(len(x))) for x in valuesList]))
 
                 if groupedParams:
-                    labelListGroup, valuesListGroup = zip(*[(p['label'], p['values']) for p in self.params if p['group'] == True])
-                    valueCombGroups = izip(*(valuesListGroup))
-                    indexCombGroups = izip(*[range(len(x)) for x in valuesListGroup])
+                    labelListGroup, valuesListGroup = list(zip(*[(p['label'], p['values']) for p in self.params if p['group'] == True]))
+                    valueCombGroups = zip(*(valuesListGroup))
+                    indexCombGroups = zip(*[list(range(len(x))) for x in valuesListGroup])
                     labelList = labelListGroup+labelList
                 else:
                     valueCombGroups = [(0,)] # this is a hack -- improve!
@@ -133,7 +133,7 @@
                         iComb = iCombNG
                         pComb = pCombNG
                     
-                    print iComb, pComb
+                    print(iComb, pComb)
 
                     for i, paramVal in enumerate(pComb):
                         paramLabel = labelList[i]
@@ -147,7 +147,7 @@
                             container[paramLabel[-1]] = paramVal
                         else:
                             setattr(self.cfg, paramLabel, paramVal) # set simConfig params
-                        print str(paramLabel)+' = '+str(paramVal)
+                        print(str(paramLabel)+' = '+str(paramVal))
                         
                     # set simLabel and jobName
                     simLabel = self.batchLabel+''.join([''.join('_'+str(i)) for i in iComb])
@@ -155,11 +155,11 @@
 
                     # skip if output file already exists
                     if self.runCfg.get('skip', False) and glob.glob(jobName+'.json'):
-                        print 'Skipping job %s since output file already exists...' % (jobName)
+                        print('Skipping job %s since output file already exists...' % (jobName))
                     elif self.runCfg.get('skipCfg', False) and glob.glob(jobName+'_cfg.json'):
-                        print 'Skipping job %s since cfg file already exists...' % (jobName)
+                        print('Skipping job %s since cfg file already exists...' % (jobName))
                     elif self.runCfg.get('skipCustom', None) and glob.glob(jobName+self.runCfg['skipCustom']):
-                        print 'Skipping job %s since %s file already exists...' % (jobName, self.runCfg['skipCustom'])
+                        print('Skipping job %s since %s file already exists...' % (jobName, self.runCfg['skipCustom']))
                     else:
                         # save simConfig json to saveFolder                        
                         self.cfg.simLabel = simLabel
@@ -199,7 +199,7 @@
 
                             # Send job_string to qsub
                             input.write(jobString)
-                            print jobString+'\n'
+                            print(jobString+'\n')
                             input.close()
 
                                                 # hpc torque job submission
@@ -239,8 +239,8 @@
                             # Send job_string to qsub
                             # output, input = popen2('sbatch') # Open a pipe to the qsub command.
                             # input.write(jobString)
-                            print 'Submitting job ',jobName
-                            print jobString+'\n'
+                            print('Submitting job ',jobName)
+                            print(jobString+'\n')
                             # input.close()
 
                             batchfile = '%s.sbatch'%(jobName)
@@ -255,7 +255,7 @@
                         # eg. usage: mpiexec -n 4 nrniv -mpi batch.py
                         elif self.runCfg.get('type',None) == 'mpi':
                             jobName = self.saveFolder+'/'+simLabel     
-                            print 'Submitting job ',jobName
+                            print('Submitting job ',jobName)
                             # master/slave bulletin board schedulling of jobs
                             pc.submit(runJob, self.runCfg.get('script', 'init.py'), cfgSavePath, netParamsSavePath)
                             
RefactoringTool: Writing converted netpyne/batch.py to netpyne_py3/batch.py.
RefactoringTool: Refactored netpyne/cell.py
--- netpyne/cell.py	(original)
+++ netpyne/cell.py	(refactored)
@@ -10,10 +10,10 @@
 from copy import deepcopy
 from time import sleep
 from neuron import h # Import NEURON
-from specs import Dict
+from .specs import Dict
 import numpy as np
 from random import seed, uniform
-import sim
+from . import sim
 
 
 ###############################################################################
@@ -89,22 +89,22 @@
             self.stims.append(Dict(params.copy()))  # add new stim to Cell object
             stimContainer = self.stims[-1]
 
-            if sim.cfg.verbose: print('  Created %s NetStim for cell gid=%d'% (params['source'], self.gid))
+            if sim.cfg.verbose: print(('  Created %s NetStim for cell gid=%d'% (params['source'], self.gid)))
         
         if sim.cfg.createNEURONObj:
             rand = h.Random()
             stimContainer['hRandom'] = rand  # add netcon object to dict in conns list
 
-            if isinstance(params['rate'], basestring):
+            if isinstance(params['rate'], str):
                 if params['rate'] == 'variable':
                     try:
                         netstim = h.NSLOC()
                         netstim.interval = 0.1**-1*1e3 # inverse of the frequency and then convert from Hz^-1 to ms (set very low)
                         netstim.noise = params['noise']
                     except:
-                        print 'Error: tried to create variable rate NetStim but NSLOC mechanism not available'
+                        print('Error: tried to create variable rate NetStim but NSLOC mechanism not available')
                 else:
-                    print 'Error: Unknown stimulation rate type: %s'%(h.params['rate'])
+                    print('Error: Unknown stimulation rate type: %s'%(h.params['rate']))
             else:
                 netstim = h.NetStim() 
                 netstim.interval = params['rate']**-1*1e3 # inverse of the frequency and then convert from Hz^-1 to ms
@@ -126,12 +126,12 @@
 
     def recordTraces (self):
         # set up voltagse recording; recdict will be taken from global context
-        for key, params in sim.cfg.recordTraces.iteritems():
+        for key, params in sim.cfg.recordTraces.items():
             
             conditionsMet = 1
             
             if 'conds' in params:
-                for (condKey,condVal) in params['conds'].iteritems():  # check if all conditions are met
+                for (condKey,condVal) in params['conds'].items():  # check if all conditions are met
                     # choose what to comapare to 
                     if condKey in ['postGid']:
                         compareTo = self.gid
@@ -143,7 +143,7 @@
                         if compareTo < condVal[0] or compareTo > condVal[1]:
                             conditionsMet = 0
                             break
-                    elif isinstance(condVal, list) and isinstance(condVal[0], basestring):
+                    elif isinstance(condVal, list) and isinstance(condVal[0], str):
                         if compareTo not in condVal:
                             conditionsMet = 0
                             break 
@@ -172,7 +172,7 @@
                         else: 
                             ptr = []
                             secLocs = []
-                            for secName,sec in self.secs.iteritems():
+                            for secName,sec in self.secs.items():
                                 synMechs = [synMech for synMech in sec['synMechs'] if synMech['label']==params['synMech']]
                                 ptr.extend([synMech['hSyn'].__getattribute__('_ref_'+params['var']) for synMech in synMechs])
                                 secLocs.extend([secName+'_'+str(synMech['loc']) for synMech in synMechs])
@@ -193,11 +193,11 @@
                         else:
                             sim.simData[key]['cell_'+str(self.gid)] = h.Vector(sim.cfg.duration/sim.cfg.recordStep+1).resize(0)
                             sim.simData[key]['cell_'+str(self.gid)].record(ptr, sim.cfg.recordStep)
-                        if sim.cfg.verbose: print '  Recording ', key, 'from cell ', self.gid, ' with parameters: ',str(params)
+                        if sim.cfg.verbose: print('  Recording ', key, 'from cell ', self.gid, ' with parameters: ',str(params))
                 except:
-                    if sim.cfg.verbose: print '  Cannot record ', key, 'from cell ', self.gid
+                    if sim.cfg.verbose: print('  Cannot record ', key, 'from cell ', self.gid)
             else:
-                if sim.cfg.verbose: print '  Conditions preclude recording ', key, ' from cell ', self.gid
+                if sim.cfg.verbose: print('  Conditions preclude recording ', key, ' from cell ', self.gid)
         #else:
         #    if sim.cfg.verbose: print '  NOT recording ', key, 'from cell ', self.gid, ' with parameters: ',str(params)
 
@@ -222,15 +222,15 @@
 
 
     def create (self):
-        for propLabel, prop in sim.net.params.cellParams.iteritems():  # for each set of cell properties
+        for propLabel, prop in sim.net.params.cellParams.items():  # for each set of cell properties
             conditionsMet = 1
-            for (condKey,condVal) in prop['conds'].iteritems():  # check if all conditions are met
+            for (condKey,condVal) in prop['conds'].items():  # check if all conditions are met
                 if isinstance(condVal, list): 
                     if isinstance(condVal[0], Number):
                         if self.tags.get(condKey) < condVal[0] or self.tags.get(condKey) > condVal[1]:
                             conditionsMet = 0
                             break
-                    elif isinstance(condVal[0], basestring):
+                    elif isinstance(condVal[0], str):
                         if self.tags.get(condKey) not in condVal:
                             conditionsMet = 0
                             break 
@@ -251,7 +251,7 @@
 
     def modify (self, prop):
         conditionsMet = 1
-        for (condKey,condVal) in prop['conds'].iteritems():  # check if all conditions are met
+        for (condKey,condVal) in prop['conds'].items():  # check if all conditions are met
             if condKey=='label':
                 if condVal not in self.tags['label']:
                     conditionsMet = 0
@@ -261,7 +261,7 @@
                     if self.tags.get(condKey) < condVal[0] or self.tags.get(condKey) > condVal[1]:
                         conditionsMet = 0
                         break
-                elif isinstance(condVal[0], basestring):
+                elif isinstance(condVal[0], str):
                     if self.tags.get(condKey) not in condVal:
                         conditionsMet = 0
                         break 
@@ -278,7 +278,7 @@
 
     def createPyStruct (self, prop):
         # set params for all sections
-        for sectName,sectParams in prop['secs'].iteritems(): 
+        for sectName,sectParams in prop['secs'].items(): 
             # create section
             if sectName not in self.secs:
                 self.secs[sectName] = Dict()  # create section dict
@@ -286,22 +286,22 @@
             
             # add distributed mechanisms 
             if 'mechs' in sectParams:
-                for mechName,mechParams in sectParams['mechs'].iteritems(): 
+                for mechName,mechParams in sectParams['mechs'].items(): 
                     if 'mechs' not in sec:
                         sec['mechs'] = Dict()
                     if mechName not in sec['mechs']: 
                         sec['mechs'][mechName] = Dict()  
-                    for mechParamName,mechParamValue in mechParams.iteritems():  # add params of the mechanism
+                    for mechParamName,mechParamValue in mechParams.items():  # add params of the mechanism
                         sec['mechs'][mechName][mechParamName] = mechParamValue
             
             # add ion info 
             if 'ions' in sectParams:
-                for ionName,ionParams in sectParams['ions'].iteritems(): 
+                for ionName,ionParams in sectParams['ions'].items(): 
                     if 'ions' not in sec:
                         sec['ions'] = Dict()
                     if ionName not in sec['ions']: 
                         sec['ions'][ionName] = Dict()  
-                    for ionParamName,ionParamValue in ionParams.iteritems():  # add params of the ion
+                    for ionParamName,ionParamValue in ionParams.items():  # add params of the ion
                         sec['ions'][ionName][ionParamName] = ionParamValue
 
 
@@ -313,19 +313,19 @@
 
             # add point processes
             if 'pointps' in sectParams:
-                for pointpName,pointpParams in sectParams['pointps'].iteritems(): 
+                for pointpName,pointpParams in sectParams['pointps'].items(): 
                     #if self.tags['cellModel'] == pointpName: # only required if want to allow setting various cell models in same rule
                     if 'pointps' not in sec:
                         sec['pointps'] = Dict()
                     if pointpName not in sec['pointps']: 
                         sec['pointps'][pointpName] = Dict()  
-                    for pointpParamName,pointpParamValue in pointpParams.iteritems():  # add params of the mechanism
+                    for pointpParamName,pointpParamValue in pointpParams.items():  # add params of the mechanism
                         sec['pointps'][pointpName][pointpParamName] = pointpParamValue
 
 
             # add geometry params 
             if 'geom' in sectParams:
-                for geomParamName,geomParamValue in sectParams['geom'].iteritems():  
+                for geomParamName,geomParamValue in sectParams['geom'].items():  
                     if 'geom' not in sec:
                         sec['geom'] = Dict()
                     if not type(geomParamValue) in [list, dict]:  # skip any list or dic params
@@ -342,7 +342,7 @@
             if 'topol' in sectParams:
                 if 'topol' not in sec:
                     sec['topol'] = Dict()
-                for topolParamName,topolParamValue in sectParams['topol'].iteritems(): 
+                for topolParamName,topolParamValue in sectParams['topol'].items(): 
                     sec['topol'][topolParamName] = topolParamValue
 
             # add other params
@@ -361,14 +361,14 @@
 
 
     def initV (self): 
-        for sec in self.secs.values():
+        for sec in list(self.secs.values()):
             if 'vinit' in sec:
                 sec['hSec'].v = sec['vinit']
 
 
     def createNEURONObj (self, prop):
         # set params for all sections
-        for sectName,sectParams in prop['secs'].iteritems(): 
+        for sectName,sectParams in prop['secs'].items(): 
             # create section
             if sectName not in self.secs:
                 self.secs[sectName] = Dict()  # create sect dict if doesn't exist
@@ -378,7 +378,7 @@
 
             # set geometry params 
             if 'geom' in sectParams:
-                for geomParamName,geomParamValue in sectParams['geom'].iteritems():  
+                for geomParamName,geomParamValue in sectParams['geom'].items():  
                     if not type(geomParamValue) in [list, dict]:  # skip any list or dic params
                         setattr(sec['hSec'], geomParamName, geomParamValue)
 
@@ -393,11 +393,11 @@
 
             # add distributed mechanisms 
             if 'mechs' in sectParams:
-                for mechName,mechParams in sectParams['mechs'].iteritems(): 
+                for mechName,mechParams in sectParams['mechs'].items(): 
                     if mechName not in sec['mechs']: 
                         sec['mechs'][mechName] = Dict()
                     sec['hSec'].insert(mechName)
-                    for mechParamName,mechParamValue in mechParams.iteritems():  # add params of the mechanism
+                    for mechParamName,mechParamValue in mechParams.items():  # add params of the mechanism
                         mechParamValueFinal = mechParamValue
                         for iseg,seg in enumerate(sec['hSec']):  # set mech params for each segment
                             if type(mechParamValue) in [list]: 
@@ -407,11 +407,11 @@
                             
             # add ions
             if 'ions' in sectParams:
-                for ionName,ionParams in sectParams['ions'].iteritems(): 
+                for ionName,ionParams in sectParams['ions'].items(): 
                     if ionName not in sec['ions']: 
                         sec['ions'][ionName] = Dict()
                     sec['hSec'].insert(ionName+'_ion')    # insert mechanism
-                    for ionParamName,ionParamValue in ionParams.iteritems():  # add params of the mechanism
+                    for ionParamName,ionParamValue in ionParams.items():  # add params of the mechanism
                         ionParamValueFinal = ionParamValue
                         for iseg,seg in enumerate(sec['hSec']):  # set ion params for each segment
                             if type(ionParamValue) in [list]: 
@@ -436,20 +436,20 @@
 
             # add point processes
             if 'pointps' in sectParams:
-                for pointpName,pointpParams in sectParams['pointps'].iteritems(): 
+                for pointpName,pointpParams in sectParams['pointps'].items(): 
                     #if self.tags['cellModel'] == pointpParams:  # only required if want to allow setting various cell models in same rule
                     if pointpName not in sec['pointps']:
                         sec['pointps'][pointpName] = Dict() 
                     pointpObj = getattr(h, pointpParams['mod'])
                     loc = pointpParams['loc'] if 'loc' in pointpParams else 0.5  # set location
                     sec['pointps'][pointpName]['hPointp'] = pointpObj(loc, sec = sec['hSec'])  # create h Pointp object (eg. h.Izhi2007b)
-                    for pointpParamName,pointpParamValue in pointpParams.iteritems():  # add params of the point process
+                    for pointpParamName,pointpParamValue in pointpParams.items():  # add params of the point process
                         if pointpParamName not in ['mod', 'loc', 'vref', 'synList'] and not pointpParamName.startswith('_'):
                             setattr(sec['pointps'][pointpName]['hPointp'], pointpParamName, pointpParamValue)
 
 
         # set topology 
-        for sectName,sectParams in prop['secs'].iteritems():  # iterate sects again for topology (ensures all exist)
+        for sectName,sectParams in prop['secs'].items():  # iterate sects again for topology (ensures all exist)
             sec = self.secs[sectName]  # pointer to section # pointer to child sec
             if 'topol' in sectParams:
                 if sectParams['topol']:
@@ -458,7 +458,7 @@
 
     def addSynMechsNEURONObj(self):
         # set params for all sections
-        for sectName,sectParams in self.secs.iteritems(): 
+        for sectName,sectParams in self.secs.items(): 
             # add synMechs (only used when loading)
             if 'synMechs' in sectParams:
                 for synMech in sectParams['synMechs']:
@@ -475,8 +475,8 @@
        
             elif stimParams['type'] in ['IClamp', 'VClamp', 'SEClamp', 'AlphaSynapse']:
                 stim = getattr(h, stimParams['type'])(self.secs[stimParams['sec']]['hSec'](stimParams['loc']))
-                stimProps = {k:v for k,v in stimParams.iteritems() if k not in ['label', 'type', 'source', 'loc', 'sec', 'h'+stimParams['type']]}
-                for stimPropName, stimPropValue in stimProps.iteritems(): # set mechanism internal stimParams
+                stimProps = {k:v for k,v in stimParams.items() if k not in ['label', 'type', 'source', 'loc', 'sec', 'h'+stimParams['type']]}
+                for stimPropName, stimPropValue in stimProps.items(): # set mechanism internal stimParams
                     if isinstance(stimPropValue, list):
                         if stimPropName == 'amp': 
                             for i,val in enumerate(stimPropValue):
@@ -504,9 +504,9 @@
             try:
                 postTarget = synMech['hSyn']
             except:
-                print '\nError: no synMech available for conn: ', conn
-                print ' cell tags: ',self.tags
-                print ' cell synMechs: ',self.secs[conn['sec']]['synMechs']
+                print('\nError: no synMech available for conn: ', conn)
+                print(' cell tags: ',self.tags)
+                print(' cell synMechs: ',self.secs[conn['sec']]['synMechs'])
                 exit()
 
             # create NetCon
@@ -533,15 +533,15 @@
         if self.secs:
             if sim.cfg.createNEURONObj: 
                 sim.pc.set_gid2node(self.gid, sim.rank) # this is the key call that assigns cell gid to a particular node
-                sec = next((secParams for secName,secParams in self.secs.iteritems() if 'spikeGenLoc' in secParams), None) # check if any section has been specified as spike generator
+                sec = next((secParams for secName,secParams in self.secs.items() if 'spikeGenLoc' in secParams), None) # check if any section has been specified as spike generator
                 if sec:
                     loc = sec['spikeGenLoc']  # get location of spike generator within section
                 else:
-                    sec = self.secs['soma'] if 'soma' in self.secs else self.secs[self.secs.keys()[0]]  # use soma if exists, otherwise 1st section
+                    sec = self.secs['soma'] if 'soma' in self.secs else self.secs[list(self.secs.keys())[0]]  # use soma if exists, otherwise 1st section
                     loc = 0.5
                 nc = None
                 if 'pointps' in sec:  # if no syns, check if point processes with 'vref' (artificial cell)
-                    for pointpName, pointpParams in sec['pointps'].iteritems():
+                    for pointpName, pointpParams in sec['pointps'].items():
                         if 'vref' in pointpParams:
                             nc = h.NetCon(sec['pointps'][pointpName]['hPointp'].__getattribute__('_ref_'+pointpParams['vref']), None, sec=sec['hSec'])
                             break
@@ -567,7 +567,7 @@
                 synMech = next((synMech for synMech in sec['synMechs'] if synMech['label']==synLabel and synMech['loc']==loc), None)
                 if not synMech:  # if synMech not in section, then create
                     synMech = Dict({'label': synLabel, 'loc': loc})
-                    for paramName, paramValue in synMechParams.iteritems():
+                    for paramName, paramValue in synMechParams.items():
                         synMech[paramName] = paramValue
                     sec['synMechs'].append(synMech)
             else:
@@ -583,7 +583,7 @@
                 if not synMech.get('hSyn'):  # if synMech doesn't have NEURON obj, then create
                     synObj = getattr(h, synMechParams['mod'])
                     synMech['hSyn'] = synObj(loc, sec=sec['hSec'])  # create h Syn object (eg. h.Exp2Syn)
-                    for synParamName,synParamValue in synMechParams.iteritems():  # add params of the synaptic mechanism
+                    for synParamName,synParamValue in synMechParams.items():  # add params of the synaptic mechanism
                         if synParamName not in ['label', 'mod', 'selfNetCon', 'loc']:
                             setattr(synMech['hSyn'], synParamName, synParamValue)
                         elif synParamName == 'selfNetcon':  # create self netcon required for some synapses (eg. homeostatic)
@@ -591,7 +591,7 @@
                             locNetCon = synParamValue.get('loc', 0.5)
                             secNetCon = self.secs.get(secLabelNetCon, None)
                             synMech['hNetcon'] = h.NetCon(secNetCon['hSec'](locNetCon)._ref_v, synMech[''], sec=secNetCon['hSec'])
-                            for paramName,paramValue in synParamValue.iteritems():
+                            for paramName,paramValue in synParamValue.items():
                                 if paramName == 'weight':
                                     synMech['hNetcon'].weight[0] = paramValue
                                 elif paramName not in ['sec', 'loc']:
@@ -605,7 +605,7 @@
         conditionsMet = 1
         if 'cellConds' in params:
             if conditionsMet:
-                for (condKey,condVal) in params['cellConds'].iteritems():  # check if all conditions are met
+                for (condKey,condVal) in params['cellConds'].items():  # check if all conditions are met
                     # check if conditions met
                     if isinstance(condVal, list):
                         if self.tags.get(condKey) < condVal[0] or self.tags.get(condKey) > condVal[1]:
@@ -616,11 +616,11 @@
                         break
 
         if conditionsMet:
-            for secLabel,sec in self.secs.iteritems():
+            for secLabel,sec in self.secs.items():
                 for synMech in sec['synMechs']:
                     conditionsMet = 1
                     if 'conds' in params:
-                        for (condKey,condVal) in params['conds'].iteritems():  # check if all conditions are met
+                        for (condKey,condVal) in params['conds'].items():  # check if all conditions are met
                             # check if conditions met
                             if condKey == 'sec':
                                 if condVal != secLabel:
@@ -630,7 +630,7 @@
                                 if synMech.get(condKey) < condVal[0] or synMech.get(condKey) > condVal[1]:
                                     conditionsMet = 0
                                     break
-                            elif isinstance(condVal, list) and isinstance(condVal[0], basestring):
+                            elif isinstance(condVal, list) and isinstance(condVal[0], str):
                                 if synMech.get(condKey) not in condVal:
                                     conditionsMet = 0
                                     break 
@@ -640,14 +640,14 @@
 
                     if conditionsMet:  # if all conditions are met, set values for this cell
                         exclude = ['conds', 'cellConds', 'label', 'mod', 'selfNetCon', 'loc']
-                        for synParamName,synParamValue in {k: v for k,v in params.iteritems() if k not in exclude}.iteritems():
+                        for synParamName,synParamValue in {k: v for k,v in params.items() if k not in exclude}.items():
                             if sim.cfg.createPyStruct: 
                                 synMech[synParamName] = synParamValue
                             if sim.cfg.createNEURONObj:
                                 try: 
                                     setattr(synMech['hSyn'], synParamName, synParamValue)
                                 except:
-                                    print 'Error setting %s=%s on synMech' % (synParamName, str(synParamValue))
+                                    print('Error setting %s=%s on synMech' % (synParamName, str(synParamValue)))
     
 
 
@@ -661,7 +661,7 @@
 
         # Avoid self connections
         if params['preGid'] == self.gid:
-            if sim.cfg.verbose: print '  Error: attempted to create self-connection on cell gid=%d, section=%s '%(self.gid, params.get('sec'))
+            if sim.cfg.verbose: print('  Error: attempted to create self-connection on cell gid=%d, section=%s '%(self.gid, params.get('sec')))
             return  # if self-connection return
 
         # Get list of section labels
@@ -718,7 +718,7 @@
 
             # Python Structure
             if sim.cfg.createPyStruct:
-                connParams = {k:v for k,v in params.iteritems() if k not in ['synsPerConn']} 
+                connParams = {k:v for k,v in params.items() if k not in ['synsPerConn']} 
                 connParams['weight'] = weights[i]
                 connParams['delay'] = delays[i]
                 if not pointp:
@@ -790,7 +790,7 @@
                         switchtimes.append(sim.cfg.duration)
                     
                     switchiter = iter(switchtimes)
-                    switchpairs = zip(switchiter,switchiter)
+                    switchpairs = list(zip(switchiter,switchiter))
                     for pair in switchpairs:
                         # Note: Cliff's makestim code is in seconds, so conversions from ms to s occurs in the args.
                         stimvecs = self._shapeStim(width=float(pulsewidth)/1000.0, isi=float(pulseperiod)/1000.0, weight=params['weight'], start=float(pair[0])/1000.0, finish=float(pair[1])/1000.0, stimshape=pulsetype)
@@ -809,8 +809,8 @@
                 sec = params['sec'] if pointp else synMechSecs[i]
                 loc = params['loc'] if pointp else synMechLocs[i]
                 preGid = netStimParams['source']+' NetStim' if netStimParams else params['preGid']
-                print('  Created connection preGid=%s, postGid=%s, sec=%s, loc=%.4g, synMech=%s, weight=%.4g, delay=%.2f, threshold=%s'%
-                    (preGid, self.gid, sec, loc, params['synMech'], weights[i], delays[i], threshold))
+                print(('  Created connection preGid=%s, postGid=%s, sec=%s, loc=%.4g, synMech=%s, weight=%.4g, delay=%.2f, threshold=%s'%
+                    (preGid, self.gid, sec, loc, params['synMech'], weights[i], delays[i], threshold)))
 
 
     def modifyConns (self, params):
@@ -818,7 +818,7 @@
             conditionsMet = 1
             
             if 'conds' in params:
-                for (condKey,condVal) in params['conds'].iteritems():  # check if all conditions are met
+                for (condKey,condVal) in params['conds'].items():  # check if all conditions are met
                     # choose what to comapare to 
                     if condKey in ['postGid']:
                         compareTo = self.gid
@@ -830,7 +830,7 @@
                         if compareTo < condVal[0] or compareTo > condVal[1]:
                             conditionsMet = 0
                             break
-                    elif isinstance(condVal, list) and isinstance(condVal[0], basestring):
+                    elif isinstance(condVal, list) and isinstance(condVal[0], str):
                         if compareTo not in condVal:
                             conditionsMet = 0
                             break 
@@ -839,13 +839,13 @@
                         break
 
             if conditionsMet and 'postConds' in params:
-                for (condKey,condVal) in params['postConds'].iteritems():  # check if all conditions are met
+                for (condKey,condVal) in params['postConds'].items():  # check if all conditions are met
                     # check if conditions met
                     if isinstance(condVal, list) and isinstance(condVal[0], Number):
                         if self.tags.get(condKey) < condVal[0] or self.tags.get(condKey) > condVal[1]:
                             conditionsMet = 0
                             break
-                    elif isinstance(condVal, list) and isinstance(condVal[0], basestring):
+                    elif isinstance(condVal, list) and isinstance(condVal[0], str):
                         if self.tags.get(condKey) not in condVal:
                             conditionsMet = 0
                             break 
@@ -854,28 +854,28 @@
                         break
 
             if conditionsMet and 'preConds' in params: 
-                print 'Warning: modifyConns() does not yet support conditions of presynaptic cells'
+                print('Warning: modifyConns() does not yet support conditions of presynaptic cells')
 
             if conditionsMet:  # if all conditions are met, set values for this cell
                 if sim.cfg.createPyStruct:
-                    for paramName, paramValue in {k: v for k,v in params.iteritems() if k not in ['conds','preConds','postConds']}.iteritems():
+                    for paramName, paramValue in {k: v for k,v in params.items() if k not in ['conds','preConds','postConds']}.items():
                         conn[paramName] = paramValue
                 if sim.cfg.createNEURONObj:
-                    for paramName, paramValue in {k: v for k,v in params.iteritems() if k not in ['conds','preConds','postConds']}.iteritems():
+                    for paramName, paramValue in {k: v for k,v in params.items() if k not in ['conds','preConds','postConds']}.items():
                         try:
                             if paramName == 'weight':
                                 conn['hNetcon'].weight[0] = paramValue
                             else:
                                 setattr(conn['hNetcon'], paramName, paramValue)
                         except:
-                            print 'Error setting %s=%s on Netcon' % (paramName, str(paramValue))
+                            print('Error setting %s=%s on Netcon' % (paramName, str(paramValue)))
 
 
     def modifyStims (self, params):
         conditionsMet = 1
         if 'cellConds' in params:
             if conditionsMet:
-                for (condKey,condVal) in params['cellConds'].iteritems():  # check if all conditions are met
+                for (condKey,condVal) in params['cellConds'].items():  # check if all conditions are met
                     # check if conditions met
                     if isinstance(condVal, list):
                         if self.tags.get(condKey) < condVal[0] or self.tags.get(condKey) > condVal[1]:
@@ -890,13 +890,13 @@
                 conditionsMet = 1
 
                 if 'conds' in params:
-                    for (condKey,condVal) in params['conds'].iteritems():  # check if all conditions are met
+                    for (condKey,condVal) in params['conds'].items():  # check if all conditions are met
                         # check if conditions met
                         if isinstance(condVal, list) and isinstance(condVal[0], Number):
                             if stim.get(condKey) < condVal[0] or stim.get(condKey) > condVal[1]:
                                 conditionsMet = 0
                                 break
-                        elif isinstance(condVal, list) and isinstance(condVal[0], basestring):
+                        elif isinstance(condVal, list) and isinstance(condVal[0], str):
                             if stim.get(condKey) not in condVal:
                                 conditionsMet = 0
                                 break 
@@ -908,13 +908,13 @@
                     if stim['type'] == 'NetStim':  # for netstims, find associated netcon
                         conn = next((conn for conn in self.conns if conn['source'] == stim['source']), None)
                     if sim.cfg.createPyStruct:
-                        for paramName, paramValue in {k: v for k,v in params.iteritems() if k not in ['conds','cellConds']}.iteritems():
+                        for paramName, paramValue in {k: v for k,v in params.items() if k not in ['conds','cellConds']}.items():
                             if stim['type'] == 'NetStim' and paramName in ['weight', 'delay', 'threshold']:
                                 conn[paramName] = paramValue
                             else:
                                 stim[paramName] = paramValue
                     if sim.cfg.createNEURONObj:
-                        for paramName, paramValue in {k: v for k,v in params.iteritems() if k not in ['conds','cellConds']}.iteritems():
+                        for paramName, paramValue in {k: v for k,v in params.items() if k not in ['conds','cellConds']}.items():
                             try:
                                 if stim['type'] == 'NetStim':
                                     if paramName == 'weight':
@@ -924,19 +924,19 @@
                                 else:
                                     setattr(stim['h'+stim['type']], paramName, paramValue)
                             except:
-                                print 'Error setting %s=%s on stim' % (paramName, str(paramValue))
+                                print('Error setting %s=%s on stim' % (paramName, str(paramValue)))
 
 
 
     def addStim (self, params):
-        if not params['sec'] or (isinstance(params['sec'], basestring) and not params['sec'] in self.secs.keys()+self.secLists.keys()):  
-            if sim.cfg.verbose: print '  Warning: no valid sec specified for stim on cell gid=%d so using soma or 1st available. Existing secs: %s; params: %s'%(self.gid, self.secs.keys(),params)
+        if not params['sec'] or (isinstance(params['sec'], str) and not params['sec'] in list(self.secs.keys())+list(self.secLists.keys())):  
+            if sim.cfg.verbose: print('  Warning: no valid sec specified for stim on cell gid=%d so using soma or 1st available. Existing secs: %s; params: %s'%(self.gid, list(self.secs.keys()),params))
             if 'soma' in self.secs:  
                 params['sec'] = 'soma'  # use 'soma' if exists
             elif self.secs:  
-                params['sec'] = self.secs.keys()[0]  # if no 'soma', use first sectiona available
+                params['sec'] = list(self.secs.keys())[0]  # if no 'soma', use first sectiona available
             else:  
-                if sim.cfg.verbose: print '  Error: no Section available on cell gid=%d to add stim'%(self.gid)
+                if sim.cfg.verbose: print('  Error: no Section available on cell gid=%d to add stim'%(self.gid))
                 return 
 
         sec = self.secs[params['sec']]
@@ -972,9 +972,9 @@
 
         elif params['type'] in ['IClamp', 'VClamp', 'SEClamp', 'AlphaSynapse']:
             stim = getattr(h, params['type'])(sec['hSec'](params['loc']))
-            stimParams = {k:v for k,v in params.iteritems() if k not in ['type', 'source', 'loc', 'sec', 'label']}
+            stimParams = {k:v for k,v in params.items() if k not in ['type', 'source', 'loc', 'sec', 'label']}
             stringParams = ''
-            for stimParamName, stimParamValue in stimParams.iteritems(): # set mechanism internal params
+            for stimParamName, stimParamValue in stimParams.items(): # set mechanism internal params
                 if isinstance(stimParamValue, list):
                     if stimParamName == 'amp': 
                         for i,val in enumerate(stimParamValue):
@@ -989,21 +989,21 @@
             self.stims.append(Dict(params)) # add to python structure
             self.stims[-1]['h'+params['type']] = stim  # add stim object to dict in stims list
 
-            if sim.cfg.verbose: print('  Added %s %s to cell gid=%d, sec=%s, loc=%.4g%s'%
-                (params['source'], params['type'], self.gid, params['sec'], params['loc'], stringParams))
+            if sim.cfg.verbose: print(('  Added %s %s to cell gid=%d, sec=%s, loc=%.4g%s'%
+                (params['source'], params['type'], self.gid, params['sec'], params['loc'], stringParams)))
                 
         else:
-            if sim.cfg.verbose: print('Adding exotic stim (NeuroML 2 based?): %s'% params)   
+            if sim.cfg.verbose: print(('Adding exotic stim (NeuroML 2 based?): %s'% params))   
             stim = getattr(h, params['type'])(sec['hSec'](params['loc']))
-            stimParams = {k:v for k,v in params.iteritems() if k not in ['type', 'source', 'loc', 'sec', 'label']}
+            stimParams = {k:v for k,v in params.items() if k not in ['type', 'source', 'loc', 'sec', 'label']}
             stringParams = ''
-            for stimParamName, stimParamValue in stimParams.iteritems(): # set mechanism internal params
+            for stimParamName, stimParamValue in stimParams.items(): # set mechanism internal params
                 if isinstance(stimParamValue, list):
-                    print "Can't set point process paramaters of type vector eg. VClamp.amp[3]"
+                    print("Can't set point process paramaters of type vector eg. VClamp.amp[3]")
                     pass
                     #setattr(stim, stimParamName._ref_[0], stimParamValue[0])
                 elif 'originalFormat' in params:
-                    if sim.cfg.verbose: print('   originalFormat: %s'%(params['originalFormat']))
+                    if sim.cfg.verbose: print(('   originalFormat: %s'%(params['originalFormat'])))
                     if params['originalFormat']=='NeuroML2_stochastic_input':
                         rand = h.Random()
                         rand.Random123(params['stim_count'], sim.id32('%d'%(sim.cfg.seeds['stim'])))
@@ -1017,20 +1017,20 @@
                     stringParams = stringParams + ', ' + stimParamName +'='+ str(stimParamValue)
             self.stims.append(params) # add to python structure
             self.stims[-1]['h'+params['type']] = stim  # add stim object to dict in stims list
-            if sim.cfg.verbose: print('  Added %s %s to cell gid=%d, sec=%s, loc=%.4g%s'%
-                (params['source'], params['type'], self.gid, params['sec'], params['loc'], stringParams))
+            if sim.cfg.verbose: print(('  Added %s %s to cell gid=%d, sec=%s, loc=%.4g%s'%
+                (params['source'], params['type'], self.gid, params['sec'], params['loc'], stringParams)))
 
 
     def _setConnSections (self, params):
         # if no section specified or single section specified does not exist
-        if not params.get('sec') or (isinstance(params.get('sec'), basestring) and not params.get('sec') in self.secs.keys()+self.secLists.keys()):  
-            if sim.cfg.verbose: print '  Warning: no valid sec specified for connection to cell gid=%d so using soma or 1st available'%(self.gid)
+        if not params.get('sec') or (isinstance(params.get('sec'), str) and not params.get('sec') in list(self.secs.keys())+list(self.secLists.keys())):  
+            if sim.cfg.verbose: print('  Warning: no valid sec specified for connection to cell gid=%d so using soma or 1st available'%(self.gid))
             if 'soma' in self.secs:  
                 params['sec'] = 'soma'  # use 'soma' if exists
             elif self.secs:  
-                params['sec'] = self.secs.keys()[0]  # if no 'soma', use first sectiona available
+                params['sec'] = list(self.secs.keys())[0]  # if no 'soma', use first sectiona available
             else:  
-                if sim.cfg.verbose: print '  Error: no Section available on cell gid=%d to add connection'%(self.gid)
+                if sim.cfg.verbose: print('  Error: no Section available on cell gid=%d to add connection'%(self.gid))
                 sec = -1  # if no Sections available print error and exit
                 return sec
 
@@ -1042,7 +1042,7 @@
             secLabels = []
             for i,section in enumerate(secList): 
                 if section not in self.secs: # remove sections that dont exist; and corresponding weight and delay 
-                    if sim.cfg.verbose: print '  Error: Section %s not available so removing from list of sections for connection to cell gid=%d'%(self.gid)
+                    if sim.cfg.verbose: print('  Error: Section %s not available so removing from list of sections for connection to cell gid=%d'%(self.gid))
                     secList.remove(section)
                     if isinstance(params['weight'], list): params['weight'].remove(params['weight'][i])
                     if isinstance(params['delay'], list): params['delay'].remove(params['delay'][i])
@@ -1077,7 +1077,7 @@
         # Find if any point process with V not calculated in section (artifical cell, eg. Izhi2007a)
         pointp = None
         if len(secLabels)==1 and 'pointps' in self.secs[secLabels[0]]:  #  check if point processes with 'vref' (artificial cell)
-            for pointpName, pointpParams in self.secs[secLabels[0]]['pointps'].iteritems():
+            for pointpName, pointpParams in self.secs[secLabels[0]]['pointps'].items():
                 if 'vref' in pointpParams:  # if includes vref param means doesn't use Section v or synaptic mechanisms
                     pointp = pointpName
                     if 'synList' in pointpParams:
@@ -1088,7 +1088,7 @@
                                 weightIndex = pointpParams['synList'].index(params.get('synMech'))  # udpate weight index based pointp synList
 
         if pointp and params['synsPerConn'] > 1: # only single synapse per connection rule allowed
-            if sim.cfg.verbose: print '  Error: Multiple synapses per connection rule not allowed for cells where V is not in section (cell gid=%d) '%(self.gid)
+            if sim.cfg.verbose: print('  Error: Multiple synapses per connection rule not allowed for cells where V is not in section (cell gid=%d) '%(self.gid))
             return -1, weightIndex
 
         return pointp, weightIndex
@@ -1098,11 +1098,11 @@
         synsPerConn = params['synsPerConn']
         if not params.get('synMech'):
             if sim.net.params.synMechParams:  # if no synMech specified, but some synMech params defined
-                synLabel = sim.net.params.synMechParams.keys()[0]  # select first synMech from net params and add syn
+                synLabel = list(sim.net.params.synMechParams.keys())[0]  # select first synMech from net params and add syn
                 params['synMech'] = synLabel
-                if sim.cfg.verbose: print '  Warning: no synaptic mechanisms specified for connection to cell gid=%d so using %s '%(self.gid, synLabel)
+                if sim.cfg.verbose: print('  Warning: no synaptic mechanisms specified for connection to cell gid=%d so using %s '%(self.gid, synLabel))
             else: # if no synaptic mechanism specified and no synMech params available 
-                if sim.cfg.verbose: print '  Error: no synaptic mechanisms available to add conn on cell gid=%d '%(self.gid)
+                if sim.cfg.verbose: print('  Error: no synaptic mechanisms available to add conn on cell gid=%d '%(self.gid))
                 return -1  # if no Synapse available print error and exit
 
         # if desired synaptic mechanism specified in conn params
@@ -1134,7 +1134,7 @@
         else:
             secLengths = [1.0 for s in secList]
             if sim.cfg.verbose: 
-                print('  Section lengths not available to distribute synapses in cell %d'%self.gid)
+                print(('  Section lengths not available to distribute synapses in cell %d'%self.gid))
             
         try:
             totLength = sum(secLengths)
@@ -1153,7 +1153,7 @@
         if plasticity and sim.cfg.createNEURONObj:
             try:
                 plastMech = getattr(h, plasticity['mech'], None)(0, sec=sec['hSec'])  # create plasticity mechanism (eg. h.STDP)
-                for plastParamName,plastParamValue in plasticity['params'].iteritems():  # add params of the plasticity mechanism
+                for plastParamName,plastParamValue in plasticity['params'].items():  # add params of the plasticity mechanism
                     setattr(plastMech, plastParamName, plastParamValue)
                 if plasticity['mech'] == 'STDP':  # specific implementation steps required for the STDP mech
                     precon = sim.pc.gid_connect(params['preGid'], plastMech); precon.weight[0] = 1 # Send presynaptic spikes to the STDP adjuster
@@ -1166,7 +1166,7 @@
                     self.conns[-1]['STDPdata']      = {'preGid':params['preGid'], 'postGid': self.gid, 'receptor': weightIndex} # Not used; FYI only; store here just so it's all in one place
                     if sim.cfg.verbose: print('  Added STDP plasticity to synaptic mechanism')
             except:
-                print 'Error: exception when adding plasticity using %s mechanism' % (plasticity['mech'])
+                print('Error: exception when adding plasticity using %s mechanism' % (plasticity['mech']))
 
 
 
@@ -1199,7 +1199,7 @@
         try:
             self.hPointp = getattr(h, self.tags['cellModel'])()
         except:
-            print "Error creating point process mechanism %s in cell with gid %d" % (self.tags['cellModel'], self.gid)
+            print("Error creating point process mechanism %s in cell with gid %d" % (self.tags['cellModel'], self.gid))
             return 
 
         # if rate is list with 2 items generate random value from uniform distribution
@@ -1208,8 +1208,8 @@
             self.params['rate'] = uniform(self.params['rate'][0], self.params['rate'][1])
  
         # set pointp params - for PointCells these are stored in self.params
-        params = {k: v for k,v in self.params.iteritems()}
-        for paramName, paramValue in params.iteritems():
+        params = {k: v for k,v in self.params.items()}
+        for paramName, paramValue in params.items():
             try:
                 if paramName == 'rate':
                     self.params['interval'] = 1000.0/paramValue
@@ -1289,7 +1289,7 @@
                     spkTimes = np.cumsum(fixedInterval + negexpInterval) + (start - interval*(1-noise))
 
                 else:
-                    print '\nError: VecStim num spks per cell > %d' % (maxReproducibleSpks)
+                    print('\nError: VecStim num spks per cell > %d' % (maxReproducibleSpks))
                     import sys
                     sys.exit() 
 
@@ -1303,12 +1303,12 @@
                     elif 'rate' in pulse:
                         interval = 1000/pulse['rate']
                     else:
-                        print 'Error: Vecstim pulse missing "rate" or "interval" parameter'
+                        print('Error: Vecstim pulse missing "rate" or "interval" parameter')
                         return
 
                     # check start,end and noise params
                     if any([x not in pulse for x in ['start', 'end']]):  
-                        print 'Error: Vecstim pulse missing "start" and/or "end" parameter'
+                        print('Error: Vecstim pulse missing "start" and/or "end" parameter')
                         return
                     else:
                         noise = pulse['noise'] if 'noise' in pulse else 0.0
@@ -1396,7 +1396,7 @@
 
         # Avoid self connections
         if params['preGid'] == self.gid:
-            if sim.cfg.verbose: print '  Error: attempted to create self-connection on cell gid=%d, section=%s '%(self.gid, params.get('sec'))
+            if sim.cfg.verbose: print('  Error: attempted to create self-connection on cell gid=%d, section=%s '%(self.gid, params.get('sec')))
             return  # if self-connection return
 
         # Weight
@@ -1417,7 +1417,7 @@
 
             # Python Structure
             if sim.cfg.createPyStruct:
-                connParams = {k:v for k,v in params.iteritems() if k not in ['synsPerConn']} 
+                connParams = {k:v for k,v in params.items() if k not in ['synsPerConn']} 
                 connParams['weight'] = weights[i]
                 connParams['delay'] = delays[i]
                 if netStimParams:
@@ -1465,7 +1465,7 @@
                         switchtimes.append(sim.cfg.duration)
                     
                     switchiter = iter(switchtimes)
-                    switchpairs = zip(switchiter,switchiter)
+                    switchpairs = list(zip(switchiter,switchiter))
                     for pair in switchpairs:
                         # Note: Cliff's makestim code is in seconds, so conversions from ms to s occurs in the args.
                         stimvecs = self._shapeStim(width=float(pulsewidth)/1000.0, isi=float(pulseperiod)/1000.0, weight=params['weight'], start=float(pair[0])/1000.0, finish=float(pair[1])/1000.0, stimshape=pulsetype)
@@ -1481,8 +1481,8 @@
                 sec = params['sec']
                 loc = params['loc']
                 preGid = netStimParams['source']+' NetStim' if netStimParams else params['preGid']
-                print('  Created connection preGid=%s, postGid=%s, sec=%s, loc=%.4g, synMech=%s, weight=%.4g, delay=%.2f, threshold=%s'%
-                    (preGid, self.gid, sec, loc, params['synMech'], weights[i], delays[i],params['threshold']))
+                print(('  Created connection preGid=%s, postGid=%s, sec=%s, loc=%.4g, synMech=%s, weight=%.4g, delay=%.2f, threshold=%s'%
+                    (preGid, self.gid, sec, loc, params['synMech'], weights[i], delays[i],params['threshold'])))
 
 
     def initV (self):
@@ -1493,7 +1493,7 @@
             try: 
                 name(*args,**kwargs)
             except:
-                print "Error: Function '%s' not yet implemented for Point Neurons" % name
+                print("Error: Function '%s' not yet implemented for Point Neurons" % name)
         return wrapper
 
     # def modify (self):
RefactoringTool: Writing converted netpyne/cell.py to netpyne_py3/cell.py.
RefactoringTool: Refactored netpyne/network.py
--- netpyne/network.py	(original)
+++ netpyne/network.py	(refactored)
@@ -12,9 +12,9 @@
 from time import time, sleep
 from numbers import Number
 from copy import copy
-from specs import ODict
+from .specs import ODict
 from neuron import h  # import NEURON
-import sim
+from . import sim
 
 
 class Network (object):
@@ -51,7 +51,7 @@
     # Instantiate network populations (objects of class 'Pop')
     ###############################################################################
     def createPops (self):
-        for popLabel, popParam in self.params.popParams.iteritems(): # for each set of population paramseters 
+        for popLabel, popParam in self.params.popParams.items(): # for each set of population paramseters 
             self.pops[popLabel] = sim.Pop(popLabel, popParam)  # instantiate a new object of class Pop and add to list pop
         return self.pops
 
@@ -63,17 +63,17 @@
         sim.pc.barrier()
         sim.timing('start', 'createTime')
         if sim.rank==0: 
-            print("\nCreating network of %i cell populations on %i hosts..." % (len(self.pops), sim.nhosts)) 
+            print(("\nCreating network of %i cell populations on %i hosts..." % (len(self.pops), sim.nhosts))) 
         
-        for ipop in self.pops.values(): # For each pop instantiate the network cells (objects of class 'Cell')
+        for ipop in list(self.pops.values()): # For each pop instantiate the network cells (objects of class 'Cell')
             newCells = ipop.createCells() # create cells for this pop using Pop method
             self.cells.extend(newCells)  # add to list of cells
             sim.pc.barrier()
-            if sim.rank==0 and sim.cfg.verbose: print('Instantiated %d cells of population %s'%(len(newCells), ipop.tags['pop']))    
-        print('  Number of cells on node %i: %i ' % (sim.rank,len(self.cells))) 
+            if sim.rank==0 and sim.cfg.verbose: print(('Instantiated %d cells of population %s'%(len(newCells), ipop.tags['pop'])))    
+        print(('  Number of cells on node %i: %i ' % (sim.rank,len(self.cells)))) 
         sim.pc.barrier()
         sim.timing('stop', 'createTime')
-        if sim.rank == 0 and sim.cfg.timing: print('  Done; cell creation time = %0.2f s.' % sim.timingData['createTime'])
+        if sim.rank == 0 and sim.cfg.timing: print(('  Done; cell creation time = %0.2f s.' % sim.timingData['createTime']))
 
         return self.cells
     
@@ -94,28 +94,28 @@
 
             sources = self.params.stimSourceParams
 
-            for targetLabel, target in self.params.stimTargetParams.iteritems():  # for each target parameter set
+            for targetLabel, target in self.params.stimTargetParams.items():  # for each target parameter set
                 if 'sec' not in target: target['sec'] = None  # if section not specified, make None (will be assigned to first section in cell)
                 if 'loc' not in target: target['loc'] = None  # if location not specified, make None 
                 
                 source = sources.get(target['source'])
 
                 postCellsTags = allCellTags
-                for condKey,condValue in target['conds'].iteritems():  # Find subset of cells that match postsyn criteria
+                for condKey,condValue in target['conds'].items():  # Find subset of cells that match postsyn criteria
                     if condKey in ['x','y','z','xnorm','ynorm','znorm']:
-                        postCellsTags = {gid: tags for (gid,tags) in postCellsTags.iteritems() if condValue[0] <= tags.get(condKey, None) < condValue[1]}  # dict with post Cell objects}  # dict with pre cell tags
+                        postCellsTags = {gid: tags for (gid,tags) in postCellsTags.items() if condValue[0] <= tags.get(condKey, None) < condValue[1]}  # dict with post Cell objects}  # dict with pre cell tags
                     elif condKey == 'cellList':
                         pass
                     elif isinstance(condValue, list): 
-                        postCellsTags = {gid: tags for (gid,tags) in postCellsTags.iteritems() if tags.get(condKey, None) in condValue}  # dict with post Cell objects
+                        postCellsTags = {gid: tags for (gid,tags) in postCellsTags.items() if tags.get(condKey, None) in condValue}  # dict with post Cell objects
                     else:
-                        postCellsTags = {gid: tags for (gid,tags) in postCellsTags.iteritems() if tags.get(condKey, None) == condValue}  # dict with post Cell objects
+                        postCellsTags = {gid: tags for (gid,tags) in postCellsTags.items() if tags.get(condKey, None) == condValue}  # dict with post Cell objects
                 
                 # subset of cells from selected pops (by relative indices)                     
                 if 'cellList' in target['conds']:
                     orderedPostGids = sorted(postCellsTags.keys())
                     gidList = [orderedPostGids[i] for i in target['conds']['cellList']]
-                    postCellsTags = {gid: tags for (gid,tags) in postCellsTags.iteritems() if gid in gidList}
+                    postCellsTags = {gid: tags for (gid,tags) in postCellsTags.items() if gid in gidList}
 
                 # calculate params if string-based funcs
                 strParams = self._stimStrToFunc(postCellsTags, source, target)
@@ -143,10 +143,10 @@
 
                         postCell.addStim(params)  # call cell method to add connections
 
-        print('  Number of stims on node %i: %i ' % (sim.rank, sum([len(cell.stims) for cell in self.cells])))
+        print(('  Number of stims on node %i: %i ' % (sim.rank, sum([len(cell.stims) for cell in self.cells]))))
         sim.pc.barrier()
         sim.timing('stop', 'stimsTime')
-        if sim.rank == 0 and sim.cfg.timing: print('  Done; cell stims creation time = %0.2f s.' % sim.timingData['stimsTime'])
+        if sim.rank == 0 and sim.cfg.timing: print(('  Done; cell stims creation time = %0.2f s.' % sim.timingData['stimsTime']))
 
         return [cell.stims for cell in self.cells]
 
@@ -173,7 +173,7 @@
         dictVars['post_znorm']  = lambda postConds: postConds['znorm'] 
          
         # add netParams variables
-        for k,v in self.params.__dict__.iteritems():
+        for k,v in self.params.__dict__.items():
             if isinstance(v, Number):
                 dictVars[k] = v
 
@@ -181,7 +181,7 @@
         strParams = {}
         for paramStrFunc in paramsStrFunc:
             strFunc = params[paramStrFunc]  # string containing function
-            strVars = [var for var in dictVars.keys() if var in strFunc and var+'norm' not in strFunc]  # get list of variables used (eg. post_ynorm or dist_xyz)
+            strVars = [var for var in list(dictVars.keys()) if var in strFunc and var+'norm' not in strFunc]  # get list of variables used (eg. post_ynorm or dist_xyz)
             lambdaStr = 'lambda ' + ','.join(strVars) +': ' + strFunc # convert to lambda function 
             lambdaFunc = eval(lambdaStr)
 
@@ -190,11 +190,11 @@
             params[paramStrFunc+'FuncVars'] = {strVar: dictVars[strVar] for strVar in strVars} 
  
             # initialize randomizer in case used in function
-            seed(sim.id32('%d'%(sim.cfg.seeds['conn']+postCellsTags.keys()[0])))
+            seed(sim.id32('%d'%(sim.cfg.seeds['conn']+list(postCellsTags.keys())[0])))
 
             # replace lambda function (with args as dict of lambda funcs) with list of values
-            strParams[paramStrFunc+'List'] = {postGid: params[paramStrFunc+'Func'](**{k:v if isinstance(v, Number) else v(postCellTags) for k,v in params[paramStrFunc+'FuncVars'].iteritems()})  
-                    for postGid,postCellTags in postCellsTags.iteritems()}
+            strParams[paramStrFunc+'List'] = {postGid: params[paramStrFunc+'Func'](**{k:v if isinstance(v, Number) else v(postCellTags) for k,v in params[paramStrFunc+'FuncVars'].items()})  
+                    for postGid,postCellTags in postCellsTags.items()}
 
         return strParams
 
@@ -218,7 +218,7 @@
             if h.arc3d(ii) >= s:
                 b = ii
                 break
-        if b == -1: print "an error occurred in pointFromLoc, SOMETHING IS NOT RIGHT"
+        if b == -1: print("an error occurred in pointFromLoc, SOMETHING IS NOT RIGHT")
 
         if h.arc3d(b) == s:  # shortcut
             x, y, z = h.x3d(b), h.y3d(b), h.z3d(b)
@@ -256,7 +256,7 @@
                     sigma_x2_y2 = gridSigma[i2][j2]
 
                     if x1 == x2 or y1 == y2: 
-                        print "ERROR in closest grid points: ", secName, x1, x2, y1, y2
+                        print("ERROR in closest grid points: ", secName, x1, x2, y1, y2)
                     else:
                        # bilinear interpolation, see http://en.wikipedia.org/wiki/Bilinear_interpolation (fixed bug from Ben Suter's code)
                        sigma = ((sigma_x1_y1*abs(x2-x)*abs(y2-y) + sigma_x2_y1*abs(x-x1)*abs(y2-y) + sigma_x1_y2*abs(x2-x)*abs(y-y1) + sigma_x2_y2*abs(x-x1)*abs(y-y1))/(abs(x2-x1)*abs(y2-y1)))
@@ -272,7 +272,7 @@
                     sigma_y2 = gridSigma[j2]
 
                     if y1 == y2: 
-                        print "ERROR in closest grid points: ", secName, y1, y2
+                        print("ERROR in closest grid points: ", secName, y1, y2)
                     else:
                        # linear interpolation, see http://en.wikipedia.org/wiki/Bilinear_interpolation
                        sigma = ((sigma_y1*abs(y2-y) + sigma_y2*abs(y-y1)) / abs(y2-y1))
@@ -290,7 +290,7 @@
         sim.timing('start', 'subConnectTime')
         print('  Distributing synapses based on subcellular connectivity rules...')
 
-        for subConnParamTemp in self.params.subConnParams.values():  # for each conn rule or parameter set
+        for subConnParamTemp in list(self.params.subConnParams.values()):  # for each conn rule or parameter set
             subConnParam = subConnParamTemp.copy()
 
             # find list of pre and post cell
@@ -302,7 +302,7 @@
                     if postCellGid in self.lid2gid:
                         postCell = self.cells[self.gid2lid[postCellGid]] 
                         allConns = [conn for conn in postCell.conns if conn['preGid'] in preCellsTags]
-                        if 'NetStim' in [x['cellModel'] for x in preCellsTags.values()]: # temporary fix to include netstim conns 
+                        if 'NetStim' in [x['cellModel'] for x in list(preCellsTags.values())]: # temporary fix to include netstim conns 
                             allConns.extend([conn for conn in postCell.conns if conn['preGid'] == 'NetStim'])
 
                         # group synMechs so they are not distributed separately
@@ -321,7 +321,7 @@
                                                 connGroup['synMech'] = '__grouped__'+connGroup['synMech']
                                                 connsGroup[iConn] = connGroup
                                             except:
-                                                print '  Warning: Grouped synMechs %s not found' % (str(connGroup))
+                                                print('  Warning: Grouped synMechs %s not found' % (str(connGroup)))
                         else:
                             conns = allConns
 
@@ -356,7 +356,7 @@
                             elif subConnParam['density']['type'] == '1Dmap': # 1D
                                 segNumSyn = self._interpolateSegmentSigma(postCell, secList, None, gridY, gridSigma) # move method to Cell!
 
-                            totSyn = sum([sum(nsyn) for nsyn in segNumSyn.values()])  # summed density
+                            totSyn = sum([sum(nsyn) for nsyn in list(segNumSyn.values())])  # summed density
                             scaleNumSyn = float(len(conns))/float(totSyn) if totSyn>0 else 0.0  
                             diffList = []
                             for sec in segNumSyn: 
@@ -368,7 +368,7 @@
                                     if diff > 0:
                                         diffList.append([diff,sec,seg])
 
-                            totSynRescale = sum([sum(nsyn) for nsyn in segNumSyn.values()])
+                            totSynRescale = sum([sum(nsyn) for nsyn in list(segNumSyn.values())])
 
                             # if missing syns due to rescaling to 0, find top values which were rounded to 0 and make 1
                             if totSynRescale < len(conns):  
@@ -389,7 +389,7 @@
                             subConnParam['density']['gridValues'] = list(subConnParam['density']['gridValues']) 
 
                             newSecs, newLocs = [], []
-                            for sec, nsyns in segNumSyn.iteritems():
+                            for sec, nsyns in segNumSyn.items():
                                 for i, seg in enumerate(postCell.secs[sec]['hSec']):
                                     for isyn in range(nsyns[i]):
                                         newSecs.append(sec)
@@ -401,10 +401,10 @@
                             # find origin section 
                             if 'soma' in postCell.secs: 
                                 secOrig = 'soma' 
-                            elif any([secName.startswith('som') for secName in postCell.secs.keys()]):
-                                secOrig = next(secName for secName in postCell.secs.keys() if secName.startswith('soma'))
+                            elif any([secName.startswith('som') for secName in list(postCell.secs.keys())]):
+                                secOrig = next(secName for secName in list(postCell.secs.keys()) if secName.startswith('soma'))
                             else: 
-                                secOrig = postCell.secs.keys()[0]
+                                secOrig = list(postCell.secs.keys())[0]
 
                             #print self.fromtodistance(postCell.secs[secOrig](0.5), postCell.secs['secs'][conn['sec']](conn['loc']))
 
@@ -455,7 +455,7 @@
             sim.cfg.createNEURONObj = False
             sim.cfg.addSynMechs = False
 
-        for connParamLabel,connParamTemp in self.params.connParams.iteritems():  # for each conn rule or parameter set
+        for connParamLabel,connParamTemp in self.params.connParams.items():  # for each conn rule or parameter set
             connParam = connParamTemp.copy()
             connParam['label'] = connParamLabel
 
@@ -496,12 +496,12 @@
         nodeSynapses = sum([len(cell.conns) for cell in sim.net.cells]) 
         nodeConnections = sum([len(set([conn['preGid'] for conn in cell.conns])) for cell in sim.net.cells])   
 
-        print('  Number of connections on node %i: %i ' % (sim.rank, nodeConnections))
+        print(('  Number of connections on node %i: %i ' % (sim.rank, nodeConnections)))
         if nodeSynapses != nodeConnections:
-            print('  Number of synaptic contacts on node %i: %i ' % (sim.rank, nodeSynapses))
+            print(('  Number of synaptic contacts on node %i: %i ' % (sim.rank, nodeSynapses)))
         sim.pc.barrier()
         sim.timing('stop', 'connectTime')
-        if sim.rank == 0 and sim.cfg.timing: print('  Done; cell connection time = %0.2f s.' % sim.timingData['connectTime'])
+        if sim.rank == 0 and sim.cfg.timing: print(('  Done; cell connection time = %0.2f s.' % sim.timingData['connectTime']))
 
         return [cell.conns for cell in self.cells]
 
@@ -512,17 +512,17 @@
     def _findCellsCondition(self, allCellTags, conds):
         try: 
             cellsTags = dict(allCellTags)
-            for condKey,condValue in conds.iteritems():  # Find subset of cells that match presyn criteria
+            for condKey,condValue in conds.items():  # Find subset of cells that match presyn criteria
                 if condKey in ['x','y','z','xnorm','ynorm','znorm']:
-                    cellsTags = {gid: tags for (gid,tags) in cellsTags.iteritems() if condValue[0] <= tags.get(condKey, None) < condValue[1]}  # dict with pre cell tags
+                    cellsTags = {gid: tags for (gid,tags) in cellsTags.items() if condValue[0] <= tags.get(condKey, None) < condValue[1]}  # dict with pre cell tags
                     prePops = {}
                 else:
                     if isinstance(condValue, list): 
-                        cellsTags = {gid: tags for (gid,tags) in cellsTags.iteritems() if tags.get(condKey, None) in condValue}  # dict with pre cell tags
-                        prePops = {i: tags for (i,tags) in prePops.iteritems() if (condKey in tags) and (tags.get(condKey, None) in condValue)}
+                        cellsTags = {gid: tags for (gid,tags) in cellsTags.items() if tags.get(condKey, None) in condValue}  # dict with pre cell tags
+                        prePops = {i: tags for (i,tags) in prePops.items() if (condKey in tags) and (tags.get(condKey, None) in condValue)}
                     else:
-                        cellsTags = {gid: tags for (gid,tags) in cellsTags.iteritems() if tags.get(condKey, None) == condValue}  # dict with pre cell tags
-                        prePops = {i: tags for (i,tags) in prePops.iteritems() if (condKey in tags) and (tags.get(condKey, None) == condValue)}
+                        cellsTags = {gid: tags for (gid,tags) in cellsTags.items() if tags.get(condKey, None) == condValue}  # dict with pre cell tags
+                        prePops = {i: tags for (i,tags) in prePops.items() if (condKey in tags) and (tags.get(condKey, None) == condValue)}
         except: 
             return None
 
@@ -537,16 +537,16 @@
         preCellsTags = dict(allCellTags)  # initialize with all presyn cells (make copy)
         postCellsTags = None
 
-        for condKey,condValue in preConds.iteritems():  # Find subset of cells that match presyn criteria
+        for condKey,condValue in preConds.items():  # Find subset of cells that match presyn criteria
             if condKey in ['x','y','z','xnorm','ynorm','znorm']:
-                preCellsTags = {gid: tags for (gid,tags) in preCellsTags.iteritems() if condValue[0] <= tags.get(condKey, None) < condValue[1]}  # dict with pre cell tags
+                preCellsTags = {gid: tags for (gid,tags) in preCellsTags.items() if condValue[0] <= tags.get(condKey, None) < condValue[1]}  # dict with pre cell tags
                 #prePops = {}
             else:
                 if isinstance(condValue, list): 
-                    preCellsTags = {gid: tags for (gid,tags) in preCellsTags.iteritems() if tags.get(condKey, None) in condValue}  # dict with pre cell tags
+                    preCellsTags = {gid: tags for (gid,tags) in preCellsTags.items() if tags.get(condKey, None) in condValue}  # dict with pre cell tags
                     #prePops = {i: tags for (i,tags) in prePops.iteritems() if (condKey in tags) and (tags.get(condKey, None) in condValue)}
                 else:
-                    preCellsTags = {gid: tags for (gid,tags) in preCellsTags.iteritems() if tags.get(condKey, None) == condValue}  # dict with pre cell tags
+                    preCellsTags = {gid: tags for (gid,tags) in preCellsTags.items() if tags.get(condKey, None) == condValue}  # dict with pre cell tags
                     #prePops = {i: tags for (i,tags) in prePops.iteritems() if (condKey in tags) and (tags.get(condKey, None) == condValue)}
 
         # if not preCellsTags: # if no presyn cells, check if netstim
@@ -558,13 +558,13 @@
 
         if preCellsTags:  # only check post if there are pre
             postCellsTags = allCellTags
-            for condKey,condValue in postConds.iteritems():  # Find subset of cells that match postsyn criteria
+            for condKey,condValue in postConds.items():  # Find subset of cells that match postsyn criteria
                 if condKey in ['x','y','z','xnorm','ynorm','znorm']:
-                    postCellsTags = {gid: tags for (gid,tags) in postCellsTags.iteritems() if condValue[0] <= tags.get(condKey, None) < condValue[1]}  # dict with post Cell objects}  # dict with pre cell tags
+                    postCellsTags = {gid: tags for (gid,tags) in postCellsTags.items() if condValue[0] <= tags.get(condKey, None) < condValue[1]}  # dict with post Cell objects}  # dict with pre cell tags
                 elif isinstance(condValue, list): 
-                    postCellsTags = {gid: tags for (gid,tags) in postCellsTags.iteritems() if tags.get(condKey, None) in condValue}  # dict with post Cell objects
+                    postCellsTags = {gid: tags for (gid,tags) in postCellsTags.items() if tags.get(condKey, None) in condValue}  # dict with post Cell objects
                 else:
-                    postCellsTags = {gid: tags for (gid,tags) in postCellsTags.iteritems() if tags.get(condKey, None) == condValue}  # dict with post Cell objects
+                    postCellsTags = {gid: tags for (gid,tags) in postCellsTags.items() if tags.get(condKey, None) == condValue}  # dict with post Cell objects
         #except:
         #   return None, None
 
@@ -610,14 +610,14 @@
                                 sqrt(preConds['znorm'] - postConds['znorm']))
         
         # add netParams variables
-        for k,v in self.params.__dict__.iteritems():
+        for k,v in self.params.__dict__.items():
             if isinstance(v, Number):
                 dictVars[k] = v
 
         # for each parameter containing a function, calculate lambda function and arguments
         for paramStrFunc in paramsStrFunc:
             strFunc = connParam[paramStrFunc]  # string containing function
-            strVars = [var for var in dictVars.keys() if var in strFunc and var+'norm' not in strFunc]  # get list of variables used (eg. post_ynorm or dist_xyz)
+            strVars = [var for var in list(dictVars.keys()) if var in strFunc and var+'norm' not in strFunc]  # get list of variables used (eg. post_ynorm or dist_xyz)
             lambdaStr = 'lambda ' + ','.join(strVars) +': ' + strFunc # convert to lambda function 
             lambdaFunc = eval(lambdaStr)
        
@@ -628,19 +628,19 @@
                 # replace function with dict of values derived from function (one per pre+post cell)
                 connParam[paramStrFunc+'Func'] = {(preGid,postGid): lambdaFunc(
                     **{strVar: dictVars[strVar] if isinstance(dictVars[strVar], Number) else dictVars[strVar](preCellTags, postCellTags) for strVar in strVars})  
-                    for preGid,preCellTags in preCellsTags.iteritems() for postGid,postCellTags in postCellsTags.iteritems()}
+                    for preGid,preCellTags in preCellsTags.items() for postGid,postCellTags in postCellsTags.items()}
 
             elif paramStrFunc in ['convergence']:
                 # replace function with dict of values derived from function (one per post cell)
                 connParam[paramStrFunc+'Func'] = {postGid: lambdaFunc(
                     **{strVar: dictVars[strVar] if isinstance(dictVars[strVar], Number) else dictVars[strVar](None, postCellTags) for strVar in strVars}) 
-                    for postGid,postCellTags in postCellsTags.iteritems()}
+                    for postGid,postCellTags in postCellsTags.items()}
 
             elif paramStrFunc in ['divergence']:
                 # replace function with dict of values derived from function (one per post cell)
                 connParam[paramStrFunc+'Func'] = {preGid: lambdaFunc(
                     **{strVar: dictVars[strVar] if isinstance(dictVars[strVar], Number) else dictVars[strVar](preCellTags, None) for strVar in strVars}) 
-                    for preGid, preCellTags in preCellsTags.iteritems()}
+                    for preGid, preCellTags in preCellsTags.items()}
 
             else:
                 # store lambda function and func vars in connParam (for weight, delay and synsPerConn since only calculated for certain conns)
@@ -653,20 +653,20 @@
     ###############################################################################
     def fullConn (self, preCellsTags, postCellsTags, connParam):
         ''' Generates connections between all pre and post-syn cells '''
-        if sim.cfg.verbose: print 'Generating set of all-to-all connections (rule: %s) ...' % (connParam['label'])
+        if sim.cfg.verbose: print('Generating set of all-to-all connections (rule: %s) ...' % (connParam['label']))
 
         # get list of params that have a lambda function
         paramsStrFunc = [param for param in [p+'Func' for p in self.connStringFuncParams] if param in connParam] 
 
         for paramStrFunc in paramsStrFunc:
             # replace lambda function (with args as dict of lambda funcs) with list of values
-            seed(sim.id32('%d'%(sim.cfg.seeds['conn']+preCellsTags.keys()[0]+postCellsTags.keys()[0])))
-            connParam[paramStrFunc[:-4]+'List'] = {(preGid,postGid): connParam[paramStrFunc](**{k:v if isinstance(v, Number) else v(preCellTags,postCellTags) for k,v in connParam[paramStrFunc+'Vars'].iteritems()})  
-                for preGid,preCellTags in preCellsTags.iteritems() for postGid,postCellTags in postCellsTags.iteritems()}
+            seed(sim.id32('%d'%(sim.cfg.seeds['conn']+list(preCellsTags.keys())[0]+list(postCellsTags.keys())[0])))
+            connParam[paramStrFunc[:-4]+'List'] = {(preGid,postGid): connParam[paramStrFunc](**{k:v if isinstance(v, Number) else v(preCellTags,postCellTags) for k,v in connParam[paramStrFunc+'Vars'].items()})  
+                for preGid,preCellTags in preCellsTags.items() for postGid,postCellTags in postCellsTags.items()}
         
         for postCellGid in postCellsTags:  # for each postsyn cell
             if postCellGid in self.lid2gid:  # check if postsyn is in this node's list of gids
-                for preCellGid, preCellTags in preCellsTags.iteritems():  # for each presyn cell
+                for preCellGid, preCellTags in preCellsTags.items():  # for each presyn cell
                     self._addCellConn(connParam, preCellGid, postCellGid) # add connection
 
 
@@ -675,21 +675,21 @@
     ###############################################################################
     def probConn (self, preCellsTags, postCellsTags, connParam):
         ''' Generates connections between all pre and post-syn cells based on probability values'''
-        if sim.cfg.verbose: print 'Generating set of probabilistic connections (rule: %s) ...' % (connParam['label'])
-
-        seed(sim.id32('%d'%(sim.cfg.seeds['conn']+preCellsTags.keys()[-1]+postCellsTags.keys()[-1])))  
+        if sim.cfg.verbose: print('Generating set of probabilistic connections (rule: %s) ...' % (connParam['label']))
+
+        seed(sim.id32('%d'%(sim.cfg.seeds['conn']+list(preCellsTags.keys())[-1]+list(postCellsTags.keys())[-1])))  
         allRands = {(preGid,postGid): random() for preGid in preCellsTags for postGid in postCellsTags}  # Create an array of random numbers for checking each connection
 
         # get list of params that have a lambda function
         paramsStrFunc = [param for param in [p+'Func' for p in self.connStringFuncParams] if param in connParam] 
 
-        for postCellGid,postCellTags in postCellsTags.iteritems():  # for each postsyn cell
+        for postCellGid,postCellTags in postCellsTags.items():  # for each postsyn cell
             if postCellGid in self.lid2gid:  # check if postsyn is in this node
-                for preCellGid, preCellTags in preCellsTags.iteritems():  # for each presyn cell
+                for preCellGid, preCellTags in preCellsTags.items():  # for each presyn cell
                     probability = connParam['probabilityFunc'][preCellGid,postCellGid] if 'probabilityFunc' in connParam else connParam['probability']
                     
                     for paramStrFunc in paramsStrFunc: # call lambda functions to get weight func args
-                        connParam[paramStrFunc+'Args'] = {k:v if isinstance(v, Number) else v(preCellTags,postCellTags) for k,v in connParam[paramStrFunc+'Vars'].iteritems()}  
+                        connParam[paramStrFunc+'Args'] = {k:v if isinstance(v, Number) else v(preCellTags,postCellTags) for k,v in connParam[paramStrFunc+'Vars'].items()}  
                   
                     if probability >= allRands[preCellGid,postCellGid]:      
                         seed(sim.id32('%d'%(sim.cfg.seeds['conn']+postCellGid+preCellGid)))  
@@ -701,22 +701,22 @@
     ###############################################################################
     def convConn (self, preCellsTags, postCellsTags, connParam):
         ''' Generates connections between all pre and post-syn cells based on probability values'''
-        if sim.cfg.verbose: print 'Generating set of convergent connections (rule: %s) ...' % (connParam['label'])
+        if sim.cfg.verbose: print('Generating set of convergent connections (rule: %s) ...' % (connParam['label']))
                
         # get list of params that have a lambda function
         paramsStrFunc = [param for param in [p+'Func' for p in self.connStringFuncParams] if param in connParam] 
 
-        for postCellGid,postCellTags in postCellsTags.iteritems():  # for each postsyn cell
+        for postCellGid,postCellTags in postCellsTags.items():  # for each postsyn cell
             if postCellGid in self.lid2gid:  # check if postsyn is in this node
                 convergence = connParam['convergenceFunc'][postCellGid] if 'convergenceFunc' in connParam else connParam['convergence']  # num of presyn conns / postsyn cell
                 convergence = max(min(int(round(convergence)), len(preCellsTags)), 0)
                 seed(sim.id32('%d'%(sim.cfg.seeds['conn']+postCellGid)))  
-                preCellsSample = sample(preCellsTags.keys(), convergence)  # selected gids of presyn cells
-                preCellsConv = {k:v for k,v in preCellsTags.iteritems() if k in preCellsSample}  # dict of selected presyn cells tags
-                for preCellGid, preCellTags in preCellsConv.iteritems():  # for each presyn cell
+                preCellsSample = sample(list(preCellsTags.keys()), convergence)  # selected gids of presyn cells
+                preCellsConv = {k:v for k,v in preCellsTags.items() if k in preCellsSample}  # dict of selected presyn cells tags
+                for preCellGid, preCellTags in preCellsConv.items():  # for each presyn cell
              
                     for paramStrFunc in paramsStrFunc: # call lambda functions to get weight func args
-                        connParam[paramStrFunc+'Args'] = {k:v if isinstance(v, Number) else v(preCellTags,postCellTags) for k,v in connParam[paramStrFunc+'Vars'].iteritems()}  
+                        connParam[paramStrFunc+'Args'] = {k:v if isinstance(v, Number) else v(preCellTags,postCellTags) for k,v in connParam[paramStrFunc+'Vars'].items()}  
         
                     seed(sim.id32('%d'%(sim.cfg.seeds['conn']+postCellGid+preCellGid)))  
                     if preCellGid != postCellGid: # if not self-connection   
@@ -728,21 +728,21 @@
     ###############################################################################
     def divConn (self, preCellsTags, postCellsTags, connParam):
         ''' Generates connections between all pre and post-syn cells based on probability values'''
-        if sim.cfg.verbose: print 'Generating set of divergent connections (rule: %s) ...' % (connParam['label'])
+        if sim.cfg.verbose: print('Generating set of divergent connections (rule: %s) ...' % (connParam['label']))
          
         # get list of params that have a lambda function
         paramsStrFunc = [param for param in [p+'Func' for p in self.connStringFuncParams] if param in connParam] 
 
-        for preCellGid, preCellTags in preCellsTags.iteritems():  # for each presyn cell
+        for preCellGid, preCellTags in preCellsTags.items():  # for each presyn cell
             divergence = connParam['divergenceFunc'][preCellGid] if 'divergenceFunc' in connParam else connParam['divergence']  # num of presyn conns / postsyn cell
             divergence = max(min(int(round(divergence)), len(postCellsTags)), 0)
             seed(sim.id32('%d'%(sim.cfg.seeds['conn']+preCellGid)))  
             postCellsSample = sample(postCellsTags, divergence)  # selected gids of postsyn cells
-            postCellsDiv = {postGid:postConds  for postGid,postConds in postCellsTags.iteritems() if postGid in postCellsSample and postGid in self.lid2gid}  # dict of selected postsyn cells tags
-            for postCellGid, postCellTags in postCellsDiv.iteritems():  # for each postsyn cell
+            postCellsDiv = {postGid:postConds  for postGid,postConds in postCellsTags.items() if postGid in postCellsSample and postGid in self.lid2gid}  # dict of selected postsyn cells tags
+            for postCellGid, postCellTags in postCellsDiv.items():  # for each postsyn cell
                 
                 for paramStrFunc in paramsStrFunc: # call lambda functions to get weight func args
-                    connParam[paramStrFunc+'Args'] = {k:v if isinstance(v, Number) else v(preCellTags,postCellTags) for k,v in connParam[paramStrFunc+'Vars'].iteritems()}  
+                    connParam[paramStrFunc+'Args'] = {k:v if isinstance(v, Number) else v(preCellTags,postCellTags) for k,v in connParam[paramStrFunc+'Vars'].items()}  
  
                 seed(sim.id32('%d'%(sim.cfg.seeds['conn']+postCellGid+preCellGid)))            
                 if preCellGid != postCellGid: # if not self-connection
@@ -754,15 +754,15 @@
     ###############################################################################
     def fromListConn (self, preCellsTags, postCellsTags, connParam):
         ''' Generates connections between all pre and post-syn cells based list of relative cell ids'''
-        if sim.cfg.verbose: print 'Generating set of connections from list (rule: %s) ...' % (connParam['label'])
+        if sim.cfg.verbose: print('Generating set of connections from list (rule: %s) ...' % (connParam['label']))
 
         # list of params that can have a lambda function
         paramsStrFunc = [param for param in [p+'Func' for p in self.connStringFuncParams] if param in connParam] 
         for paramStrFunc in paramsStrFunc:
             # replace lambda function (with args as dict of lambda funcs) with list of values
-            seed(sim.id32('%d'%(sim.cfg.seeds['conn']+preCellsTags.keys()[0]+postCellsTags.keys()[0])))
-            connParam[paramStrFunc[:-4]+'List'] = {(preGid,postGid): connParam[paramStrFunc](**{k:v if isinstance(v, Number) else v(preCellTags,postCellTags) for k,v in connParam[paramStrFunc+'Vars'].iteritems()})  
-                    for preGid,preCellTags in preCellsTags.iteritems() for postGid,postCellTags in postCellsTags.iteritems()}
+            seed(sim.id32('%d'%(sim.cfg.seeds['conn']+list(preCellsTags.keys())[0]+list(postCellsTags.keys())[0])))
+            connParam[paramStrFunc[:-4]+'List'] = {(preGid,postGid): connParam[paramStrFunc](**{k:v if isinstance(v, Number) else v(preCellTags,postCellTags) for k,v in connParam[paramStrFunc+'Vars'].items()})  
+                    for preGid,preCellTags in preCellsTags.items() for postGid,postCellTags in postCellsTags.items()}
 
         if isinstance(connParam['weight'], list): connParam['weightFromList'] = list(connParam['weight'])  # if weight is a list, copy to weightFromList
         if isinstance(connParam['delay'], list): connParam['delayFromList'] = list(connParam['delay'])  # if delay is a list, copy to delayFromList
@@ -851,7 +851,7 @@
             sim._gatherCells()  # update allCells
 
         sim.timing('stop', 'modifyCellsTime')
-        if sim.rank == 0 and sim.cfg.timing: print('  Done; cells modification time = %0.2f s.' % sim.timingData['modifyCellsTime'])
+        if sim.rank == 0 and sim.cfg.timing: print(('  Done; cells modification time = %0.2f s.' % sim.timingData['modifyCellsTime']))
 
 
     ###############################################################################
@@ -870,7 +870,7 @@
              sim._gatherCells()  # update allCells
 
         sim.timing('stop', 'modifySynMechsTime')
-        if sim.rank == 0 and sim.cfg.timing: print('  Done; syn mechs modification time = %0.2f s.' % sim.timingData['modifySynMechsTime'])
+        if sim.rank == 0 and sim.cfg.timing: print(('  Done; syn mechs modification time = %0.2f s.' % sim.timingData['modifySynMechsTime']))
 
 
 
@@ -890,7 +890,7 @@
             sim._gatherCells()  # update allCells
 
         sim.timing('stop', 'modifyConnsTime')
-        if sim.rank == 0 and sim.cfg.timing: print('  Done; connections modification time = %0.2f s.' % sim.timingData['modifyConnsTime'])
+        if sim.rank == 0 and sim.cfg.timing: print(('  Done; connections modification time = %0.2f s.' % sim.timingData['modifyConnsTime']))
 
 
     ###############################################################################
@@ -909,9 +909,9 @@
             sim._gatherCells()  # update allCells
 
         sim.timing('stop', 'modifyStimsTime')
-        if sim.rank == 0 and sim.cfg.timing: print('  Done; stims modification time = %0.2f s.' % sim.timingData['modifyStimsTime'])
-
-
-
-
-
+        if sim.rank == 0 and sim.cfg.timing: print(('  Done; stims modification time = %0.2f s.' % sim.timingData['modifyStimsTime']))
+
+
+
+
+
RefactoringTool: Writing converted netpyne/network.py to netpyne_py3/network.py.
RefactoringTool: Refactored netpyne/neuromlFuncs.py
--- netpyne/neuromlFuncs.py	(original)
+++ netpyne/neuromlFuncs.py	(refactored)
@@ -17,7 +17,7 @@
 import pprint; pp = pprint.PrettyPrinter(depth=6)
 import math
 from collections import OrderedDict
-import sim, specs
+from . import sim, specs
 
 ###############################################################################
 ### Get connection centric network representation as used in NeuroML2
@@ -26,8 +26,8 @@
 
     nn = {}
 
-    for np_pop in net.pops.values(): 
-        print("Adding conns for: %s"%np_pop.tags)
+    for np_pop in list(net.pops.values()): 
+        print(("Adding conns for: %s"%np_pop.tags))
         if not np_pop.tags['cellModel'] ==  'NetStim':
             for cell in net.cells:
                 if cell.gid in np_pop.cellGids:
@@ -44,10 +44,10 @@
                             synMech = conn['synMech']
                             threshold = conn['threshold']
 
-                            if sim.cfg.verbose: print("      Conn %s[%i]->%s[%i] with %s, w: %s, d: %s"%(popPre, indexPre,popPost, indexPost, synMech, weight, delay))
+                            if sim.cfg.verbose: print(("      Conn %s[%i]->%s[%i] with %s, w: %s, d: %s"%(popPre, indexPre,popPost, indexPost, synMech, weight, delay)))
 
                             projection_info = (popPre,popPost,synMech)
-                            if not projection_info in nn.keys():
+                            if not projection_info in list(nn.keys()):
                                 nn[projection_info] = []
 
                             nn[projection_info].append({'indexPre':indexPre,'indexPost':indexPost,'weight':weight,'delay':delay})
@@ -65,9 +65,9 @@
 
     stims = {}
 
-    for np_pop in net.pops.values(): 
+    for np_pop in list(net.pops.values()): 
         if not np_pop.tags['cellModel'] ==  'NetStim':
-            print("Adding stims for: %s"%np_pop.tags)
+            print(("Adding stims for: %s"%np_pop.tags))
             for cell in net.cells:
                 if cell.gid in np_pop.cellGids:
                     pop, index = gids_vs_pop_indices[cell.gid]
@@ -91,7 +91,7 @@
                         name_stim = 'NetStim_%s_%s_%s_%s_%s'%(ref,pop,rate,noise,synMech)
 
                         stim_info = (name_stim, pop, rate, noise,synMech)
-                        if not stim_info in stims.keys():
+                        if not stim_info in list(stims.keys()):
                             stims[stim_info] = []
 
 
@@ -109,9 +109,9 @@
     def _export_synapses (net, nml_doc):
 
         syn_types = {}
-        for id,syn in net.params.synMechParams.iteritems():
+        for id,syn in net.params.synMechParams.items():
             syn_types[id]=syn['mod']
-            if sim.cfg.verbose: print('Exporting details of syn: %s'%syn)
+            if sim.cfg.verbose: print(('Exporting details of syn: %s'%syn))
             if syn['mod'] == 'Exp2Syn':
                 syn0 = neuroml.ExpTwoSynapse(id=id, 
                                              gbase='1uS',
@@ -188,7 +188,7 @@
 
         net = sim.net
         
-        print("Exporting network to NeuroML 2, reference: %s"%reference)
+        print(("Exporting network to NeuroML 2, reference: %s"%reference))
         
         import neuroml
         import neuroml.writers as writers
@@ -205,30 +205,30 @@
         
         cells_added = []
         
-        for np_pop in net.pops.values(): 
-            if sim.cfg.verbose: print("-- Adding population: %s"%np_pop.tags)
+        for np_pop in list(net.pops.values()): 
+            if sim.cfg.verbose: print(("-- Adding population: %s"%np_pop.tags))
             
             cell_param_set = {} 
 
-            for cell_name in net.params.cellParams.keys():
+            for cell_name in list(net.params.cellParams.keys()):
                 cell_param_set0 = net.params.cellParams[cell_name]
                 someMatches = False
                 someMisMatches = False
-                if sim.cfg.verbose: print("  -- Comparing conds: %s"%cell_param_set0)
+                if sim.cfg.verbose: print(("  -- Comparing conds: %s"%cell_param_set0))
                 for cond in cell_param_set0['conds']:
                     if len(cell_param_set0['conds'][cond])>0:
                         if cond in np_pop.tags and cell_param_set0['conds'][cond] == np_pop.tags[cond]:
-                            if sim.cfg.verbose: print "    Cond: %s matches..."%cond
+                            if sim.cfg.verbose: print("    Cond: %s matches..."%cond)
                             someMatches = True
                         else:
-                            if sim.cfg.verbose: print "    Cond: %s DOESN'T match (%s != %s)..."%(cond,cell_param_set0['conds'][cond],np_pop.tags[cond] if cond in np_pop.tags else "???")
+                            if sim.cfg.verbose: print("    Cond: %s DOESN'T match (%s != %s)..."%(cond,cell_param_set0['conds'][cond],np_pop.tags[cond] if cond in np_pop.tags else "???"))
                             someMisMatches = True
                 if someMatches and not someMisMatches:
-                    if sim.cfg.verbose: print("   Matches: %s"%cell_param_set0)
+                    if sim.cfg.verbose: print(("   Matches: %s"%cell_param_set0))
                     cell_param_set.update(cell_param_set0)
                 
             if not np_pop.tags['cellModel'] == 'NetStim' and len(cell_param_set)==0:
-                print("Error, could not find cellParams for %s"%np_pop.tags)
+                print(("Error, could not find cellParams for %s"%np_pop.tags))
                 exit(-1)
                 
             if not np_pop.tags['cellModel'] == 'NetStim':
@@ -243,7 +243,7 @@
                 
                 
             if not np_pop.tags['cellModel'] == 'NetStim' and not str(cell_param_set) in cells_added:
-                if sim.cfg.verbose: print("---------------  Adding a cell from pop %s: \n%s"%(np_pop.tags,cell_param_set))
+                if sim.cfg.verbose: print(("---------------  Adding a cell from pop %s: \n%s"%(np_pop.tags,cell_param_set)))
                 
                 # print("=====  Adding the cell %s: \n%s"%(cell_name,pp.pprint(cell_param_set)))
                 
@@ -252,12 +252,12 @@
 
                 if len(cell_param_set['secs']) == 1 \
                    and soma is not None\
-                   and not soma.has_key('mechs') \
+                   and 'mechs' not in soma \
                    and len(soma['pointps']) == 1:
 
-                    pproc = soma['pointps'].values()[0]
-
-                    print("Assuming abstract cell with behaviour set by single point process: %s!"%pproc)
+                    pproc = list(soma['pointps'].values())[0]
+
+                    print(("Assuming abstract cell with behaviour set by single point process: %s!"%pproc))
 
                     if pproc['mod'] == 'Izhi2007b':
                         izh = neuroml.Izhikevich2007Cell(id=cell_id)
@@ -275,7 +275,7 @@
 
                         nml_doc.izhikevich2007_cells.append(izh)
                     else:
-                        print("Unknown point process: %s; can't convert to NeuroML 2 equivalent!"%pproc['mod'])
+                        print(("Unknown point process: %s; can't convert to NeuroML 2 equivalent!"%pproc['mod']))
                         exit(1)
                 else:
                     print("Assuming normal cell with behaviour set by ion channel mechanisms!")
@@ -299,7 +299,7 @@
 
                     parentDistal = neuroml.Point3DWithDiam(x=0,y=0,z=0,diameter=0)
 
-                    for np_sec_name in cell_param_set['secs'].keys():
+                    for np_sec_name in list(cell_param_set['secs'].keys()):
 
                         parent_seg = None
 
@@ -307,7 +307,7 @@
                         nml_seg = neuroml.Segment(id=count,name=np_sec_name)
                         nml_segs[np_sec_name] = nml_seg
 
-                        if np_sec.has_key('topol') and len(np_sec['topol'])>0:
+                        if 'topol' in np_sec and len(np_sec['topol'])>0:
                             parent_seg = nml_segs[np_sec['topol']['parentSec']]
                             nml_seg.parent = neuroml.SegmentParent(segments=parent_seg.id)
 
@@ -315,11 +315,11 @@
                                 print("Currently only support cell topol with parentX == 1.0 and childX == 0")
                                 exit(1)
 
-                        if not ( (not np_sec['geom'].has_key('pt3d')) or len(np_sec['geom']['pt3d'])==0 or len(np_sec['geom']['pt3d'])==2 ):
-                            print("Currently only support cell geoms with 2 pt3ds (or 0 and diam/L specified): %s"%np_sec['geom'])
+                        if not ( ('pt3d' not in np_sec['geom']) or len(np_sec['geom']['pt3d'])==0 or len(np_sec['geom']['pt3d'])==2 ):
+                            print(("Currently only support cell geoms with 2 pt3ds (or 0 and diam/L specified): %s"%np_sec['geom']))
                             exit(1)
 
-                        if (not np_sec['geom'].has_key('pt3d') or len(np_sec['geom']['pt3d'])==0):
+                        if ('pt3d' not in np_sec['geom'] or len(np_sec['geom']['pt3d'])==0):
 
                             if parent_seg == None:
                                 nml_seg.proximal = neuroml.Point3DWithDiam(x=parentDistal.x,
@@ -360,7 +360,7 @@
                         '''
                         See https://github.com/Neurosim-lab/netpyne/issues/130
                         '''
-                        cm = np_sec['geom']['cm'] if np_sec['geom'].has_key('cm') else 1
+                        cm = np_sec['geom']['cm'] if 'cm' in np_sec['geom'] else 1
                         if isinstance(cm,dict) and len(cm)==0:
                             cm = 1
                         mp.specific_capacitances.append(neuroml.SpecificCapacitance(value="%s uF_per_cm2"%cm, 
@@ -371,7 +371,7 @@
 
                         mp.spike_threshes.append(neuroml.SpikeThresh(value="%s mV"%sim.net.params.defaultThreshold))
 
-                        for mech_name in np_sec['mechs'].keys():
+                        for mech_name in list(np_sec['mechs'].keys()):
                             mech = np_sec['mechs'][mech_name]
                             if mech_name == 'hh':
 
@@ -418,7 +418,7 @@
                                                             ion='non_specific')
                                 mp.channel_densities.append(leak_cd)
                             else:
-                                print("Currently NML2 export only supports mech hh, not: %s"%mech_name)
+                                print(("Currently NML2 export only supports mech hh, not: %s"%mech_name))
                                 exit(1)
 
 
@@ -427,9 +427,9 @@
                 cells_added.append(str(cell_param_set))
                 
             
-        for np_pop in net.pops.values(): 
+        for np_pop in list(net.pops.values()): 
             index = 0
-            print("Adding population: %s"%np_pop.tags)
+            print(("Adding population: %s"%np_pop.tags))
             
             type = 'populationList'
             if not np_pop.tags['cellModel'] ==  'NetStim':
@@ -453,11 +453,11 @@
             nn = _convertNetworkRepresentation(net, gids_vs_pop_indices)
 
             half_elect_conns_added = []
-            for proj_info in nn.keys():
+            for proj_info in list(nn.keys()):
 
                 prefix = "NetConn"
                 popPre,popPost,synMech = proj_info
-                if sim.cfg.verbose: print("Adding proj: %s->%s (%s)"%(popPre,popPost,synMech))
+                if sim.cfg.verbose: print(("Adding proj: %s->%s (%s)"%(popPre,popPost,synMech)))
                 
                 if syn_types[synMech]!='ElectSyn':
                     projection = neuroml.Projection(id="%s_%s_%s_%s"%(prefix,popPre, popPost,synMech), 
@@ -478,7 +478,7 @@
                 
                 
                 for conn in nn[proj_info]:
-                    if sim.cfg.verbose: print("Adding conn %s"%conn)
+                    if sim.cfg.verbose: print(("Adding conn %s"%conn))
                     
                     if syn_types[synMech]!='ElectSyn':
                         connection = neuroml.ConnectionWD(id=index, \
@@ -535,10 +535,10 @@
         if stimulations:
             stims = _convertStimulationRepresentation(net, gids_vs_pop_indices, nml_doc)
 
-            for stim_info in stims.keys():
+            for stim_info in list(stims.keys()):
                 name_stim, post_pop, rate, noise, synMech = stim_info
 
-                if sim.cfg.verbose: print("Adding stim: %s"%[stim_info])
+                if sim.cfg.verbose: print(("Adding stim: %s"%[stim_info]))
 
                 if noise==0:
                     source = neuroml.SpikeGenerator(id=name_stim,period="%ss"%(1./rate))
@@ -596,10 +596,10 @@
                                    copy_neuroml = False,
                                    include_extra_files = [],
                                    gen_plots_for_all_v = False,
-                                   gen_plots_for_only_populations = populations_vs_components.keys(),
+                                   gen_plots_for_only_populations = list(populations_vs_components.keys()),
                                    gen_saves_for_all_v = False,
                                    plot_all_segments = False, 
-                                   gen_saves_for_only_populations = populations_vs_components.keys(),
+                                   gen_saves_for_only_populations = list(populations_vs_components.keys()),
                                    save_all_segments = False,
                                    seed=1234)
                                
@@ -645,18 +645,18 @@
 
         def finalise(self):
 
-            for popParam in self.popParams.keys():
+            for popParam in list(self.popParams.keys()):
                 self.netParams.popParams[popParam] = self.popParams[popParam]
 
-            for cellParam in self.cellParams.keys():
+            for cellParam in list(self.cellParams.keys()):
                 self.netParams.cellParams[cellParam] = self.cellParams[cellParam]
 
-            for proj_id in self.projection_infos.keys():
+            for proj_id in list(self.projection_infos.keys()):
                 projName, prePop, postPop, synapse, ptype = self.projection_infos[proj_id]
 
                 self.netParams.synMechParams[synapse] = {'mod': synapse}
 
-            for stimName in self.stimSources.keys():
+            for stimName in list(self.stimSources.keys()):
                 self.netParams.stimSourceParams[stimName] = self.stimSources[stimName]
                 self.netParams.stimTargetParams[stimName] = self.stimLists[stimName]
 
@@ -683,7 +683,7 @@
         #    
         def handleNetwork(self, network_id, notes, temperature=None):
             if temperature:
-                print("\n****************\n   Need to set temperature to %s!!!\n********************"%temperature)
+                print(("\n****************\n   Need to set temperature to %s!!!\n********************"%temperature))
 
 
         #
@@ -691,7 +691,7 @@
         #    
         def handlePopulation(self, population_id, component, size, component_obj):
 
-            if self.verbose: print("A population: %s with %i of %s (%s)"%(population_id,size,component,component_obj))
+            if self.verbose: print(("A population: %s with %i of %s (%s)"%(population_id,size,component,component_obj)))
             
             self.pop_ids_vs_components[population_id] = component_obj
 
@@ -755,11 +755,11 @@
                 
                 
                 else:
-                    ordered_segs, cumulative_lengths = cell.get_ordered_segments_in_groups(cellRule['secs'].keys(),include_cumulative_lengths=True)
+                    ordered_segs, cumulative_lengths = cell.get_ordered_segments_in_groups(list(cellRule['secs'].keys()),include_cumulative_lengths=True)
                     self.pop_ids_vs_ordered_segs[population_id] = ordered_segs
                     self.pop_ids_vs_cumulative_lengths[population_id] = cumulative_lengths
                     
-                    for section in cellRule['secs'].keys():
+                    for section in list(cellRule['secs'].keys()):
                         #print("ggg %s: %s"%(section,ordered_segs[section]))
                         for seg in ordered_segs[section]:
                             prox, dist = self._get_prox_dist(seg, seg_ids_vs_segs)
@@ -770,7 +770,7 @@
                                     parent_seg = seg_ids_vs_segs[seg.parent.segments]
                                     parent_sec = None
                                     #TODO: optimise
-                                    for sec in ordered_segs.keys():
+                                    for sec in list(ordered_segs.keys()):
                                         if parent_seg.id in [s.id for s in ordered_segs[sec]]:
                                             parent_sec = sec
                                     fract = float(seg.parent.fraction_along)
@@ -797,7 +797,7 @@
                                 seg_grps_vs_nrn_sections[seg_grp.id].append(section_name)
                         else:
                             seg_grps_vs_nrn_sections[seg_grp.id].append(inc.segment_groups)
-                            if not cellRule['secLists'].has_key(seg_grp.id): cellRule['secLists'][seg_grp.id] = []
+                            if seg_grp.id not in cellRule['secLists']: cellRule['secLists'][seg_grp.id] = []
                             cellRule['secLists'][seg_grp.id].append(inc.segment_groups)
 
                     if not seg_grp.neuro_lex_id or seg_grp.neuro_lex_id !="sao864921383":
@@ -819,7 +819,7 @@
                         if cm.ion and cm.ion == 'non_specific':
                             mech['e'] = erev
                         else:
-                            if not cellRule['secs'][section_name]['ions'].has_key(cm.ion):
+                            if cm.ion not in cellRule['secs'][section_name]['ions']:
                                 cellRule['secs'][section_name]['ions'][cm.ion] = {}
                             cellRule['secs'][section_name]['ions'][cm.ion]['e'] = erev
                             
@@ -840,7 +840,7 @@
                             pass
                             ##mech['e'] = erev
                         else:
-                            if not cellRule['secs'][section_name]['ions'].has_key(cm.ion):
+                            if cm.ion not in cellRule['secs'][section_name]['ions']:
                                 cellRule['secs'][section_name]['ions'][cm.ion] = {}
                             ##cellRule['secs'][section_name]['ions'][cm.ion]['e'] = erev
                             
@@ -899,7 +899,7 @@
                 
                 popInfo['cellType'] = component
                 
-                if self.verbose: print("Abstract cell: %s"%(isinstance(component_obj,BaseCell)))
+                if self.verbose: print(("Abstract cell: %s"%(isinstance(component_obj,BaseCell))))
                 
                 if not isinstance(component_obj,BaseCell):
                     popInfo['originalFormat'] = 'NeuroML2_SpikeSource' 
@@ -943,7 +943,7 @@
 
         def _convert_to_nrn_section_location(self, population_id, seg_id, fract_along):
             
-            if not self.pop_ids_vs_seg_ids_vs_segs.has_key(population_id) or not self.pop_ids_vs_seg_ids_vs_segs[population_id].has_key(seg_id):
+            if population_id not in self.pop_ids_vs_seg_ids_vs_segs or seg_id not in self.pop_ids_vs_seg_ids_vs_segs[population_id]:
                 return 'soma', 0.5
             
             if not self.pop_ids_vs_use_segment_groups_for_neuron[population_id]:
@@ -951,7 +951,7 @@
                 return self.pop_ids_vs_seg_ids_vs_segs[population_id][seg_id].name, fract_along
             else:
                 fract_sec = -1
-                for sec in self.pop_ids_vs_ordered_segs[population_id].keys():
+                for sec in list(self.pop_ids_vs_ordered_segs[population_id].keys()):
                     ind = 0
                     for seg in self.pop_ids_vs_ordered_segs[population_id][sec]:
                         if seg.id == seg_id:
@@ -987,7 +987,7 @@
         #
         def handleProjection(self, projName, prePop, postPop, synapse, hasWeights=False, hasDelays=False, type="projection", synapse_obj=None, pre_synapse_obj=None):
 
-            if self.verbose: print("A projection: %s (%s) from %s -> %s with syn: %s" % (projName, type, prePop, postPop, synapse))
+            if self.verbose: print(("A projection: %s (%s) from %s -> %s with syn: %s" % (projName, type, prePop, postPop, synapse)))
             self.projection_infos[projName] = (projName, prePop, postPop, synapse, type)
             self.connections[projName] = []
 
@@ -1076,7 +1076,7 @@
                         'conds': {'pop':pop_id, 'cellList': [cellId]}}
                         
             
-            if self.verbose: print("Input: %s[%s] on %s, cellId: %i, seg: %i (nrn: %s), fract: %f (nrn: %f); ref: %s" % (inputListId,id,pop_id,cellId,segId,nrn_sec,fract,nrn_fract,stimId))
+            if self.verbose: print(("Input: %s[%s] on %s, cellId: %i, seg: %i (nrn: %s), fract: %f (nrn: %f); ref: %s" % (inputListId,id,pop_id,cellId,segId,nrn_sec,fract,nrn_fract,stimId)))
             
             # TODO: build just one stimLists/stimSources entry for the inputList
             # Issue: how to specify the sec/loc per individual stim??
@@ -1094,7 +1094,7 @@
         import pprint
         pp = pprint.PrettyPrinter(indent=4)
 
-        print("Importing NeuroML 2 network from: %s"%fileName)
+        print(("Importing NeuroML 2 network from: %s"%fileName))
 
         nmlHandler = None
         
@@ -1115,7 +1115,7 @@
 
             nmlHandler.finalise()
 
-            print('Finished import of NeuroML2; populations vs gids NML has calculated: %s'%nmlHandler.gids)
+            print(('Finished import of NeuroML2; populations vs gids NML has calculated: %s'%nmlHandler.gids))
             #print('Connections: %s'%nmlHandler.connections)
 
         if fileName.endswith(".h5"):
@@ -1133,7 +1133,7 @@
 
             nmlHandler.finalise()
 
-            print('Finished import: %s'%nmlHandler.gids)
+            print(('Finished import: %s'%nmlHandler.gids))
             #print('Connections: %s'%nmlHandler.connections)
 
 
@@ -1146,14 +1146,14 @@
 
 
         # Check gids equal....
-        for popLabel,pop in sim.net.pops.iteritems():
-            if sim.cfg.verbose: print("gid: %s: %s, %s"%(popLabel,pop, pop.cellGids))
+        for popLabel,pop in sim.net.pops.items():
+            if sim.cfg.verbose: print(("gid: %s: %s, %s"%(popLabel,pop, pop.cellGids)))
             for gid in pop.cellGids:
                 assert gid in nmlHandler.gids[popLabel]
             
-        for proj_id in nmlHandler.projection_infos.keys():
+        for proj_id in list(nmlHandler.projection_infos.keys()):
             projName, prePop, postPop, synapse, ptype = nmlHandler.projection_infos[proj_id]
-            if sim.cfg.verbose: print("Creating connections for %s (%s): %s->%s via %s"%(projName, ptype, prePop, postPop, synapse))
+            if sim.cfg.verbose: print(("Creating connections for %s (%s): %s->%s via %s"%(projName, ptype, prePop, postPop, synapse)))
             
             preComp = nmlHandler.pop_ids_vs_components[prePop]
             
@@ -1210,7 +1210,7 @@
                 cell = sim.net.cells[sim.net.gid2lid[preGapParams['gid']]] 
                 cell.addConn(preGapParams)
                 
-        print('  Number of connections on node %i: %i ' % (sim.rank, sum([len(cell.conns) for cell in sim.net.cells])))
+        print(('  Number of connections on node %i: %i ' % (sim.rank, sum([len(cell.conns) for cell in sim.net.cells]))))
 
                         
 
RefactoringTool: Writing converted netpyne/neuromlFuncs.py to netpyne_py3/neuromlFuncs.py.
RefactoringTool: Refactored netpyne/pop.py
--- netpyne/pop.py	(original)
+++ netpyne/pop.py	(refactored)
@@ -10,7 +10,7 @@
 from matplotlib.pylab import arange, seed, rand, array, pi, sqrt, sin, cos, arccos
 import numpy as np
 from neuron import h # Import NEURON
-import sim
+from . import sim
 
 
 ###############################################################################
@@ -42,7 +42,7 @@
                 sim.nextHost=0
         
         if sim.cfg.verbose: 
-            print("Distributed population of %i cells on %s hosts: %s, next: %s"%(numCellsPop,sim.nhosts,hostCells,sim.nextHost))
+            print(("Distributed population of %i cells on %s hosts: %s, next: %s"%(numCellsPop,sim.nhosts,hostCells,sim.nextHost)))
         return hostCells
 
 
@@ -67,7 +67,7 @@
         # not enough tags to create cells
         else:
             self.tags['numCells'] = 1
-            print 'Warninig: number or density of cells not specified for population %s; defaulting to numCells = 1' % (self.tags['pop'])
+            print('Warninig: number or density of cells not specified for population %s; defaulting to numCells = 1' % (self.tags['pop']))
             cells = self.createCellsFixedNum()
 
         return cells
@@ -113,7 +113,7 @@
         for i in self._distributeCells(int(sim.net.params.scale * self.tags['numCells']))[sim.rank]:
             gid = sim.net.lastGid+i
             self.cellGids.append(gid)  # add gid list of cells belonging to this population - not needed?
-            cellTags = {k: v for (k, v) in self.tags.iteritems() if k in sim.net.params.popTagsCopiedToCells}  # copy all pop tags to cell tags, except those that are pop-specific
+            cellTags = {k: v for (k, v) in self.tags.items() if k in sim.net.params.popTagsCopiedToCells}  # copy all pop tags to cell tags, except those that are pop-specific
             cellTags['pop'] = self.tags['pop']
             cellTags['xnorm'] = randLocs[i,0] # set x location (um)
             cellTags['ynorm'] = randLocs[i,1] # set y location (um)
@@ -122,7 +122,7 @@
             cellTags['y'] = sim.net.params.sizeY * randLocs[i,1] # set y location (um)
             cellTags['z'] = sim.net.params.sizeZ * randLocs[i,2] # set z location (um)
             cells.append(self.cellModelClass(gid, cellTags)) # instantiate Cell object
-            if sim.cfg.verbose: print('Cell %d/%d (gid=%d) of pop %s, on node %d, '%(i, sim.net.params.scale * self.tags['numCells']-1, gid, self.tags['pop'], sim.rank))
+            if sim.cfg.verbose: print(('Cell %d/%d (gid=%d) of pop %s, on node %d, '%(i, sim.net.params.scale * self.tags['numCells']-1, gid, self.tags['pop'], sim.rank)))
         sim.net.lastGid = sim.net.lastGid + self.tags['numCells'] 
         return cells
 
@@ -157,7 +157,7 @@
                 strFunc = self.tags['density']  # string containing function
                 strVars = [var for var in ['xnorm', 'ynorm', 'znorm'] if var in strFunc]  # get list of variables used 
                 if not len(strVars) == 1:
-                    print 'Error: density function (%s) for population %s does not include "xnorm", "ynorm" or "znorm"'%(strFunc,self.tags['pop'])
+                    print('Error: density function (%s) for population %s does not include "xnorm", "ynorm" or "znorm"'%(strFunc,self.tags['pop']))
                     return
                 coordFunc = strVars[0] 
                 lambdaStr = 'lambda ' + coordFunc +': ' + strFunc # convert to lambda function 
@@ -166,20 +166,20 @@
                 maxRange = self.tags[coordFunc+'Range'][1]
 
                 interval = 0.001  # interval of location values to evaluate func in order to find the max cell density
-                maxDensity = max(map(densityFunc, (arange(minRange, maxRange, interval))))  # max cell density 
+                maxDensity = max(list(map(densityFunc, (arange(minRange, maxRange, interval)))))  # max cell density 
                 maxCells = volume * maxDensity  # max number of cells based on max value of density func 
                 
                 seed(sim.id32('%d' % sim.cfg.seeds['loc']+sim.net.lastGid))  # reset random number generator
                 locsAll = minRange + ((maxRange-minRange)) * rand(int(maxCells), 1)  # random location values 
-                locsProb = array(map(densityFunc, locsAll)) / maxDensity  # calculate normalized density for each location value (used to prune)
+                locsProb = array(list(map(densityFunc, locsAll))) / maxDensity  # calculate normalized density for each location value (used to prune)
                 allrands = rand(len(locsProb))  # create an array of random numbers for checking each location pos 
                 
                 makethiscell = locsProb>allrands  # perform test to see whether or not this cell should be included (pruning based on density func)
                 funcLocs = [locsAll[i] for i in range(len(locsAll)) if i in array(makethiscell.nonzero()[0],dtype='int')] # keep only subset of yfuncLocs based on density func
                 self.tags['numCells'] = len(funcLocs)  # final number of cells after pruning of location values based on density func
-                if sim.cfg.verbose: print 'Volume=%.2f, maxDensity=%.2f, maxCells=%.0f, numCells=%.0f'%(volume, maxDensity, maxCells, self.tags['numCells'])
+                if sim.cfg.verbose: print('Volume=%.2f, maxDensity=%.2f, maxCells=%.0f, numCells=%.0f'%(volume, maxDensity, maxCells, self.tags['numCells']))
             else:
-                print 'Error: Density functions are only implemented for cuboid shaped networks'
+                print('Error: Density functions are only implemented for cuboid shaped networks')
                 exit(0)
         else:  # NO ynorm-dep
             self.tags['numCells'] = int(self.tags['density'] * volume)  # = density (cells/mm^3) * volume (mm^3)
@@ -218,12 +218,12 @@
             if funcLocs and coordFunc == coord+'norm':  # if locations for this coordinate calculated using density function
                 randLocs[:,icoord] = funcLocs
 
-        if sim.cfg.verbose and not funcLocs: print 'Volume=%.4f, density=%.2f, numCells=%.0f'%(volume, self.tags['density'], self.tags['numCells'])
+        if sim.cfg.verbose and not funcLocs: print('Volume=%.4f, density=%.2f, numCells=%.0f'%(volume, self.tags['density'], self.tags['numCells']))
 
         for i in self._distributeCells(self.tags['numCells'])[sim.rank]:
             gid = sim.net.lastGid+i
             self.cellGids.append(gid)  # add gid list of cells belonging to this population - not needed?
-            cellTags = {k: v for (k, v) in self.tags.iteritems() if k in sim.net.params.popTagsCopiedToCells}  # copy all pop tags to cell tags, except those that are pop-specific
+            cellTags = {k: v for (k, v) in self.tags.items() if k in sim.net.params.popTagsCopiedToCells}  # copy all pop tags to cell tags, except those that are pop-specific
             cellTags['pop'] = self.tags['pop']
             cellTags['xnorm'] = randLocs[i,0]  # calculate x location (um)
             cellTags['ynorm'] = randLocs[i,1]  # calculate y location (um)
@@ -233,7 +233,7 @@
             cellTags['z'] = sizeZ * randLocs[i,2]  # calculate z location (um)
             cells.append(self.cellModelClass(gid, cellTags)) # instantiate Cell object
             if sim.cfg.verbose: 
-                print('Cell %d/%d (gid=%d) of pop %s, pos=(%2.f, %2.f, %2.f), on node %d, '%(i, self.tags['numCells']-1, gid, self.tags['pop'],cellTags['x'], cellTags['y'], cellTags['z'], sim.rank))
+                print(('Cell %d/%d (gid=%d) of pop %s, pos=(%2.f, %2.f, %2.f), on node %d, '%(i, self.tags['numCells']-1, gid, self.tags['pop'],cellTags['x'], cellTags['y'], cellTags['z'], sim.rank)))
         sim.net.lastGid = sim.net.lastGid + self.tags['numCells'] 
         return cells
 
@@ -247,7 +247,7 @@
             #    self.cellModelClass = getattr(f, self.tags['cellsList'][i]['cellModel'])  # select cell class to instantiate cells based on the cellModel tags
             gid = sim.net.lastGid+i
             self.cellGids.append(gid)  # add gid list of cells belonging to this population - not needed?
-            cellTags = {k: v for (k, v) in self.tags.iteritems() if k in sim.net.params.popTagsCopiedToCells}  # copy all pop tags to cell tags, except those that are pop-specific
+            cellTags = {k: v for (k, v) in self.tags.items() if k in sim.net.params.popTagsCopiedToCells}  # copy all pop tags to cell tags, except those that are pop-specific
             cellTags['pop'] = self.tags['pop']
             cellTags.update(self.tags['cellsList'][i])  # add tags specific to this cells
             for coord in ['x','y','z']:
@@ -259,7 +259,7 @@
                     cellTags[coord+'norm'] = cellTags[coord] = 0
             if 'propList' not in cellTags: cellTags['propList'] = []  # initalize list of property sets if doesn't exist
             cells.append(self.cellModelClass(gid, cellTags)) # instantiate Cell object
-            if sim.cfg.verbose: print('Cell %d/%d (gid=%d) of pop %d, on node %d, '%(i, self.tags['numCells']-1, gid, i, sim.rank))
+            if sim.cfg.verbose: print(('Cell %d/%d (gid=%d) of pop %d, on node %d, '%(i, self.tags['numCells']-1, gid, i, sim.rank)))
         sim.net.lastGid = sim.net.lastGid + len(self.tags['cellsList'])
         return cells
 
@@ -290,7 +290,7 @@
         for i in self._distributeCells(numCells)[sim.rank]:
             gid = sim.net.lastGid+i
             self.cellGids.append(gid)  # add gid list of cells belonging to this population - not needed?
-            cellTags = {k: v for (k, v) in self.tags.iteritems() if k in sim.net.params.popTagsCopiedToCells}  # copy all pop tags to cell tags, except those that are pop-specific
+            cellTags = {k: v for (k, v) in self.tags.items() if k in sim.net.params.popTagsCopiedToCells}  # copy all pop tags to cell tags, except those that are pop-specific
             cellTags['pop'] = self.tags['pop']
             cellTags['xnorm'] = gridLocs[i][0] / sim.net.params.sizeX # set x location (um)
             cellTags['ynorm'] = gridLocs[i][1] / sim.net.params.sizeY # set y location (um)
@@ -299,7 +299,7 @@
             cellTags['y'] = gridLocs[i][1] # set y location (um)
             cellTags['z'] = gridLocs[i][2] # set z location (um)
             cells.append(self.cellModelClass(gid, cellTags)) # instantiate Cell object
-            if sim.cfg.verbose: print('Cell %d/%d (gid=%d) of pop %s, on node %d, '%(i, numCells, gid, self.tags['pop'], sim.rank))
+            if sim.cfg.verbose: print(('Cell %d/%d (gid=%d) of pop %s, on node %d, '%(i, numCells, gid, self.tags['pop'], sim.rank)))
         sim.net.lastGid = sim.net.lastGid + numCells
         return cells
 
@@ -322,7 +322,7 @@
                     self.cellModelClass = sim.PointCell
                     excludeTags = ['pop', 'cellModel', 'cellType', 'numCells', 'density', 
                                 'xRange', 'yRange', 'zRange', 'xnormRange', 'ynormRange', 'znormRange', 'vref']
-                    params = {k: v for k,v in self.tags.iteritems() if k not in excludeTags}
+                    params = {k: v for k,v in self.tags.items() if k not in excludeTags}
                     self.tags['params'] = params
                     for k in self.tags['params']: self.tags.pop(k)
                     sim.net.params.popTagsCopiedToCells.append('params')
RefactoringTool: Writing converted netpyne/pop.py to netpyne_py3/pop.py.
RefactoringTool: Refactored netpyne/sim.py
--- netpyne/sim.py	(original)
+++ netpyne/sim.py	(refactored)
@@ -14,13 +14,13 @@
     netpyne.__gui__ = False
 
 # import all required modules
-from simFuncs import *
-from neuromlFuncs import *
-from wrappers import *
-import analysis
-from network import Network
-from cell import CompartCell, PointCell, NML2Cell, NML2SpikeSource
-from pop import Pop 
-import utils
+from .simFuncs import *
+from .neuromlFuncs import *
+from .wrappers import *
+from . import analysis
+from .network import Network
+from .cell import CompartCell, PointCell, NML2Cell, NML2SpikeSource
+from .pop import Pop 
+from . import utils
 from neuron import h
 
RefactoringTool: Writing converted netpyne/sim.py to netpyne_py3/sim.py.
RefactoringTool: Refactored netpyne/simFuncs.py
--- netpyne/simFuncs.py	(original)
+++ netpyne/simFuncs.py	(refactored)
@@ -17,14 +17,14 @@
 import os
 from time import time
 from datetime import datetime
-import cPickle as pk
+import pickle as pk
 import hashlib 
 from numbers import Number
 from copy import copy
-from specs import Dict, ODict
+from .specs import Dict, ODict
 from collections import OrderedDict
 from neuron import h, init # Import NEURON
-import sim, specs
+from . import sim, specs
 
 
 
@@ -120,7 +120,7 @@
         else:
             return specs.NetParams(data['net']['params'])
     else:
-        print('netParams not found in file %s'%(filename))
+        print(('netParams not found in file %s'%(filename)))
 
     pass
 
@@ -138,9 +138,9 @@
             sim.net.allCells = data['net']['cells']
         if instantiate:
             # calculate cells to instantiate in this node
-            cellsNode = [data['net']['cells'][i] for i in xrange(int(sim.rank), len(data['net']['cells']), sim.nhosts)] 
+            cellsNode = [data['net']['cells'][i] for i in range(int(sim.rank), len(data['net']['cells']), sim.nhosts)] 
             if sim.cfg.createPyStruct:
-                for popLoadLabel, popLoad in data['net']['pops'].iteritems():
+                for popLoadLabel, popLoad in data['net']['pops'].items():
                     pop = sim.Pop(popLoadLabel, popLoad['tags'])
                     pop.cellGids = popLoad['cellGids']
                     sim.net.pops[popLoadLabel] = pop
@@ -164,9 +164,9 @@
                         if sim.cfg.verbose: ' Unable to load cell stims' 
 
                     sim.net.cells.append(cell)
-                print('  Created %d cells' % (len(sim.net.cells)))
-                print('  Created %d connections' % (sum([len(c.conns) for c in sim.net.cells])))
-                print('  Created %d stims' % (sum([len(c.stims) for c in sim.net.cells])))
+                print(('  Created %d cells' % (len(sim.net.cells))))
+                print(('  Created %d connections' % (sum([len(c.conns) for c in sim.net.cells]))))
+                print(('  Created %d stims' % (sum([len(c.stims) for c in sim.net.cells]))))
 
                 # only create NEURON objs, if there is Python struc (fix so minimal Python struct is created)
                 if sim.cfg.createNEURONObj:  
@@ -185,13 +185,13 @@
                         except:
                             if sim.cfg.verbose: ' Unable to load instantiate cell conns or stims' 
 
-                    print('  Added NEURON objects to %d cells' % (len(sim.net.cells)))
+                    print(('  Added NEURON objects to %d cells' % (len(sim.net.cells))))
 
             if sim.rank == 0 and sim.cfg.timing: 
                 sim.timing('stop', 'loadNetTime')
-                print('  Done; re-instantiate net time = %0.2f s' % sim.timingData['loadNetTime'])
+                print(('  Done; re-instantiate net time = %0.2f s' % sim.timingData['loadNetTime']))
     else:
-        print('  netCells and/or netPops not found in file %s'%(filename))
+        print(('  netCells and/or netPops not found in file %s'%(filename)))
 
 
 ###############################################################################
@@ -206,7 +206,7 @@
         else:
             return specs.SimConfig(data['simConfig'])
     else:
-        print('  simConfig not found in file %s'%(filename))
+        print(('  simConfig not found in file %s'%(filename)))
     pass
 
 
@@ -219,7 +219,7 @@
     if 'simData' in data:
         sim.allSimData = data['simData']
     else:
-        print('  simData not found in file %s'%(filename))
+        print(('  simData not found in file %s'%(filename)))
 
     pass
 
@@ -247,14 +247,14 @@
     # load pickle file
     if ext == 'pkl':
         import pickle
-        print('Loading file %s ... ' % (filename))
+        print(('Loading file %s ... ' % (filename)))
         with open(filename, 'r') as fileObj:
             data = pickle.load(fileObj)
 
     # load dpk file
     elif ext == 'dpk':
         import gzip
-        print('Loading file %s ... ' % (filename))
+        print(('Loading file %s ... ' % (filename)))
         #fn=sim.cfg.filename #.split('.')
         #gzip.open(fn, 'wb').write(pk.dumps(dataSave)) # write compressed string
         print('NOT IMPLEMENTED!')
@@ -262,14 +262,14 @@
     # load json file
     elif ext == 'json':
         import json
-        print('Loading file %s ... ' % (filename))
+        print(('Loading file %s ... ' % (filename)))
         with open(filename, 'r') as fileObj:
             data = json.load(fileObj, object_pairs_hook=OrderedDict)
 
     # load mat file
     elif ext == 'mat':
         from scipy.io import savemat 
-        print('Loading file %s ... ' % (filename))
+        print(('Loading file %s ... ' % (filename)))
         #savemat(sim.cfg.filename+'.mat', replaceNoneObj(dataSave))  # replace None and {} with [] so can save in .mat format
         print('Finished saving!')
 
@@ -277,14 +277,14 @@
     elif ext == 'saveHDF5':
         #dataSaveUTF8 = _dict2utf8(replaceNoneObj(dataSave)) # replace None and {} with [], and convert to utf
         import hdf5storage
-        print('Loading file %s ... ' % (filename))
+        print(('Loading file %s ... ' % (filename)))
         #hdf5storage.writes(dataSaveUTF8, filename=sim.cfg.filename+'.hdf5')
         print('NOT IMPLEMENTED!')
 
     # load CSV file (currently only saves spikes)
     elif ext == 'csv':
         import csv
-        print('Loading file %s ... ' % (filename))
+        print(('Loading file %s ... ' % (filename)))
         writer = csv.writer(open(sim.cfg.filename+'.csv', 'wb'))
         #for dic in dataSave['simData']:
         #    for values in dic:
@@ -293,7 +293,7 @@
 
     # load Dat file(s) 
     elif ext == 'dat': 
-        print('Loading file %s ... ' % (filename))
+        print(('Loading file %s ... ' % (filename)))
         print('NOT IMPLEMENTED!')
         # traces = sim.cfg.recordTraces
         # for ref in traces.keys():
@@ -306,12 +306,12 @@
         #             dat_file.write('%s\t%s\n'%((i*sim.cfg.dt/1000),trace[i]/1000))
 
     else:
-        print('Format not recognized for file %s'%(filename))
+        print(('Format not recognized for file %s'%(filename)))
         return 
 
     if hasattr(sim, 'rank') and sim.rank == 0 and hasattr(sim, 'cfg') and sim.cfg.timing: 
         sim.timing('stop', 'loadFileTime')
-        print('  Done; file loading time = %0.2f s' % sim.timingData['loadFileTime'])
+        print(('  Done; file loading time = %0.2f s' % sim.timingData['loadFileTime']))
    
 
     return data
@@ -327,7 +327,7 @@
     # clean cells and simData in all nodes
     sim.clearObj([cell.__dict__ for cell in sim.net.cells])
     sim.clearObj([stim for stim in sim.simData['stims']])
-    for key in sim.simData.keys(): del sim.simData[key]  
+    for key in list(sim.simData.keys()): del sim.simData[key]  
     for c in sim.net.cells: del c
     for p in sim.net.pops: del p
     del sim.net.params
@@ -337,7 +337,7 @@
     if sim.rank == 0:
         sim.clearObj([cell.__dict__ for cell in sim.net.allCells])
         sim.clearObj([stim for stim in sim.allSimData['stims']])
-        for key in sim.allSimData.keys(): del sim.allSimData[key]
+        for key in list(sim.allSimData.keys()): del sim.allSimData[key]
         for c in sim.net.allCells: del c
         for p in sim.net.allPops: del p
         del sim.net.allCells
@@ -380,7 +380,7 @@
     elif type(obj) in [dict, Dict]:
         if objCopy == 'ROOT':
             objCopy = Dict() 
-        for key,val in obj.iteritems():
+        for key,val in obj.items():
             if type(val) in [list]:
                 objCopy[key] = [] 
                 copyReplaceItemObj(val, keystart, newval, objCopy[key])
@@ -405,7 +405,7 @@
             del item
                 
     elif type(obj) in [dict, Dict, ODict]:
-        for key in obj.keys():
+        for key in list(obj.keys()):
             val = obj[key]
             if type(val) in [list, dict, Dict, ODict]:
                 clearObj(val)
@@ -422,7 +422,7 @@
                 replaceItemObj(item, keystart, newval)
 
     elif type(obj) == dict:
-        for key,val in obj.iteritems():
+        for key,val in obj.items():
             if type(val) in [list, dict]:
                 replaceItemObj(val, keystart, newval)
             if key.startswith(keystart):
@@ -440,7 +440,7 @@
                 replaceFuncObj(item)
 
     elif type(obj) == dict:
-        for key,val in obj.iteritems():
+        for key,val in obj.items():
             if type(val) in [list, dict]:
                 replaceFuncObj(val)
             if 'func_name' in dir(val): #hasattr(val,'func_name'):  # avoid hasattr() since it creates key in Dicts() 
@@ -458,7 +458,7 @@
                 replaceNoneObj(item)
 
     elif type(obj) in [dict, Dict, ODict]:
-        for key,val in obj.iteritems():
+        for key,val in obj.items():
             if type(val) in [list, dict, Dict, ODict]:
                 replaceNoneObj(val)
             if val == None:
@@ -482,7 +482,7 @@
                 replaceDictODict(item)
 
     elif type(obj) in [dict, OrderedDict, Dict, ODict]:
-        for key,val in obj.iteritems():
+        for key,val in obj.items():
             if type(val) == Dict:
                 obj[key] = val.todict()
             elif type(val) == ODict:
@@ -521,7 +521,7 @@
                 obj[obj.index(item)] = str(item)
 
     elif type(obj) == dict or type(obj) == ODict:
-        for key,val in obj.iteritems():
+        for key,val in obj.items():
             if type(val) in [list, dict, ODict]:
                 tupleToStr(val)
             elif type(val) == tuple:
@@ -536,16 +536,16 @@
 #unidict = {k.decode('utf8'): v.decode('utf8') for k, v in strdict.items()}
     #print obj
     import collections
-    if isinstance(obj, basestring):
+    if isinstance(obj, str):
         return obj.decode('utf8')
     elif isinstance(obj, collections.Mapping):
-        for key in obj.keys():
+        for key in list(obj.keys()):
             if isinstance(key, Number):
                 obj[str(key).decode('utf8')] = obj[key]
                 obj.pop(key)
-        return dict(map(_dict2utf8, obj.iteritems()))
+        return dict(list(map(_dict2utf8, iter(obj.items()))))
     elif isinstance(obj, collections.Iterable):
-        return type(obj)(map(_dict2utf8, obj))
+        return type(obj)(list(map(_dict2utf8, obj)))
     else:
         return obj
 
@@ -565,7 +565,7 @@
     import imp, __main__
 
     if len(sys.argv) > 1:
-        print '\nReading command line arguments using syntax: python file.py [simConfig=filepath] [netParams=filepath]'
+        print('\nReading command line arguments using syntax: python file.py [simConfig=filepath] [netParams=filepath]')
 
     cfgPath = None
     netParamsPath = None
@@ -583,7 +583,7 @@
             elif netParamsPath.endswith('py'):
                 netParamsModule = imp.load_source(os.path.basename(netParamsPath).split('.')[0], netParamsPath)
                 netParams = netParamsModule.netParams
-                print 'Importing netParams from %s' %(netParamsPath)
+                print('Importing netParams from %s' %(netParamsPath))
 
     if not cfgPath:
         try:
@@ -591,7 +591,7 @@
             cfg = cfgModule.cfg
             __main__.cfg = cfg
         except:
-            print '\nWarning: Could not load cfg from command line path or from default cfg.py'
+            print('\nWarning: Could not load cfg from command line path or from default cfg.py')
             cfg = None
 
     if not netParamsPath:
@@ -599,7 +599,7 @@
             netParamsModule = imp.load_source('netParams', 'netParams.py')
             netParams = netParamsModule.netParams
         except:
-            print '\nWarning: Could not load netParams from command line path or from default netParams.py'
+            print('\nWarning: Could not load netParams from command line path or from default netParams.py')
             netParams = None
 
     return cfg, netParams
@@ -618,7 +618,7 @@
     # stim spike recording
     if 'plotRaster' in sim.cfg.analysis:
         if isinstance(sim.cfg.analysis['plotRaster'],dict) and 'include' in sim.cfg.analysis['plotRaster']:
-            netStimLabels = sim.net.params.stimSourceParams.keys()+['allNetStims']
+            netStimLabels = list(sim.net.params.stimSourceParams.keys())+['allNetStims']
             for item in sim.cfg.analysis['plotRaster']['include']:
                 if item in netStimLabels: 
                     sim.cfg.recordStim = True
@@ -629,7 +629,7 @@
             sim.cfg.recordStim = True
 
         elif (isinstance(sim.cfg.analysis['plotSpikeHist'],dict) and 'include' in sim.cfg.analysis['plotSpikeHist']) :
-            netStimLabels = sim.net.params.stimSourceParams.keys()+['allNetStims','eachPop']
+            netStimLabels = list(sim.net.params.stimSourceParams.keys())+['allNetStims','eachPop']
             for item in sim.cfg.analysis['plotSpikeHist']['include']:
                 if item in netStimLabels: 
                     sim.cfg.recordStim = True
@@ -651,18 +651,18 @@
         # get actual cell objects to record from, both from recordCell and plotCell lists
         cellsRecord = getCellsList(sim.cfg.recordCells)+cellsPlot
 
-        for key in sim.cfg.recordTraces.keys(): sim.simData[key] = Dict()  # create dict to store traces
+        for key in list(sim.cfg.recordTraces.keys()): sim.simData[key] = Dict()  # create dict to store traces
         for cell in cellsRecord: cell.recordTraces()  # call recordTraces function for each cell
         
         cat = 0
         total = 0
         for key in sim.simData:
-            if sim.cfg.verbose: print("   Recording: %s:"%key)
+            if sim.cfg.verbose: print(("   Recording: %s:"%key))
             if len(sim.simData[key])>0: cat+=1
             for k2 in sim.simData[key]:
-                if sim.cfg.verbose: print("      %s"%k2)
+                if sim.cfg.verbose: print(("      %s"%k2))
                 total+=1
-        print("Recording %s traces of %s types on node %i"%(total, cat, sim.rank))
+        print(("Recording %s traces of %s types on node %i"%(total, cat, sim.rank)))
                 
     
     timing('stop', 'setrecordTime')
@@ -689,11 +689,11 @@
         elif isinstance(condition, int):  # cell gid 
             cellGids.append(condition)
         
-        elif isinstance(condition, basestring):  # entire pop
+        elif isinstance(condition, str):  # entire pop
             cellGids.extend(list(sim.net.pops[condition].cellGids)) 
         
         elif isinstance(condition, tuple) or isinstance(condition, list):  # subset of a pop with relative indices
-            cellsPop = [gid for gid,tags in allCellTags.iteritems() if tags['pop']==condition[0]]
+            cellsPop = [gid for gid,tags in allCellTags.items() if tags['pop']==condition[0]]
 
             if isinstance(condition[1], list):
                 cellGids.extend([gid for i,gid in enumerate(cellsPop) if i in condition[1]])
@@ -711,31 +711,31 @@
 def setGlobals ():
     hParams = sim.cfg.hParams
     # iterate globals dic in each cellParams
-    cellGlobs = {k:v for k,v in hParams.iteritems()}
-    for cellRuleName, cellRule in sim.net.params.cellParams.iteritems():
-        for k,v in getattr(cellRule, 'globals', {}).iteritems():
+    cellGlobs = {k:v for k,v in hParams.items()}
+    for cellRuleName, cellRule in sim.net.params.cellParams.items():
+        for k,v in getattr(cellRule, 'globals', {}).items():
             if k not in cellGlobs:
                 cellGlobs[k] = v
             elif k in ['celsius', 'v_init', 'clamp_resist'] and cellGlobs[k] != v:  # exception
                 if k == 'v_init':
                     wrongVinit = [s['v_init'] for s in cellRule['secs'] if 'v_init' in s and s['v_init'] != v] # check if set inside secs
                     if len(wrongVinit) > 0:
-                        print '\nWarning: global variable %s=%s, but cellParams rule %s requires %s=%s' % (k, str(cellGlobs[k]), cellRuleName, k, str(v))
+                        print('\nWarning: global variable %s=%s, but cellParams rule %s requires %s=%s' % (k, str(cellGlobs[k]), cellRuleName, k, str(v)))
                 else: 
-                    print '\nWarning: global variable %s=%s, but cellParams rule %s requires %s=%s' % (k, str(cellGlobs[k]), cellRuleName, k, str(v))
+                    print('\nWarning: global variable %s=%s, but cellParams rule %s requires %s=%s' % (k, str(cellGlobs[k]), cellRuleName, k, str(v)))
             elif k in cellGlobs and cellGlobs[k] != v:
-                print '\nError: global variable %s has different values (%s vs %s) in two cellParams rules' % (k, str(v), str(cellGlobs[k]))
+                print('\nError: global variable %s has different values (%s vs %s) in two cellParams rules' % (k, str(v), str(cellGlobs[k])))
                 sys.exit() 
 
     # h global params
     if sim.cfg.verbose and len(cellGlobs) > 0: 
-        print '\nSetting h global variables ...'
-    for key,val in cellGlobs.iteritems(): 
+        print('\nSetting h global variables ...')
+    for key,val in cellGlobs.items(): 
         try:
             setattr(h, key, val) # set other h global vars (celsius, clamp_resist)
-            if sim.cfg.verbose: print('  h.%s = %s' % (key, str(val)))
+            if sim.cfg.verbose: print(('  h.%s = %s' % (key, str(val))))
         except:
-            print '\nError: could not set global %s = %s' % (key, str(val))
+            print('\nError: could not set global %s = %s' % (key, str(val)))
 
 
 ###############################################################################
@@ -774,7 +774,7 @@
     # parallelcontext vars
     sim.pc.set_maxstep(10)
     mindelay = sim.pc.allreduce(sim.pc.set_maxstep(10), 2) # flag 2 returns minimum value
-    if sim.rank==0 and sim.cfg.verbose: print('Minimum delay (time-step for queue exchange) is %.2f'%(mindelay))
+    if sim.rank==0 and sim.cfg.verbose: print(('Minimum delay (time-step for queue exchange) is %.2f'%(mindelay)))
     sim.pc.setup_transfer()  # setup transfer of source_var to target_var
 
     # handler for printing out time during simulation run
@@ -782,7 +782,7 @@
         def printRunTime():
             h('objref cvode')
             h('cvode = new CVode()')
-            for i in xrange(int(sim.cfg.printRunTime*1000.0), int(sim.cfg.duration), int(sim.cfg.printRunTime*1000.0)):
+            for i in range(int(sim.cfg.printRunTime*1000.0), int(sim.cfg.duration), int(sim.cfg.printRunTime*1000.0)):
                 h.cvode.event(i, 'print ' + str(i/1000.0) + ',"s"')
         
         sim.printRunTime = printRunTime
@@ -812,14 +812,14 @@
     preRun()
     init()
 
-    if sim.rank == 0: print('\nRunning simulation for %s ms...'%sim.cfg.duration)
+    if sim.rank == 0: print(('\nRunning simulation for %s ms...'%sim.cfg.duration))
     sim.pc.psolve(sim.cfg.duration)
     
     sim.pc.barrier() # Wait for all hosts to get to this point
     timing('stop', 'runTime')
     if sim.rank==0: 
-        print('  Done; run time = %0.2f s; real-time ratio: %0.2f.' % 
-            (sim.timingData['runTime'], sim.cfg.duration/1000/sim.timingData['runTime']))
+        print(('  Done; run time = %0.2f s; real-time ratio: %0.2f.' % 
+            (sim.timingData['runTime'], sim.cfg.duration/1000/sim.timingData['runTime'])))
 
 
 ###############################################################################
@@ -839,8 +839,8 @@
     sim.pc.barrier() # Wait for all hosts to get to this point
     timing('stop', 'runTime')
     if sim.rank==0: 
-        print('  Done; run time = %0.2f s; real-time ratio: %0.2f.' % 
-            (sim.timingData['runTime'], sim.cfg.duration/1000/sim.timingData['runTime']))
+        print(('  Done; run time = %0.2f s; real-time ratio: %0.2f.' % 
+            (sim.timingData['runTime'], sim.cfg.duration/1000/sim.timingData['runTime'])))
                 
 
 ###############################################################################
@@ -887,35 +887,35 @@
         for cell in sim.net.cells:
             cell.conns = []
             
-    simDataVecs = ['spkt','spkid','stims']+sim.cfg.recordTraces.keys()
+    simDataVecs = ['spkt','spkid','stims']+list(sim.cfg.recordTraces.keys())
     if sim.nhosts > 1:  # only gather if >1 nodes 
-        netPopsCellGids = {popLabel: list(pop.cellGids) for popLabel,pop in sim.net.pops.iteritems()}
+        netPopsCellGids = {popLabel: list(pop.cellGids) for popLabel,pop in sim.net.pops.items()}
         
         # gather only sim data
         if getattr(sim.cfg, 'gatherOnlySimData', False):
             nodeData = {'simData': sim.simData} 
             data = [None]*sim.nhosts
             data[0] = {}
-            for k,v in nodeData.iteritems():
+            for k,v in nodeData.items():
                 data[0][k] = v 
             gather = sim.pc.py_alltoall(data)
             sim.pc.barrier() 
 
             if sim.rank == 0: # simData
-                print '  Gathering only sim data...'
+                print('  Gathering only sim data...')
                 sim.allSimData = Dict()
-                for k in gather[0]['simData'].keys():  # initialize all keys of allSimData dict
+                for k in list(gather[0]['simData'].keys()):  # initialize all keys of allSimData dict
                     sim.allSimData[k] = {}
 
                 # fill in allSimData taking into account if data is dict of h.Vector (code needs improvement to be more generic)
                 for node in gather:  # concatenate data from each node
-                    for key,val in node['simData'].iteritems():  # update simData dics of dics of h.Vector 
+                    for key,val in node['simData'].items():  # update simData dics of dics of h.Vector 
                         if key in simDataVecs:          # simData dicts that contain Vectors
                             if isinstance(val,dict):                
-                                for cell,val2 in val.iteritems():
+                                for cell,val2 in val.items():
                                     if isinstance(val2,dict):       
                                         sim.allSimData[key].update(Dict({cell:Dict()}))
-                                        for stim,val3 in val2.iteritems():
+                                        for stim,val3 in val2.items():
                                             sim.allSimData[key][cell].update({stim:list(val3)}) # udpate simData dicts which are dicts of dicts of Vectors (eg. ['stim']['cell_1']['backgrounsd']=h.Vector)
                                     else:
                                         sim.allSimData[key].update({cell:list(val2)})  # udpate simData dicts which are dicts of Vectors (eg. ['v']['cell_1']=h.Vector)
@@ -926,7 +926,7 @@
 
             
             sim.net.allPops = ODict() # pops
-            for popLabel,pop in sim.net.pops.iteritems(): sim.net.allPops[popLabel] = pop.__getstate__() # can't use dict comprehension for OrderedDict
+            for popLabel,pop in sim.net.pops.items(): sim.net.allPops[popLabel] = pop.__getstate__() # can't use dict comprehension for OrderedDict
             
             sim.net.allCells = [c.__dict__ for c in sim.net.cells]
         
@@ -935,33 +935,33 @@
             nodeData = {'netCells': [c.__getstate__() for c in sim.net.cells], 'netPopsCellGids': netPopsCellGids, 'simData': sim.simData} 
             data = [None]*sim.nhosts
             data[0] = {}
-            for k,v in nodeData.iteritems():
+            for k,v in nodeData.items():
                 data[0][k] = v 
             gather = sim.pc.py_alltoall(data)
             sim.pc.barrier()  
             if sim.rank == 0:
                 allCells = []
                 allPops = ODict()
-                for popLabel,pop in sim.net.pops.iteritems(): allPops[popLabel] = pop.__getstate__() # can't use dict comprehension for OrderedDict
+                for popLabel,pop in sim.net.pops.items(): allPops[popLabel] = pop.__getstate__() # can't use dict comprehension for OrderedDict
                 allPopsCellGids = {popLabel: [] for popLabel in netPopsCellGids}
                 sim.allSimData = Dict()
 
-                for k in gather[0]['simData'].keys():  # initialize all keys of allSimData dict
+                for k in list(gather[0]['simData'].keys()):  # initialize all keys of allSimData dict
                     sim.allSimData[k] = {}
 
                 # fill in allSimData taking into account if data is dict of h.Vector (code needs improvement to be more generic)
                 for node in gather:  # concatenate data from each node
                     allCells.extend(node['netCells'])  # extend allCells list
-                    for popLabel,popCellGids in node['netPopsCellGids'].iteritems():
+                    for popLabel,popCellGids in node['netPopsCellGids'].items():
                         allPopsCellGids[popLabel].extend(popCellGids)
                         
-                    for key,val in node['simData'].iteritems():  # update simData dics of dics of h.Vector 
+                    for key,val in node['simData'].items():  # update simData dics of dics of h.Vector 
                         if key in simDataVecs:          # simData dicts that contain Vectors
                             if isinstance(val,dict):                
-                                for cell,val2 in val.iteritems():
+                                for cell,val2 in val.items():
                                     if isinstance(val2,dict):       
                                         sim.allSimData[key].update(Dict({cell:Dict()}))
-                                        for stim,val3 in val2.iteritems():
+                                        for stim,val3 in val2.items():
                                             sim.allSimData[key][cell].update({stim:list(val3)}) # udpate simData dicts which are dicts of dicts of Vectors (eg. ['stim']['cell_1']['backgrounsd']=h.Vector)
                                     else:
                                         sim.allSimData[key].update({cell:list(val2)})  # udpate simData dicts which are dicts of Vectors (eg. ['v']['cell_1']=h.Vector)
@@ -972,7 +972,7 @@
 
                 sim.net.allCells =  sorted(allCells, key=lambda k: k['gid']) 
                 
-                for popLabel,pop in allPops.iteritems():
+                for popLabel,pop in allPops.items():
                     pop['cellGids'] = sorted(allPopsCellGids[popLabel])
                 sim.net.allPops = allPops
         
@@ -993,17 +993,17 @@
         else:
             sim.net.allCells = [c.__dict__ for c in sim.net.cells]
         sim.net.allPops = ODict()
-        for popLabel,pop in sim.net.pops.iteritems(): sim.net.allPops[popLabel] = pop.__getstate__() # can't use dict comprehension for OrderedDict
+        for popLabel,pop in sim.net.pops.items(): sim.net.allPops[popLabel] = pop.__getstate__() # can't use dict comprehension for OrderedDict
         sim.allSimData = Dict() 
-        for k in sim.simData.keys():  # initialize all keys of allSimData dict
+        for k in list(sim.simData.keys()):  # initialize all keys of allSimData dict
                 sim.allSimData[k] = Dict()
-        for key,val in sim.simData.iteritems():  # update simData dics of dics of h.Vector 
+        for key,val in sim.simData.items():  # update simData dics of dics of h.Vector 
                 if key in simDataVecs:          # simData dicts that contain Vectors
                     if isinstance(val,dict):                
-                        for cell,val2 in val.iteritems():
+                        for cell,val2 in val.items():
                             if isinstance(val2,dict):       
                                 sim.allSimData[key].update(Dict({cell:Dict()}))
-                                for stim,val3 in val2.iteritems():
+                                for stim,val3 in val2.items():
                                     sim.allSimData[key][cell].update({stim:list(val3)}) # udpate simData dicts which are dicts of dicts of Vectors (eg. ['stim']['cell_1']['backgrounsd']=h.Vector)
                             else:
                                 sim.allSimData[key].update({cell:list(val2)})  # udpate simData dicts which are dicts of Vectors (eg. ['v']['cell_1']=h.Vector)
@@ -1016,7 +1016,7 @@
     sim.pc.barrier()
     if sim.rank == 0:
         timing('stop', 'gatherTime')
-        if sim.cfg.timing: print('  Done; gather time = %0.2f s.' % sim.timingData['gatherTime'])
+        if sim.cfg.timing: print(('  Done; gather time = %0.2f s.' % sim.timingData['gatherTime']))
 
         print('\nAnalyzing...')
         sim.totalSpikes = len(sim.allSimData['spkt'])   
@@ -1035,16 +1035,16 @@
             sim.connsPerCell = 0
             sim.synsPerCell = 0
         
-        print('  Cells: %i' % (sim.numCells) ) 
-        print('  Connections: %i (%0.2f per cell)' % (sim.totalConnections, sim.connsPerCell))
+        print(('  Cells: %i' % (sim.numCells) )) 
+        print(('  Connections: %i (%0.2f per cell)' % (sim.totalConnections, sim.connsPerCell)))
         if sim.totalSynapses != sim.totalConnections:
-            print('  Synaptic contacts: %i (%0.2f per cell)' % (sim.totalSynapses, sim.synsPerCell))
+            print(('  Synaptic contacts: %i (%0.2f per cell)' % (sim.totalSynapses, sim.synsPerCell)))
         if 'runTime' in sim.timingData: 
-            print('  Spikes: %i (%0.2f Hz)' % (sim.totalSpikes, sim.firingRate))
+            print(('  Spikes: %i (%0.2f Hz)' % (sim.totalSpikes, sim.firingRate)))
             if sim.cfg.printPopAvgRates: 
                 sim.allSimData['popRates'] = sim.popAvgRates()
-            print('  Simulated time: %0.1f s; %i workers' % (sim.cfg.duration/1e3, sim.nhosts))
-            print('  Run time: %0.2f s' % (sim.timingData['runTime']))
+            print(('  Simulated time: %0.1f s; %i workers' % (sim.cfg.duration/1e3, sim.nhosts)))
+            print(('  Run time: %0.2f s' % (sim.timingData['runTime'])))
 
             sim.allSimData['avgRate'] = sim.firingRate  # save firing rate
             
@@ -1056,7 +1056,7 @@
 ###############################################################################
 def popAvgRates (trange = None, show = True):
     if not hasattr(sim, 'allSimData') or 'spkt' not in sim.allSimData:
-        print 'Error: sim.allSimData not available; please call sim.gatherData()'
+        print('Error: sim.allSimData not available; please call sim.gatherData()')
         return None
 
     spkts = sim.allSimData['spkt']
@@ -1065,7 +1065,7 @@
     if not trange: 
         trange = [0, sim.cfg.duration]
     else:
-        spkids,spkts = zip(*[(spkid,spkt) for spkid,spkt in zip(spkids,spkts) if trange[0] <= spkt <= trange[1]])
+        spkids,spkts = list(zip(*[(spkid,spkt) for spkid,spkt in zip(spkids,spkts) if trange[0] <= spkt <= trange[1]]))
 
     avgRates = Dict()
     for pop in sim.net.allPops:
@@ -1073,7 +1073,7 @@
         if numCells > 0:
             tsecs = float((trange[1]-trange[0]))/1000.0
             avgRates[pop] = len([spkid for spkid in spkids if sim.net.allCells[int(spkid)]['tags']['pop']==pop])/numCells/tsecs
-            print '   %s : %.3f Hz'%(pop, avgRates[pop])
+            print('   %s : %.3f Hz'%(pop, avgRates[pop]))
 
     return avgRates
 
@@ -1088,13 +1088,13 @@
     avg_comp_time = sim.pc.allreduce(computation_time, 1)/sim.nhosts
     load_balance = avg_comp_time/max_comp_time
 
-    print 'node:',sim.rank,' comp_time:',computation_time
+    print('node:',sim.rank,' comp_time:',computation_time)
     if sim.rank==0:
-        print 'max_comp_time:', max_comp_time
-        print 'min_comp_time:', min_comp_time
-        print 'avg_comp_time:', avg_comp_time
-        print 'load_balance:',load_balance
-        print '\nspike exchange time (run_time-comp_time): ', sim.timingData['runTime'] - max_comp_time
+        print('max_comp_time:', max_comp_time)
+        print('min_comp_time:', min_comp_time)
+        print('avg_comp_time:', avg_comp_time)
+        print('load_balance:',load_balance)
+        print('\nspike exchange time (run_time-comp_time): ', sim.timingData['runTime'] - max_comp_time)
 
     return [max_comp_time, min_comp_time, avg_comp_time, load_balance]
 
@@ -1111,7 +1111,7 @@
         nodeData = {'netCells': [c.__getstate__() for c in sim.net.cells]} 
         data = [None]*sim.nhosts
         data[0] = {}
-        for k,v in nodeData.iteritems():
+        for k,v in nodeData.items():
             data[0][k] = v 
         gather = sim.pc.py_alltoall(data)
         sim.pc.barrier()  
@@ -1153,7 +1153,7 @@
         # copy source files
         if isinstance(sim.cfg.backupCfgFile, list) and len(sim.cfg.backupCfgFile) == 2:
             simName = sim.cfg.simLabel if sim.cfg.simLabel else os.path.basename(sim.cfg.filename)
-            print('Copying cfg file %s ... ' % simName)
+            print(('Copying cfg file %s ... ' % simName))
             source = sim.cfg.backupCfgFile[0]
             targetFolder = sim.cfg.backupCfgFile[1]
             # make dir
@@ -1161,11 +1161,11 @@
                 os.mkdir(targetFolder)
             except OSError:
                 if not os.path.exists(targetFolder):
-                    print ' Could not create target folder: %s' % (targetFolder)
+                    print(' Could not create target folder: %s' % (targetFolder))
             # copy file
             targetFile = targetFolder + '/' + simName + '_cfg.py'
             if os.path.exists(targetFile):
-                print ' Removing prior cfg file' , targetFile
+                print(' Removing prior cfg file' , targetFile)
                 os.system('rm ' + targetFile)  
             os.system('cp ' + source + ' ' + targetFile) 
 
@@ -1176,7 +1176,7 @@
             try:
                 os.mkdir(targetFolder)
             except OSError:
-                print ' Could not create target folder: %s' % (targetFolder)
+                print(' Could not create target folder: %s' % (targetFolder))
 
         # saving data
         if not include: include = sim.cfg.saveDataInclude
@@ -1204,7 +1204,7 @@
             if sim.cfg.savePickle:
                 import pickle
                 dataSave = replaceDictODict(dataSave)
-                print('Saving output as %s ... ' % (sim.cfg.filename+'.pkl'))
+                print(('Saving output as %s ... ' % (sim.cfg.filename+'.pkl')))
                 with open(sim.cfg.filename+'.pkl', 'wb') as fileObj:
                     pickle.dump(dataSave, fileObj)
                 print('Finished saving!')
@@ -1212,7 +1212,7 @@
             # Save to dpk file
             if sim.cfg.saveDpk:
                 import gzip
-                print('Saving output as %s ... ' % (sim.cfg.filename+'.dpk'))
+                print(('Saving output as %s ... ' % (sim.cfg.filename+'.dpk')))
                 fn=sim.cfg.filename #.split('.')
                 gzip.open(fn, 'wb').write(pk.dumps(dataSave)) # write compressed string
                 print('Finished saving!')
@@ -1221,7 +1221,7 @@
             if sim.cfg.saveJson:
                 import json
                 #dataSave = replaceDictODict(dataSave)  # not required since json saves as dict
-                print('Saving output as %s ... ' % (sim.cfg.filename+'.json '))
+                print(('Saving output as %s ... ' % (sim.cfg.filename+'.json ')))
                 with open(sim.cfg.filename+'.json', 'w') as fileObj:
                     json.dump(dataSave, fileObj)
                 print('Finished saving!')
@@ -1229,7 +1229,7 @@
             # Save to mat file
             if sim.cfg.saveMat:
                 from scipy.io import savemat 
-                print('Saving output as %s ... ' % (sim.cfg.filename+'.mat'))
+                print(('Saving output as %s ... ' % (sim.cfg.filename+'.mat')))
                 savemat(sim.cfg.filename+'.mat', tupleToStr(replaceNoneObj(dataSave)))  # replace None and {} with [] so can save in .mat format
                 print('Finished saving!')
 
@@ -1237,7 +1237,7 @@
             if sim.cfg.saveHDF5:
                 dataSaveUTF8 = _dict2utf8(replaceNoneObj(dataSave)) # replace None and {} with [], and convert to utf
                 import hdf5storage
-                print('Saving output as %s... ' % (sim.cfg.filename+'.hdf5'))
+                print(('Saving output as %s... ' % (sim.cfg.filename+'.hdf5')))
                 hdf5storage.writes(dataSaveUTF8, filename=sim.cfg.filename+'.hdf5')
                 print('Finished saving!')
 
@@ -1245,7 +1245,7 @@
             if sim.cfg.saveCSV:
                 if 'simData' in dataSave:
                     import csv
-                    print('Saving output as %s ... ' % (sim.cfg.filename+'.csv'))
+                    print(('Saving output as %s ... ' % (sim.cfg.filename+'.csv')))
                     writer = csv.writer(open(sim.cfg.filename+'.csv', 'wb'))
                     for dic in dataSave['simData']:
                         for values in dic:
@@ -1255,12 +1255,12 @@
             # Save to Dat file(s) 
             if sim.cfg.saveDat:
                 traces = sim.cfg.recordTraces
-                for ref in traces.keys():
-                    for cellid in sim.allSimData[ref].keys():
+                for ref in list(traces.keys()):
+                    for cellid in list(sim.allSimData[ref].keys()):
                         dat_file_name = '%s_%s.dat'%(ref,cellid)
                         dat_file = open(dat_file_name, 'w')
                         trace = sim.allSimData[ref][cellid]
-                        print("Saving %i points of data on: %s:%s to %s"%(len(trace),ref,cellid,dat_file_name))
+                        print(("Saving %i points of data on: %s:%s to %s"%(len(trace),ref,cellid,dat_file_name)))
                         for i in range(len(trace)):
                             dat_file.write('%s\t%s\n'%((i*sim.cfg.dt/1000),trace[i]/1000))
 
@@ -1269,14 +1269,14 @@
             # Save timing
             if sim.cfg.timing: 
                 timing('stop', 'saveTime')
-                print('  Done; saving time = %0.2f s.' % sim.timingData['saveTime'])
+                print(('  Done; saving time = %0.2f s.' % sim.timingData['saveTime']))
             if sim.cfg.timing and sim.cfg.saveTiming: 
                 import pickle
                 with open('timing.pkl', 'wb') as file: pickle.dump(sim.timing, file)
 
 
             # clean to avoid mem leaks
-            for key in dataSave.keys(): 
+            for key in list(dataSave.keys()): 
                 del dataSave[key]
             del dataSave
 
@@ -1326,15 +1326,15 @@
     # print memory diagnostic info
     if sim.rank == 0: # and checkMemory:
         import resource
-        print '\nMEMORY -----------------------'
-        print 'Sections: '
-        print h.topology()
-        print 'NetCons: '
-        print len(h.List("NetCon"))
-        print 'NetStims:'
-        print len(h.List("NetStim"))
-        print '\n Memory usage: %s \n' % resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
+        print('\nMEMORY -----------------------')
+        print('Sections: ')
+        print(h.topology())
+        print('NetCons: ')
+        print(len(h.List("NetCon")))
+        print('NetStims:')
+        print(len(h.List("NetStim")))
+        print('\n Memory usage: %s \n' % resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)
         # import objgraph
         # objgraph.show_most_common_types()
-        print '--------------------------------\n'
-
+        print('--------------------------------\n')
+
RefactoringTool: Writing converted netpyne/simFuncs.py to netpyne_py3/simFuncs.py.
RefactoringTool: Refactored netpyne/specs.py
--- netpyne/specs.py	(original)
+++ netpyne/specs.py	(refactored)
@@ -66,18 +66,18 @@
 
     def fromdict(self, d):
         d = self.dotify(d) 
-        for k,v in d.iteritems():
+        for k,v in d.items():
             self[k] = v
     
     def __repr__(self):
-        keys = self.keys()
+        keys = list(self.keys())
         args = ', '.join(['%s: %r' % (key, self[key]) for key in keys])
         return '{%s}' % (args)
     
 
     def dotify(self, x):
         if isinstance(x, dict):
-            return Dict( (k, self.dotify(v)) for k,v in x.iteritems() )
+            return Dict( (k, self.dotify(v)) for k,v in x.items() )
         elif isinstance(x, (list, tuple)):
             return type(x)( self.dotify(v) for v in x )
         else:
@@ -85,7 +85,7 @@
 
     def undotify(self, x): 
         if isinstance(x, dict):
-            return dict( (k, self.undotify(v)) for k,v in x.iteritems() )
+            return dict( (k, self.undotify(v)) for k,v in x.items() )
         elif isinstance(x, (list, tuple)):
             return type(x)( self.undotify(v) for v in x )
         else:
@@ -166,20 +166,20 @@
 
     def fromOrderedDict(self, d):
         d = self.dotify(d) 
-        for k,v in d.iteritems():
+        for k,v in d.items():
             self[k] = v
     
     def __repr__(self):
-        keys = self.keys()
+        keys = list(self.keys())
         args = ', '.join(['%s: %r' % (key, self[key]) for key in keys])
         return '{%s}' % (args)
     
 
     def dotify(self, x):
         if isinstance(x, OrderedDict):
-            return ODict( (k, self.dotify(v)) for k,v in x.iteritems() )
+            return ODict( (k, self.dotify(v)) for k,v in x.items() )
         elif isinstance(x, dict):
-            return Dict( (k, self.dotify(v)) for k,v in x.iteritems() )
+            return Dict( (k, self.dotify(v)) for k,v in x.items() )
         elif isinstance(x, (list, tuple)):
             return type(x)( self.dotify(v) for v in x )
         else:
@@ -187,9 +187,9 @@
 
     def undotify(self, x):  
         if isinstance(x, OrderedDict):
-            return OrderedDict( (k, self.undotify(v)) for k,v in x.iteritems() ) 
+            return OrderedDict( (k, self.undotify(v)) for k,v in x.items() ) 
         elif isinstance(x, dict):
-            return dict( (k, self.undotify(v)) for k,v in x.iteritems() )
+            return dict( (k, self.undotify(v)) for k,v in x.items() )
         elif isinstance(x, (list, tuple)):
             return type(x)( self.undotify(v) for v in x )
         else:
@@ -249,7 +249,7 @@
 
         # fill in params from dict passed as argument
         if netParamsDict:
-            for k,v in netParamsDict.iteritems(): 
+            for k,v in netParamsDict.items(): 
                 if isinstance(v, OrderedDict):
                     setattr(self, k, ODict(v))
                 elif isinstance(v, dict):
@@ -268,14 +268,14 @@
             os.mkdir(folder)
         except OSError:
             if not os.path.exists(folder):
-                print ' Could not create', folder
+                print(' Could not create', folder)
 
         dataSave = {'netParams': self.__dict__}
         
         # Save to json file
         if ext == 'json':
             import json
-            print('Saving netParams to %s ... ' % (filename))
+            print(('Saving netParams to %s ... ' % (filename)))
             with open(filename, 'w') as fileObj:
                 json.dump(dataSave, fileObj, indent=4, sort_keys=True)
 
@@ -334,12 +334,12 @@
         if somaAtOrigin:
             somaSec = next((sec for sec in cellRule['secs'] if 'soma' in sec), None)
             if not somaSec or not 'pt3d' in cellRule['secs'][somaSec]['geom']:
-                print 'Warning: cannot place soma at origin because soma does not exist or does not contain pt3d'
+                print('Warning: cannot place soma at origin because soma does not exist or does not contain pt3d')
                 return
             soma3d = cellRule['secs'][somaSec]['geom']['pt3d']
             midpoint = int(len(soma3d)/2)
             somaX, somaY, somaZ = soma3d[midpoint][0:3]
-            for sec in cellRule['secs'].values():
+            for sec in list(cellRule['secs'].values()):
                 for i,pt3d in enumerate(sec['geom']['pt3d']):
                     sec['geom']['pt3d'][i] = (pt3d[0] - somaX, pt3d[1] - somaY, pt3d[2] - somaZ, pt3d[3])
 
@@ -362,15 +362,15 @@
         if label in self.cellParams:
             cellRule = self.cellParams[label]
         else:
-            print 'Error adding secList: netParams.cellParams does not contain %s' % (label)
+            print('Error adding secList: netParams.cellParams does not contain %s' % (label))
             return
 
         if not isinstance(somaDist, list) or len(somaDist) != 2:
-            print 'Error adding secList: somaDist should be a list with 2 elements'
+            print('Error adding secList: somaDist should be a list with 2 elements')
             return
 
         secList = []
-        for secName, sec in cellRule.secs.iteritems():
+        for secName, sec in cellRule.secs.items():
             if 'pt3d' in sec['geom']:
                 pt3d = sec['geom']['pt3d']
                 midpoint = int(len(pt3d)/2)
@@ -380,7 +380,7 @@
                     secList.append(secName)
 
             else:
-                print 'Error adding secList: Sections do not contain 3d points' 
+                print('Error adding secList: Sections do not contain 3d points') 
                 return
 
         cellRule.secLists[secListName] = list(secList)
@@ -390,15 +390,15 @@
         if label in self.cellParams:
             cellRule = self.cellParams[label]
         else:
-            print 'Error renaming section: netParams.cellParams does not contain %s' % (label)
+            print('Error renaming section: netParams.cellParams does not contain %s' % (label))
             return
 
         if oldSec not in cellRule['secs']:
-            print 'Error renaming section: cellRule does not contain section %s' % (label)
+            print('Error renaming section: cellRule does not contain section %s' % (label))
             return
 
         cellRule['secs'][newSec] = cellRule['secs'].pop(oldSec)  # replace sec name
-        for sec in cellRule['secs'].values():  # replace appearences in topol
+        for sec in list(cellRule['secs'].values()):  # replace appearences in topol
             if sec['topol'].get('parentSec') == oldSec: sec['topol']['parentSec'] = newSec
 
 
@@ -407,19 +407,19 @@
         if label in self.cellParams:
             cellRule = self.cellParams[label]
         else:
-            print 'Error adding weightNorm: netParams.cellParams does not contain %s' % (label)
+            print('Error adding weightNorm: netParams.cellParams does not contain %s' % (label))
             return
 
         with open(fileName, 'r') as fileObj: 
             weightNorm = pickle.load(fileObj)
 
         try:
-            somaSec = next((k for k in weightNorm.keys() if k.startswith('soma')),None)
+            somaSec = next((k for k in list(weightNorm.keys()) if k.startswith('soma')),None)
             somaWeightNorm = weightNorm[somaSec][0]
         except:
-            print 'Error setting weightNorm: no soma section available to set threshold'
-            return
-        for sec, wnorm in weightNorm.iteritems():
+            print('Error setting weightNorm: no soma section available to set threshold')
+            return
+        for sec, wnorm in weightNorm.items():
             if sec in cellRule['secs']:  
                 wnorm = [min(wn,threshold*somaWeightNorm) for wn in wnorm]
                 cellRule['secs'][sec]['weightNorm'] = wnorm  # add weight normalization factors for each section
@@ -430,7 +430,7 @@
         if label in self.cellParams:
             cellRule = self.cellParams[label]
         else:
-            print 'Error saving: netParams.cellParams does not contain %s' % (label)
+            print('Error saving: netParams.cellParams does not contain %s' % (label))
             return
         with open(fileName, 'w') as fileObj:  
             pickle.dump(cellRule, fileObj)
@@ -445,7 +445,7 @@
 
 
     def todict(self):
-        from sim import replaceDictODict
+        from .sim import replaceDictODict
         return replaceDictODict(self.__dict__)
 
 
@@ -504,7 +504,7 @@
 
         # fill in params from dict passed as argument
         if simConfigDict:
-            for k,v in simConfigDict.iteritems():
+            for k,v in simConfigDict.items():
                 if isinstance(v, OrderedDict):
                     setattr(self, k, ODict(v)) 
                 elif isinstance(v, dict):
@@ -523,14 +523,14 @@
             os.mkdir(folder)
         except OSError:
             if not os.path.exists(folder):
-                print ' Could not create', folder
+                print(' Could not create', folder)
 
         dataSave = {'simConfig': self.__dict__}
         
         # Save to json file
         if ext == 'json':
             import json
-            print('Saving simConfig to %s ... ' % (filename))
+            print(('Saving simConfig to %s ... ' % (filename)))
             with open(filename, 'w') as fileObj:
                 json.dump(dataSave, fileObj, indent=4, sort_keys=True)
 
@@ -538,6 +538,6 @@
         self.analysis[func] =  params
 
     def todict(self):
-        from sim import replaceDictODict
+        from .sim import replaceDictODict
         return replaceDictODict(self.__dict__)
 
RefactoringTool: Writing converted netpyne/specs.py to netpyne_py3/specs.py.
RefactoringTool: Refactored netpyne/utils.py
--- netpyne/utils.py	(original)
+++ netpyne/utils.py	(refactored)
@@ -39,18 +39,18 @@
             if filePath not in sys.path:  # add to path if not there (need to import module)
                 sys.path.insert(0, filePath)
             moduleName = fileNameOnly.split('.py')[0]  # remove .py to obtain module name
-            exec('import '+ moduleName + ' as tempModule') in locals() # import module dynamically
+            exec(('import '+ moduleName + ' as tempModule'), locals()) # import module dynamically
             modulePointer = tempModule
             paramLabels = getattr(modulePointer, labels) # tuple with labels
             paramValues = getattr(modulePointer, values)  # variable with paramValues
             if key:  # if paramValues = dict
                 paramValues = paramValues[key]
-            params = dict(zip(paramLabels, paramValues))
+            params = dict(list(zip(paramLabels, paramValues)))
             sys.path.remove(filePath)
         except:
-            print "Error loading cell parameter values from " + fileName
-    else:
-        print "Trying to import izhi params from a file without the .py extension"
+            print("Error loading cell parameter values from " + fileName)
+    else:
+        print("Trying to import izhi params from a file without the .py extension")
     return params
 
 
@@ -60,13 +60,13 @@
     for i, mechtype in enumerate(['mechs','pointps']):
         mt = h.MechanismType(i)  # either distributed mechs (0) or point process (1)
         varList[mechtype] = {}
-        for j in xrange(int(mt.count())):
+        for j in range(int(mt.count())):
             mt.select(j)
             mt.selected(msname)
             ms = h.MechanismStandard(msname[0], 1) # PARAMETER (modifiable)
             varList[mechtype][msname[0]] = []
             propName = h.ref('')
-            for var in xrange(int(ms.count())):
+            for var in range(int(ms.count())):
                 k = ms.name(propName, var)
                 varList[mechtype][msname[0]].append(propName[0])
     return varList
@@ -104,7 +104,7 @@
 
 
 def setGlobals (glob):
-    for k,v in glob.iteritems():
+    for k,v in glob.items():
         setattr(h, k, v)
 
     # # remove vars are not in glob ?
@@ -118,10 +118,10 @@
 
 def _equal_dicts (d1, d2, ignore_keys):
     ignored = set(ignore_keys)
-    for k1, v1 in d1.iteritems():
+    for k1, v1 in d1.items():
         if k1 not in ignored and (k1 not in d2 or d2[k1] != v1):
             return False
-    for k2, v2 in d2.iteritems():
+    for k2, v2 in d2.items():
         if k2 not in ignored and k2 not in d1:
             return False
     return True
@@ -135,7 +135,7 @@
     except KeyError:
         pass
 
-    for mod in modules.values():
+    for mod in list(modules.values()):
         try:
             delattr(mod, modname)
         except:
@@ -144,7 +144,7 @@
 def importCell (fileName, cellName, cellArgs = None, cellInstance = False):
     h.initnrn()
     varList = mechVarList()  # list of properties for all density mechanisms and point processes
-    origGlob = getGlobals(varList['mechs'].keys()+varList['pointps'].keys())
+    origGlob = getGlobals(list(varList['mechs'].keys())+list(varList['pointps'].keys()))
 
     if cellArgs is None: cellArgs = [] # Define as empty list if not otherwise defined
 
@@ -166,7 +166,7 @@
         if filePath not in sys.path:  # add to path if not there (need to import module)
             sys.path.insert(0, filePath)
         moduleName = fileNameOnly.split('.py')[0]  # remove .py to obtain module name
-        exec('import ' + moduleName + ' as tempModule') in globals(), locals() # import module dynamically
+        exec(('import ' + moduleName + ' as tempModule'), globals(), locals()) # import module dynamically
         modulePointer = tempModule
         if isinstance(cellArgs, dict):
             cell = getattr(modulePointer, cellName)(**cellArgs) # create cell using template, passing dict with args
@@ -174,7 +174,7 @@
             cell = getattr(modulePointer, cellName)(*cellArgs)  # create cell using template, passing list with args
         sys.path.remove(filePath)
     else:
-        print "File name should be either .hoc or .py file"
+        print("File name should be either .hoc or .py file")
         return
 
     secDic, secListDic, synMechs, globs = getCellParams(cell, varList, origGlob)
@@ -193,7 +193,7 @@
 
     ''' Import cell from HOC template or python file into framework format (dict of sections, with geom, topol, mechs, syns)'''
     if fileName.endswith('.hoc') or fileName.endswith('.tem'):
-        print 'Importing from .hoc network not yet supported'
+        print('Importing from .hoc network not yet supported')
         return
         # h.load_file(fileName)
         # for cellName in cellNames:
@@ -207,18 +207,18 @@
             sys.path.insert(0, filePath)
         moduleName = fileNameOnly.split('.py')[0]  # remove .py to obtain module name
         os.chdir(filePath)
-        print '\nRunning network in %s to import cells into NetPyNE ...\n'%(fileName)
+        print('\nRunning network in %s to import cells into NetPyNE ...\n'%(fileName))
         from neuron import load_mechanisms
         load_mechanisms(filePath)
-        exec('import ' + moduleName + ' as tempModule') in globals(), locals() # import module dynamically
+        exec(('import ' + moduleName + ' as tempModule'), globals(), locals()) # import module dynamically
         modulePointer = tempModule
         sys.path.remove(filePath)
     else:
-        print "File name should be either .hoc or .py file"
+        print("File name should be either .hoc or .py file")
         return
 
     for label, conds, cellName in zip(labelList, condsList, cellNamesList):
-        print '\nImporting %s from %s ...'%(cellName, fileName)
+        print('\nImporting %s from %s ...'%(cellName, fileName))
         exec('cell = tempModule' + '.' + cellName)
         #cell = getattr(modulePointer, cellName) # get cell object
         secs, secLists, synMechs = getCellParams(cell)
@@ -253,7 +253,7 @@
     # create dict with dir(cell) name corresponding to each hname 
     dirCellSecNames = {} 
     for sec in secs:
-        dirCellSecNames.update({hname: name for hname,name in dirCellHnames.iteritems() if hname == sec.hname()})
+        dirCellSecNames.update({hname: name for hname,name in dirCellHnames.items() if hname == sec.hname()})
 
     secDic = {}
     synMechs = []
@@ -352,7 +352,7 @@
                         try:
                             synMech[varName] = point.__getattribute__(varName)
                         except:
-                            print 'Could not read variable %s from synapse %s'%(varName,synMech['label'])
+                            print('Could not read variable %s from synapse %s'%(varName,synMech['label']))
 
                     if not [_equal_dicts(synMech, synMech2, ignore_keys=['label']) for synMech2 in synMechs]:
                         synMechs.append(synMech)
@@ -368,7 +368,7 @@
                             # special condition for Izhi model, to set vinit=vr
                             # if varName == 'vr': secDic[secName]['vinit'] = point.__getattribute__(varName) 
                         except:
-                            print 'Could not read %s variable from point process %s'%(varName,pointpName)
+                            print('Could not read %s variable from point process %s'%(varName,pointpName))
 
         if pointps: secDic[secName]['pointps'] = pointps
 
@@ -385,7 +385,7 @@
     secLists = h.List('SectionList')
     if int(secLists.count()): 
         secListDic = {}
-        for i in xrange(int(secLists.count())):  # loop over section lists
+        for i in range(int(secLists.count())):  # loop over section lists
             hname = secLists.o(i).hname()
             if hname in dirCellHnames:  # use python variable name
                 secListName = dirCellHnames[hname]
@@ -396,9 +396,9 @@
         secListDic = {}
 
     # globals
-    globs = getGlobals(varList['mechs'].keys()+varList['pointps'].keys(), origGlob=origGlob)
+    globs = getGlobals(list(varList['mechs'].keys())+list(varList['pointps'].keys()), origGlob=origGlob)
     if 'v_init' in globs:  # set v_init for each section (allows for cells with differnet vinits)
-        for sec in secDic.values(): sec['vinit'] = globs['v_init']  
+        for sec in list(secDic.values()): sec['vinit'] = globs['v_init']  
 
     # clean 
     h.initnrn()
@@ -435,7 +435,7 @@
         f.write(connText)  # write starting text
         for row in range(1,numRows+1):
             if sheet.cell(row=row, column=colProb).value:  # if not empty row
-                print 'Creating conn rule for row ' + str(row)
+                print('Creating conn rule for row ' + str(row))
                 # read row values
                 pre = sheet.cell(row=row, column=colPreTags).value
                 post = sheet.cell(row=row, column=colPostTags).value
RefactoringTool: Writing converted netpyne/utils.py to netpyne_py3/utils.py.
RefactoringTool: Refactored netpyne/wrappers.py
--- netpyne/wrappers.py	(original)
+++ netpyne/wrappers.py	(refactored)
@@ -11,7 +11,7 @@
 __all__.extend(['create', 'simulate', 'analyze', 'createSimulate', 'createSimulateAnalyze', 'load', 'loadSimulate', 'loadSimulateAnalyze', \
 'createExportNeuroML2','importNeuroML2SimulateAnalyze'])  # wrappers
 
-import sim
+from . import sim
 
 ###############################################################################
 # Wrapper to create network
RefactoringTool: Writing converted netpyne/wrappers.py to netpyne_py3/wrappers.py.
RefactoringTool: No changes to netpyne/support/__init__.py
RefactoringTool: Writing converted netpyne/support/__init__.py to netpyne_py3/support/__init__.py.
RefactoringTool: Refactored netpyne/support/bsmart.py
--- netpyne/support/bsmart.py	(original)
+++ netpyne/support/bsmart.py	(refactored)
@@ -95,7 +95,7 @@
     try: # First, try the Cholesky decomposition
         output=linalg.cholesky(M)
     except: # If not, just return garbage
-        print 'WARNING: Cholesky failed, so returning (invalid) identity matrix!'    
+        print('WARNING: Cholesky failed, so returning (invalid) identity matrix!')    
         output=matrix(eye(size(M,0)))
     
     return output
@@ -234,7 +234,7 @@
     [L,N] = shape(x); #L is the number of channels, N is the total points in every channel 
      
     if freq==0: F=timefreq(x[0,:],fs) # Define the frequency points
-    else: F=array(range(0,freq+1)) # Or just pick them
+    else: F=array(list(range(0,freq+1))) # Or just pick them
     npts=size(F,0)
     # Initialize arrays
     maxindex=np.sum(arange(1,L))
@@ -298,11 +298,11 @@
     
     Version: 2011jul18
     """
-    from bsmart import timefreq, pwcausalr
+    from .bsmart import timefreq, pwcausalr
     from scipy import array, size
     
     if maxfreq==0: F=timefreq(vec1,rate) # Define the frequency points
-    else: F=array(range(0,maxfreq+1)) # Or just pick them
+    else: F=array(list(range(0,maxfreq+1))) # Or just pick them
     npts=size(F,0)
     
     data=array([vec1,vec2])
RefactoringTool: Writing converted netpyne/support/bsmart.py to netpyne_py3/support/bsmart.py.
RefactoringTool: Refactored netpyne/support/morphology.py
--- netpyne/support/morphology.py	(original)
+++ netpyne/support/morphology.py	(refactored)
@@ -1,6 +1,6 @@
 # Code adapted from https://github.com/ahwillia/PyNeuron-Toolbox under MIT license
 
-from __future__ import division
+
 import numpy as np
 import pylab as plt
 from matplotlib.pyplot import cm
@@ -80,7 +80,7 @@
 
     # get a list of the swc section objects
     swc_secs = i3d.swc.sections
-    swc_secs = [swc_secs.object(i) for i in xrange(int(swc_secs.count()))]
+    swc_secs = [swc_secs.object(i) for i in range(int(swc_secs.count()))]
 
     # initialize the lists of sections
     sec_list = {1: cell.soma, 2: cell.axon, 3: cell.dend, 4: cell.apic}
@@ -113,7 +113,7 @@
                         swc_sec.raw.getval(2, 0), sec=sec)
 
         j = swc_sec.first
-        xx, yy, zz = [swc_sec.raw.getrow(i).c(j) for i in xrange(3)]
+        xx, yy, zz = [swc_sec.raw.getrow(i).c(j) for i in range(3)]
         dd = swc_sec.d.c(j)
         if swc_sec.iscontour_:
             # never happens in SWC files, but can happen in other formats supported
@@ -554,10 +554,10 @@
             'section_orientation': h.section_orientation(sec=sec),
             'parent': my_parent,
             'parent_loc': my_parent_loc,
-            'x': [h.x3d(i, sec=sec) for i in xrange(n3d)],
-            'y': [h.y3d(i, sec=sec) for i in xrange(n3d)],
-            'z': [h.z3d(i, sec=sec) for i in xrange(n3d)],
-            'diam': [h.diam3d(i, sec=sec) for i in xrange(n3d)],
+            'x': [h.x3d(i, sec=sec) for i in range(n3d)],
+            'y': [h.y3d(i, sec=sec) for i in range(n3d)],
+            'z': [h.z3d(i, sec=sec) for i in range(n3d)],
+            'diam': [h.diam3d(i, sec=sec) for i in range(n3d)],
             'name': sec.hname()           
         })
 
RefactoringTool: Writing converted netpyne/support/morphology.py to netpyne_py3/support/morphology.py.
RefactoringTool: Refactored netpyne/support/stackedBarGraph.py
--- netpyne/support/stackedBarGraph.py	(original)
+++ netpyne/support/stackedBarGraph.py	(refactored)
@@ -182,7 +182,7 @@
             data_copy /= data_stack[levels-1]
             data_stack /= data_stack[levels-1]
             if heights is not None:
-                print "WARNING: setting scale and heights does not make sense."
+                print("WARNING: setting scale and heights does not make sense.")
                 heights = None
         elif heights is not None:
             data_copy /= data_stack[levels-1]
RefactoringTool: Writing converted netpyne/support/stackedBarGraph.py to netpyne_py3/support/stackedBarGraph.py.
RefactoringTool: Files that were modified:
RefactoringTool: netpyne/__init__.py
RefactoringTool: netpyne/analysis.py
RefactoringTool: netpyne/batch.py
RefactoringTool: netpyne/cell.py
RefactoringTool: netpyne/network.py
RefactoringTool: netpyne/neuromlFuncs.py
RefactoringTool: netpyne/pop.py
RefactoringTool: netpyne/sim.py
RefactoringTool: netpyne/simFuncs.py
RefactoringTool: netpyne/specs.py
RefactoringTool: netpyne/utils.py
RefactoringTool: netpyne/wrappers.py
RefactoringTool: netpyne/support/__init__.py
RefactoringTool: netpyne/support/bsmart.py
RefactoringTool: netpyne/support/morphology.py
RefactoringTool: netpyne/support/stackedBarGraph.py
Salvador-Duras-MacBook-Pro% 

** installing py3 to test
bash
conda create -n py35 python=3.5 anaconda
source activate py35
export PYTHONPATH=/usr/site/nrniv/local/python:/usr/arch/nrn/share/python/lib/python
unset PYTHONHOME

(py35) bash-3.2$ python
Python 3.5.2 |Anaconda 4.3.1 (x86_64)| (default, Jul  2 2016, 17:52:12) 
[GCC 4.2.1 Compatible Apple LLVM 4.2 (clang-425.0.28)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
>>> from neuron import h
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/usr/arch/nrn/share/python/lib/python/neuron/__init__.py", line 120
    print "Enabling NEURON+Python help system."
                                              ^
SyntaxError: Missing parentheses in call to 'print'

sam: need to recompile Neuron and specify python3

* 17Jun05 Debugging netpyne (forum q)
** Steps
1) netParams.py (error checking)
2) init.py 
-- error msgs (understand conceptual implementation)
-- verbose
-- inspect instanced net
-- results

** Possible causes
- netParams syntax,format,typo - error check should help
- netParams conceptual (eg. label doesn't exist) - error check
- netpyne bug

* 17Oct17 Fixing issue importing cell
** problem
Importing cell works in Penny's computer but not mine or Sergios
works = produces same outptu in NEURON/Py than in NetPyNE

** same code (penny+me)
*** NEURON/Py code
from CA229_PFC import *
import matplotlib.pyplot as plt
from neuron import h
import numpy as np
#import json
#import time
#import pdb     # For python debugging




cell = CA229()
cell.init_once()

Stim = h.IClamp(cell.soma[2](0.5))
Stim.dur = 300
Stim.delay = 200
Stim.amp = 0.2

t_vec = h.Vector()
t_vec.record(h._ref_t)
v_vec_soma = h.Vector()
v_vec_dend1 = h.Vector()
v_vec_dend2 = h.Vector()


v_vec_soma.record(cell.soma[2](0.5)._ref_v)
#v_vec_dend1.record(cell.basal[8](0.9)._ref_v)
v_vec_dend2.record(cell.basal[34](0.8)._ref_v)


h.tstop = 500
h.v_init = -67.3
h.celsius = 32
h.run() # plot voltage vs time


plt.figure() # Default figsize is (8,6)
plt.plot(t_vec, v_vec_soma, label = 'Soma[0](0.5)', color = 'blue')
#plt.plot(t_vec, v_vec_dend1, label = 'Basal[8](0.9)', color = 'green')
plt.plot(t_vec, v_vec_dend2, label = 'Basal[34](0.8)', color = 'red')
plt.ylim([-80, 60])
plt.xlim([0,500])
plt.legend(loc = 'best')
plt.show()

*** netpyne code
"""
params.py

netParams is a dict containing a set of network parameters using a standardized structure

simConfig is a dict containing a set of simulation configurations using a standardized structure

Contributors: salvadordura@gmail.com
"""

#import matplotlib; matplotlib.use('Agg')

from netpyne import specs
# from netpyne import sim
# sim.version()
# sim.gitChangeset()

netParams = specs.NetParams()   # object of class NetParams to store the network parameters
simConfig = specs.SimConfig()   # object of class SimConfig to store the simulation configuration

#netParams.scaleConnWeightNetStims = 1.0 #0.5  # scale conn weight factor for NetStims
###############################################################################
#
# MPI HH TUTORIAL PARAMS
#
###############################################################################

###############################################################################
# NETWORK PARAMETERS
###############################################################################

# Population parameters
##########

cellRule = netParams.importCellParams(label='PFC_full',conds={'cellType': 'PFC', 'cellModel': 'PFC_full'},
  fileName='CA229_PFC.py', cellName='MakeCA229')

netParams.cellParams['PFC_cell_rule'] = cellRule


data = netParams.cellParams['PFC_cell_rule']

#import json
#with open('CellRule.json','w') as output:
#    json.dump(data, output)
########## secName is the compartment name: soma_0, soma_1, basal_1, basal_2
#for secName,sec in cellRule['secs'].iteritems(): sec['v_init'] = -67.59

netParams.popParams['PFC'] = {'cellType': 'PFC', 'cellModel': 'PFC_full', 'numCells': 1}


#netParams.synMechParams['AMPA'] = {'mod':'GLU'}
#netParams.synMechParams['NMDA'] = {'mod':'NMDA','Beta': 0.01}


netParams.stimSourceParams['Stim'] = {'type':'IClamp','delay':200, 'amp': 0.2, 'dur':300}
netParams.stimTargetParams['Stim->PFC'] = {'source': 'Stim','conds': {'pop':'PFC'}, 'sec': 'soma_2', 'loc': 0.5}
#netParams.popParams['ST1'] = {'cellModel': 'NetStim', 'numCells': 1, 'rate':50, 'noise': 0, 'start':50, 'number': 1}
#netParams.popParams['ST1_1'] = {'cellModel': 'NetStim', 'numCells': 1, 'rate': 50, 'noise': 0, 'start':50, 'number': 1}
#netParams.popParams['ST2'] = {'cellModel': 'NetStim', 'numCells': 1, 'rate':50, 'noise': 0, 'start':50, 'number': 1}
#import itertools

#w_AMPA = list(itertools.repeat(0.00058, 20))
#loc_AMPA = list(itertools.repeat(0.6, 20))
###### Connectivity parameters
#netParams.connParams['ST1'] = {
#    'preConds': {'pop': 'ST1'},
#    'postConds': {'pop': 'PFC', 'cellModel':'PFC_full'},
#    'synMech': 'AMPA',
#    'weight': 0.00058,                    # weight of each connection
#    'delay': 10,
#    'synsPerConn': 10,
#    'sec': 'basal_34',
#    'loc': 0.6,
#    'threshold': -20}#
#

#netParams.connParams['ST2'] = {
#    'preConds': {'pop': 'ST2'},
#    'postConds': {'pop': 'PFC', 'cellModel':'PFC_full'},
#    'synMech': 'NMDA',
#    'weight': 0.02,                    # weight of each connection
#    'delay': 10,
#    'synsPerConn': 2,
#    'sec': 'basal_34',
#    'loc': 0.6,
#    'threshold': -20}



###############################################################################
# SIMULATION PARAMETERS
###############################################################################

# Simulation parameters
#simConfig.hParams = {'celsius': 6}
simConfig.duration = 500 # Duration of the simulation, in ms
simConfig.dt = 0.025 # Internal integration timestep to use
simConfig.seeds = {'conn': 1, 'stim': 1, 'loc': 1} # Seeds for randomizers (connectivity, input stimulation and cell locations)
simConfig.createNEURONObj = 1  # create HOC objects when instantiating network
simConfig.createPyStruct = 1  # create Python structure (simulator-independent) when instantiating network
simConfig.verbose = False  # show detailed messages
simConfig.hParams = {'celsius': 32, 'v_init': -67.3}

#'celsius': 32,
# Recording
simConfig.recordCells = ['all']  # which cells to record from
simConfig.recordTraces = {'V_soma':{'sec':'soma_2','loc':0.5,'var':'v'}}
simConfig.recordTraces['Bdend1'] = {'sec':'basal_34', 'loc': 0.8, 'var': 'v'}
simConfig.recordTraces['Bdend2'] = {'sec':'basal_34', 'loc': 0.5, 'var': 'v'}
simConfig.recordTraces['Bdend3'] = {'sec':'basal_34', 'loc': 0.3, 'var': 'v'}
#simConfig.recordTraces['Bdend'] = {'sec':'basal_34', 'loc': 0.8, 'var': 'v'}
simConfig.recordStim = False  # record spikes of cell stims
simConfig.recordStep = 0.1 # Step size in ms to save data (eg. V traces, LFP, etc)

# Saving
simConfig.filename = 'HHTut'  # Set file output name
#simConfig.Label = 'sim1'
simConfig.saveFileStep = 1000 # step size in ms to save data to disk
simConfig.savePickle = False # Whether or not to write spikes etc. to a .mat file
simConfig.recordStim = True
simConfig.saveJson = True # save to json file

# Analysis and plotting
simConfig.analysis['plotRaster'] = False  # Plot raster
simConfig.analysis['plotTraces'] = {'include': [0], 'overlay': True, 'saveFig': True, 'showFig': False}  # Plot raster
simConfig.analysis['plot2Dnet'] = False  # Plot 2D net cells and connections

from netpyne import sim
sim.createSimulateAnalyze(netParams = netParams, simConfig = simConfig)

import pylab; pylab.show()

** same/similar NEURON version
penny: NEURON -- VERSION 7.5 master (8c17845) 2017-06-22
me: NEURON -- VERSION 7.5 master (0388d94) 2017-08-09

** python version
penny: Python 2.7.13 |Continuum Analytics, Inc.| (default, Dec 20 2016, 23:05:08) 
me: Python 2.7.13 |Anaconda custom (x86_64)| (default, Dec 20 2016, 23:05:08) 

** netpyne version!
difference in netpyne: sim.replaceDictODict()
- due to an obscure bug resulting from using `isinstance()` instead of `type()` (isinstance takes into account inherited
classes, so was applied to wrong objects and messed up imported structures)

* 17Oct18 Implementing HNN's dipole
** chat with sam
samn [8:58 AM] 
looks like two components dipole.mod (non point process with pointer) dipole_pp.mod (point process)


salvadord [11:48 AM] 
not familiar with non-point process with pointer — any doc/notes on that ?


samn [11:49 AM] not much - stephanie developed that with michael hines a long time ago and then shane lee translated it to
python with michael's help


[11:49] 
maybe i should email steph/michael and cc you


[11:49] 
dipole_insert in cell.py has a few comments


salvadord [11:50 AM] 
I’ll check the code and if can’t figure out will let u know


samn [11:50 AM] 
mainly what dipole needs is the axial resistance and voltage in different locations so that it can calculate the axial current flow


salvadord [11:50 AM] 
ic


samn [11:51 AM] 
wonder if mh could add something for getting axial current in an easier way; similar to new feature of transmembrane current

* 17Oct18 Automating conversion from py2 to py3
** steps required and which can be included in py2
*** 2to3
convert everything, including examples and docs
*** DONE - replace global import sim with local in each func
- can probably be done now in py2
*** DONE fix import neuromlFuncs and analysis
- use py3 format
from . import x
import .x
*** DONE id32() encode utf-8
- use in py2 (error?)
return int(hashlib.md5(obj.encode('utf-8')).hexdigest()[0:8],16) 
*** DONE replace popen2 with Popen in batch.py
- not sure if Popen available in py2?

py2: output, input = popen2('qsub') # Open a pipe to the qsub command.                            

py3: proc = Popen(command.split(' '), stdin=PIPE, stdout=PIPE)  # Open a pipe to the qsub command.
    (output, input) = (proc.stdin, proc.stdout)
*** DONE replaced exec to import with importlib.import_module
- test in py2 - looks like more elegant solution

            # tempModule=None
            # exec(('import '+ moduleName + ' as tempModule'), locals()) # import module dynamically
            import importlib
            tempModule = importlib.import_module(moduleName)

*** DONE replaced x.setattr(...) with setattr(x,...)
- 4 occur in cell.py - more stable, use in py2


** create script to convert py2 to 3
# py2to3.py - convert netpyne py2 to py3
from subprocess import call

py2_root = '../netpyne_repo'
folders = ['netpyne', 'doc', 'examples']
files = ['CHANGES.md', 'README.md', 'sdnotes.org', '.gitignore']

for file in files:
	call(('rm %s'%(file)).split(' '))
	call(('cp %s/%s .'%(py2_root, file)).split(' '))

for folder in folders: 
	call(('rm -r %s'%(folder)).split(' '))
	call(('2to3 --output-dir=./%s -W -n %s/%s'%(folder, py2_root, folder)).split(' '))

** error checking error in py3
Traceback (most recent call last):
  File "/usr/site/python3/netpyne/netpyne/tests/tests.py", line 2849, in execRunTests
    self.testTypeObj.testIsBoolean(paramName)
  File "/usr/site/python3/netpyne/netpyne/tests/tests.py", line 257, in testIsBoolean
    assert (isinstance (val,bool) or val in [0,1]), "Value specified is " + str(val) + "."
AssertionError: Value specified is 0.1.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "init.py", line 8, in <module>
    sim.createSimulateAnalyze(simConfig = cfg, netParams = netParams) 
  File "/usr/site/python3/netpyne/netpyne/wrappers.py", line 73, in createSimulateAnalyze
    (pops, cells, conns, stims, simData) = sim.create(netParams, simConfig, output=True)
  File "/usr/site/python3/netpyne/netpyne/wrappers.py", line 25, in create
    sim.initialize(netParams, simConfig)  # create network object and set cfg and net params
  File "/usr/site/python3/netpyne/netpyne/simFuncs.py", line 72, in initialize
    simTestObj.runTests()
  File "/usr/site/python3/netpyne/netpyne/tests/tests.py", line 1520, in runTests
    self.runSimConfigTests() # load simConfig tests
  File "/usr/site/python3/netpyne/netpyne/tests/tests.py", line 2465, in runSimConfigTests
    self.execRunTests(simConfigTestObj, simConfigParams)
  File "/usr/site/python3/netpyne/netpyne/tests/tests.py", line 2857, in execRunTests
    print(str(testObj.errorMessageLevel[testIndex]) + ": " + str(testObj.messageText[testIndex]) + str(e[0]))
TypeError: 'AssertionError' object is not subscriptable

* 17Nov01 Issue reproducing PT cell results
** problem
- when run vs load from saved get different result
- also in old vs new version of netpyne where the way to convert netParams to dict changed
- saved netParams and net in json are identical in good vs bad version
** possible explanations/solutions
- order of mechs saved (order of instnatiation affects since dependent global variables?)
- global variables not saved properly

** solved
was due to using getattr() instead of x.get() when setting global variables

* 17Nov22 MPI error during gathering
** forum link
https://www.neuron.yale.edu/phpBB/viewtopic.php?f=45&t=3770&sid=7945c6bfcb495b22a4b3e72c0850d885
** testing
tried on zn
- 24 nodes gave error
- trying with:
simConfig.gatherOnlySimData = True
simConfig.saveCellSecs = False
simConfig.saveCellConns = False

only a couple traces actually recorded so small simData -- maybe bug because empty?
WORKED OK!

* 17Dec21 GUI
** setup
1) checkout and pull all branches:
Pavos-MBP% python gitall.py branches
NEURON_UI  development

org.geppetto.frontend.jupyter  development

org.geppetto.frontend  interface

Geppetto Neuron  interface 

1) npm install from
   /u/salvadord/Documents/ISB/Models/NEURON-UI/org.geppetto.frontend.jupyter/src/jupyter_geppetto/geppetto/src/main/webapp

2) in /utilities/ python run-dev-server.py

3) checkout and pull metadata branch in netpyne repo

** Extend GUI
- In browser open console + disable cache (eg. Network -> "Disable cache" with browser open) -- so changes in js take effect after reloading if run-dev-server.py running

- using javascript REACT -- component based

- start in:
/u/salvadord/Documents/ISB/Models/NEURON-UI/org.geppetto.frontend.jupyter/src/jupyter_geppetto/geppetto/src/main/webapp/extensions/geppetto-neuron

- render() method

- check imports for other components

** to check can import tut example
	
from neuron_ui.tests.tut3 import netParams, simConfig
netpyne_geppetto.netParams=netParams
netpyne_geppetto.simConfig=simConfig
neuron-ui

** create branch and then PR

** set background color
CanvasContainer.setBackgroundColor('#000')
** set cell cylinders
network.PT5B[0].setGeometryType('cylinders')
* 17Dec22 Extracellular recording (LFP) from Allen BMTK Bionet
** recxelectrode class 
https://github.com/AllenInstitute/bmtk/blob/develop/bmtk/simulator/bionet/recxelectrode.py
** simulation code
https://github.com/AllenInstitute/bmtk/blob/a20b10af77563e2dbebb8c2db7c3c8878783d0f9/bmtk/simulator/bionet/simulation.py

*** pre sim (deprecated?)
    def calculate_ecp(self, positions_file, ecp_output):
        """Set recording of the ExtraCellular Potential
        :param positions_file:
        """
        self._ecp_output = ecp_output
        self._calc_ecp = True
        self.rel = RecXElectrode(positions_file)
        for gid in self.gids['biophysical']:
            cell = self.net.cells[gid]
            self.rel.calc_transfer_resistance(gid, cell.get_seg_coords())

        self._rel_nsites = self.rel.nsites

        h.cvode.use_fast_imem(1)  # make i_membrane_ a range variable
        self.fih1 = h.FInitializeHandler(0, self.set_pointers)


*** compute and save after sim

   if self._calc_ecp:
            nsites = self.rel.nsites
            self.data_block['ecp'] = np.empty((nt_block, nsites))

-----

        # compute and save the ECP
        if self._calc_ecp:
            for gid in self.gids['biophysical']:  # compute ecp only from the biophysical cells
                cell = self.net.cells[gid]    
                im = cell.get_im()
                tr = self.rel.get_transfer_resistance(gid)
                ecp = np.dot(tr, im)
     
                if self.cell_variables and gid in self.gids['save_cell_vars']:
                    cell_data_block = self.data_block['cells'][gid] 
                    cell_data_block['ecp'][tstep_block-1, :] = ecp
      
                self.data_block['ecp'][tstep_block-1, :] += ecp


        if calc_ecp:
            self.im_ptr = h.PtrVector(self._nseg)  # pointer vector
            self.im_ptr.ptr_update_callback(self.set_im_ptr)   # used for gathering an array of  i_membrane values from the pointer vector
            self.imVec = h.Vector(self._nseg)


    def set_im_ptr(self): 
        """Set PtrVector to point to the i_membrane_"""
        jseg = 0
        for sec in self.hobj.all:  
            for seg in sec:    
                self.im_ptr.pset(jseg,seg._ref_i_membrane_)  # notice the underscore at the end
                jseg += 1

** cell methods required
    def calc_seg_coords(self, morph_seg_coords):
        """Calculate segment coordinates for individual cells"""
        phi_y = self._props.rotation_angle_yaxis  # self._props['rotation_angle_yaxis']
        phi_z = self._props.rotation_angle_zaxis  # self._props['rotation_angle_zaxis']

        RotY = utils.rotation_matrix([0, 1, 0], phi_y)  # rotate segments around yaxis normal to pia
        RotZ = utils.rotation_matrix([0, 0, 1], -phi_z) # rotate segments around zaxis to get a proper orientation
        RotYZ = RotY.dot(RotZ)

        # rotated coordinates around z axis first then shift relative to the soma
        self._seg_coords['p0'] = self._pos_soma + np.dot(RotYZ, morph_seg_coords['p0'])
        self._seg_coords['p1'] = self._pos_soma + np.dot(RotYZ, morph_seg_coords['p1'])

    def get_seg_coords(self):
        return self._seg_coords


    def get_im(self):
        """Gather membrane currents from PtrVector into imVec (does not need a loop!)"""
        self.im_ptr.gather(self.imVec)
        return self.imVec.as_numpy()  # (nA)

** insights
seg_coords['p0'] = array with the starting 3D point of each cell segment
seg_coords['p1'] = array with the ending 3D point of each cell segment


** implementation
*** specs.py
cfg.recordECP = True

*** cell.py
if cfg.recordECP:
 self.im_ptr = h.PtrVector(self._nseg)  # pointer vector
 self.im_ptr.ptr_update_callback(self.set_im_ptr)   # used for gathering an array of  i_membrane values from the pointer vector

    def set_im_ptr(self): 
        """Set PtrVector to point to the i_membrane_"""
        jseg = 0
        for sec in self.hobj.all:  
            for seg in sec:    
                self.im_ptr.pset(jseg,seg._ref_i_membrane_)  # notice the underscore at the end
                jseg += 1

*** network.py (or simFuncs.py?)
self.calc_seg_coords()  # use for computing the ECP

    def calc_seg_coords(self): -- call method in each cell
        """Needed for the ECP calculations"""
        for node_type_id, morphology in self.__morphologies_cache.items():
            morph_seg_coords = morphology.calc_seg_coords()   # needed for ECP calculations

            for node in self._local_node_types[node_type_id]:
                self._cells[node.node_id].calc_seg_coords(morph_seg_coords)

- calc seg coords for each cell class (relative to each morphology, so don't repeat) - calculate for 1 cell of each pop
- adapt to each cell by translating by x,y,z

*** simFuncs
if cfg.recordECP:
 set_ecp_recording()

    def set_ecp_recording(self):

        '''
        Set recording of the ExtraCellular Potential
        '''

        self.rel = RecXElectrode(self.conf)
        
        for gid in self.gids['biophysical']:
            cell = self.net.cells[gid]
            self.rel.calc_transfer_resistance(gid, cell.get_seg_coords())
        
        h.cvode.use_fast_imem(1)   # make i_membrane_ a range variable
        self.fih1 = h.FInitializeHandler(0, self.set_pointers)

    def set_pointers(self):    # set pointers to i_membrane in each cell             
        for gid, cell in self.net.cells.items():
            cell.set_im_ptr()

- calcualte ECP:
            for gid in self.gids['biophysical']: # compute ecp only from the biophysical cells
                 
                cell = self.net.cells[gid]    
                im = cell.get_im()
                tr = self.rel.get_transfer_resistance(gid)
                ecp = np.dot(tr,im)
     
                if self.conf['run']['save_cell_vars'] and gid in self.gids['save_cell_vars'] :
                    cell_data_block = self.data_block['cells'][gid] 
                    cell_data_block['ecp'][tstep_block-1,:] = ecp
      
                self.data_block['ecp'][tstep_block-1,:] += ecp


- store ECP in simData

* 17Dec23 LFP using Sam's simple method
** classes
from math import sqrt,pi

class currsource:
  def __init__ (self, ptr, x, y, z):
    self.ptr = ptr
    self.x = x
    self.y = y
    self.z = z
  def getcurr (self, elx, ely, elz):
    d = sqrt((elx - self.x)**2 + (ely - self.y)**2 + (elz - self.z)**2)
    if d > 0:    
      val = self.ptr[0]
      return val / d
    return 0.0 
  def getcurrd (self, d):
    if d > 0.0: return self.ptr[0] / d
    return 0.0 

class pointlfp:
  def __init__ (self, elx, ely, elz, lcurr = [], sigma=1.0):
    self.lcurr = lcurr
    self.elx = elx
    self.ely = ely
    self.elz = elz
    self.sigma = 1.0
    self.vlfp = []
    self.ld = []
  def setld (self):
    for currs in self.lcurr:
      self.ld.append(sqrt((self.elx - currs.x)**2 + (self.ely - currs.y)**2 + (self.elz - currs.z)**2))
  def calcv (self):
    if len(self.ld) < 1: self.setld()
    i = 0.0
    for currs,d in zip(self.lcurr,self.ld): i += currs.getcurrd(d)
    return i / (4.0*pi*self.sigma)
  def reset (self):
    self.vlfp = []
    self.ld = []
  def savev (self): self.vlfp.append(self.calcv())

** main network code
def pyrcurrsrc (cell,lcurrsrc):
  for sec in [cell.Bdend, cell.soma, cell.Adend1, cell.Adend2, cell.Adend3]:
    lcurrsrc.append(currsource(sec(0.5).pas._ref_i, cell.x, cell.y, getzpos(cell,sec)))
    lcurrsrc.append(currsource(sec(0.5).nacurrent._ref_ina, cell.x, cell.y, getzpos(cell,sec)))
    lcurrsrc.append(currsource(sec(0.5).kacurrent._ref_ika, cell.x, cell.y, getzpos(cell,sec)))
    lcurrsrc.append(currsource(sec(0.5).kdrcurrent._ref_ik, cell.x, cell.y, getzpos(cell,sec)))
    lcurrsrc.append(currsource(sec(0.5).hcurrent._ref_ih, cell.x, cell.y, getzpos(cell,sec)))
    lcurrsrc.append(currsource(sec(0.5)._ref_i_cap, cell.x, cell.y, getzpos(cell,sec)))
  lcurrsrc.append(currsource(cell.somaGABAf.syn._ref_i, cell.x, cell.y, getzpos(cell,cell.soma)))
  lcurrsrc.append(currsource(cell.somaAMPAf.syn._ref_i, cell.x, cell.y, getzpos(cell,cell.soma)))
  lcurrsrc.append(currsource(cell.BdendAMPA.syn._ref_i, cell.x, cell.y, getzpos(cell,cell.Bdend)))
  lcurrsrc.append(currsource(cell.BdendNMDA.syn._ref_iNMDA, cell.x, cell.y, getzpos(cell,cell.Bdend)))
  lcurrsrc.append(currsource(cell.BdendNMDA.syn._ref_ica, cell.x, cell.y, getzpos(cell,cell.Bdend)))
  lcurrsrc.append(currsource(cell.Adend3GABAs.syn._ref_i, cell.x, cell.y, getzpos(cell,cell.Adend3)))
  lcurrsrc.append(currsource(cell.Adend3GABAf.syn._ref_i, cell.x, cell.y, getzpos(cell,cell.Adend3)))
  lcurrsrc.append(currsource(cell.Adend3NMDA.syn._ref_iNMDA, cell.x, cell.y, getzpos(cell,cell.Adend3)))
  lcurrsrc.append(currsource(cell.Adend3NMDA.syn._ref_ica, cell.x, cell.y, getzpos(cell,cell.Adend3)))
  lcurrsrc.append(currsource(cell.Adend3AMPAf.syn._ref_i, cell.x, cell.y, getzpos(cell,cell.Adend3)))

def allpyrcurrsrc ():
  lcurrsrc = []
  for cell in net.pyr.cell: pyrcurrsrc(cell,lcurrsrc)
  return lcurrsrc

def makepflp (elx,ely,elz):
  plfp = pointlfp(elx,ely,elz,allpyrcurrsrc())
  return plfp

def recpyrcurr (cell,lrec,lx,ly,lz):
  xpos,ypos = cell.x,cell.y;
  for sec in [cell.Bdend, cell.soma, cell.Adend1, cell.Adend2, cell.Adend3]:
    reccurr(lrec,sec(0.5).pas._ref_i); savepos(lx,ly,lz,cell,sec)
    reccurr(lrec,sec(0.5).nacurrent._ref_ina); savepos(lx,ly,lz,cell,sec)
    reccurr(lrec,sec(0.5).kacurrent._ref_ika); savepos(lx,ly,lz,cell,sec)
    reccurr(lrec,sec(0.5).kdrcurrent._ref_ik); savepos(lx,ly,lz,cell,sec)
    reccurr(lrec,sec(0.5).hcurrent._ref_ih); savepos(lx,ly,lz,cell,sec)
    reccurr(lrec,sec(0.5)._ref_i_cap); savepos(lx,ly,lz,cell,sec)
  reccurr(lrec,cell.somaGABAf.syn._ref_i); savepos(lx,ly,lz,cell,cell.soma)
  reccurr(lrec,cell.somaAMPAf.syn._ref_i); savepos(lx,ly,lz,cell,cell.soma)
  reccurr(lrec,cell.BdendAMPA.syn._ref_i); savepos(lx,ly,lz,cell,cell.Bdend)
  reccurr(lrec,cell.BdendNMDA.syn._ref_iNMDA); savepos(lx,ly,lz,cell,cell.Bdend)
  reccurr(lrec,cell.BdendNMDA.syn._ref_ica); savepos(lx,ly,lz,cell,cell.Bdend)
  reccurr(lrec,cell.Adend3GABAs.syn._ref_i); savepos(lx,ly,lz,cell,cell.Adend3)
  reccurr(lrec,cell.Adend3GABAf.syn._ref_i); savepos(lx,ly,lz,cell,cell.Adend3)
  reccurr(lrec,cell.Adend3NMDA.syn._ref_iNMDA); savepos(lx,ly,lz,cell,cell.Adend3)
  reccurr(lrec,cell.Adend3NMDA.syn._ref_ica); savepos(lx,ly,lz,cell,cell.Adend3)
  reccurr(lrec,cell.Adend3AMPAf.syn._ref_i); savepos(lx,ly,lz,cell,cell.Adend3)
  return lrec,lx,ly,lz

def recallpyrcurr ():
  lrec,lx,ly,lz = [],[],[],[]
  for cell in net.pyr.cell: recpyrcurr(cell,lrec,lx,ly,lz)
  return lrec,lx,ly,lz

def genLFP (lrec,lx,ly,lz,elx,ely,elz):
  vlfp = h.Vector(lrec[0].size()); vtmp=h.Vector(lrec[0].size())
  for i,vec in enumerate(lrec):
    vtmp.copy(vec)
    d = sqrt((elx - lx[i])**2 + (ely - ly[i])**2 + (elz - lz[i])**2)
    if d > 0:
      vtmp.mul(1.0/d)
      vlfp.add(vtmp)
  sigma = 1.0 # arbitrary
  vlfp.mul(1.0/(4.0*pi*sigma))
  return vlfp
  
* 17Dec02 Implementing RxD
** celParams data model (inside cellParams)
- cellParams['rule1'] (dict)
-- ['rxd'] (dict)
--- ['Species'] (dict)
---- [label] (dict)
----- ['d': , 'name': , 'charge': ,...]
--- ['Region'] (dict)
---- [label] (dict)
----- ['secs': ]
--- ['Reaction'] (dict)
--- ['Rate'] (dict)
--- ['MultiCompartmentReaction'] (dict)
--- ['Extracellular'] (dict)

** cell instance data model (inside cell)
- Cell (object)
-- rxd (dict)
--- ['Species'] (dict)
---- [label] (dict)
----- ['d': , 'name': , 'charge': ,...]
--- ['Region'] (dict)
---- [label] (dict)
----- ['secs': ]
--- ['Reaction'] (dict)
--- ['Rate'] (dict)
--- ['MultiCompartmentReaction'] (dict)
--- ['Extracellular'] (dict)

** rxdParams data model (new attribute of netParams)
- rxdParams (dict)
-- ['Species'] (dict)
--- [label] (dict)
---- ['d': , 'name': , 'charge': ,...]
-- ['Region'] (dict)
--- [label] (dict)
---- ['secs': ]  % conditions to define cells that sections apply to
-- ['Reaction'] (dict)
-- ['Rate'] (dict)
-- ['MultiCompartmentReaction'] (dict)
-- ['Extracellular'] (dict)



* Steps to release new version
- Update CHANGES.md
- /netpyne/__init__.py __version__='0.7.8'
- gcp "VERSION 0.7.8" (from development branch)
- create PR from development to master (via https://github.com/Neurosim-lab/netpyne)
- make sure no conflicts and Travis tests pass 
- merge PR
- "bnp" alias (to build documentation)
- "npr" alias(to release on pip)
- Announce new release:
-- on github: https://github.com/Neurosim-lab/netpyne/releases
-- on NEURON forum: https://www.neuron.yale.edu/phpBB/viewtopic.php?f=45&t=3685&sid=9c380fe3a835babd47148c81ae71343e
-- on Google group: https://groups.google.com/forum/#!forum/netpyne-mailing
-- on Slack #netpyne
-- on Twitter (salvador account; create netpyne account?)

* Netpyne Models/Users
** Github examples folder
** Documentation tutorials
** M1 network (Salva, Neurosim)
** Parallel Neuron paper (Alex, Neurosim)
** Claustrum network (Jing, George Augustine)
** Sensorimotor network + arm (Cliff, Kerr lab)
** Hippocampus model (Ernie, Neurosim)
** OSB/NeuroML (Padraig UCL)
** V1 load/save model (Allen Brain Institute)
** STDP (Anatoly Buchin, Allen)
STDP in networks of biophysically detailed cells 
** Basal Ganglia (Lucas, UCD)
http://www.neuromuscularsystemsucd.info/research-areas
*** email
I made a new pull request into the development branch as requested. I am using Netpyne to model the Basal Ganglia network
using biophysically detailed and simplified spiking models. I am going to look at the effect of pathological oscillations on
task performance for motor tasks. One of the overarching goals of our group is to combine different models into a multi-scale
model of Basal Ganglia, spinal chord and motor units in the muscles, so I may use Netpyne for that too.  I appreciate all the
work that is made open source by your group. It helped me a lot while learning how to use the more advanced features of
Neuron using Python.  All the best, Lucas

** LFP oscillations (Fink, Ohio Wesleyan)
Christian G. Fink, PhD
Assistant Professor of Physics and Neuroscience
Ohio Wesleyan University

** Learning, dendritic computations (Birgit Kriener, Einevoll lab, University of Oslo)
** Thalamocortical epilespy (Andrew Knox, Cincinatti)
** Cortex, Schizophrenia (Cristoph Metzner, Hertfordshire)

** Spinal cord circuits (Vittorio Caggiano, IBM Watson)

** Convert hoc models (Ben Latimer, Missouri)
** Thalamocortical stimulation (Brenyn Jungmann, Nahir lab,Missouri)
** Fear circuits (Aliyah Taylor, Princeton/Missouri)

** Macaque M1 TMS/tDCS (Aman Aberra, Duke)
** CA1/CA3 (Mariane Bezaire, Boston University; Andras Ecker, HBP)
** EEG (Sam Neymotin, Boston)

** Cerebellum (Sergio Solinas)
** Cerebellum (Stefano Masoli, Univ Pavia)
** LFP in SUA vs MUA (Harry Tran) harrytran75005@gmail.com
the relationship between the single unit activty (SUA) and the multi unit activity (MUA) - 
so the LFP produced by a single neuron and its LFP in a population of neurons
** EEE network and single cell (JOe, Sergio)
** Ischemia with RxD
** EMAIL LIST
salvadordura@gmail.com
billl@neurosim.downstate.edu
samnemo@gmail.com
cliff@thekerrlab.com
btessler92@gmail.com
joe.w.graham@gmail.com	
james.chen@downstate.edu
ahseidenstein@gmail.com
andrew.knox@cchmc.org
penggao.1987@gmail.com
ramazan.tekin@batman.edu.tr
sergio.angulo@gmail.com
mitra.siddhartha@gmail.com
adrianquintana@gmail.com
matteo.cantarelli@gmail.com
foxy1987@gmail.com
christoph.metzner@googlemail.com
mdistasio@gmail.com
caggiano@gmail.com
jing.lim.12@ucl.ac.uk
davidkedz@hotmail.com
p.gleeson@ucl.ac.uk
anat.buchin@gmail.com
lucas.koelman@ucdconnect.ie
cgfink@owu.edu
birgit.kriener@medisin.uio.no
LatimerB@missouri.edu
bwjmbb@mail.missouri.edu
ali.taylor331@gmail.com
aman.aberra@duke.edu
marianne.bezaire@gmail.com
smgsolinas@gmail.com
bremen@fastwebnet.it
harrytran75005@gmail.com

* Related tools
** NEURON
Multiscale simulator
http://neuron.yale.edu/neuron/
\cite{Carn06,Lytt16}
** Genesis
Multiscale simulator
http://genesis-sim.org/
\cite{Bowe12}
** MOOSE
Multiscale simulator
https://moose.ncbs.res.in/
\cite{RayB08}
** NEST
Large scale network simulator
http://www.nest-simulator.org/
\cite{Ples15}
** Nengo
Large scale network simulator
http://www.nengo.ca/
\cite{Stew09}
** GeNN
Large scale network simulator (GPUs)
http://genn-team.github.io/genn/
\cite{Yavu16}
** Brian
Mathematically oriented simulator
http://briansimulator.org/
\cite{Good08}

** MUSIC
Multi-simulator tool
http://software.incf.org/software/music
\cite{Djur10}
** PyNN
Multi-simulator tool
http://neuralensemble.org/PyNN/
\cite{Davi09}
** NeuroConstruct
Multi-simulator tool
http://www.neuroconstruct.org/
\cite{Glee07}
** N2A
Multi-simulator tool
https://github.com/frothga/n2a
\cite{Roth14} 
** PyNeuroML/libNeuroML
Multi-simulator tool (for NeuroML2/LEMS models; combines libNeuroML, PyLEMS, jNeuroML)
https://github.com/NeuroML/pyNeuroML
\cite{Vell14}
** Topographica
Multi-simulator tool (focused on topographic maps)
http://ioam.github.io/topographica/
\cite{Bedn09}
** NetPyNE
Tool for design/simulation/analysis of multiscale networks in NEURON
https://neurosimlab.org/netpyne
\cite{Dura16c}
** Morphforge
Tool for design/simulation/analysis of single cell and simple nets in NEURON
\cite{Hull14}
https://morphforge.readthedocs.io
** AllenSDK
Tool for design/simulation/analysis of single cell and simple nets in NEURON
https://alleninstitute.github.io/AllenSDK/biophysical_models.html
** Mozaik
Multi-simulator tool; Batch simulation organization and analysis 
http://neuralensemble.org/docs/mozaik/index.html
\cite{Anto13}
** Lancet
Batch simulation organization and analysis
http://ioam.github.io/lancet/
\cite{Stev13}
** SimTracker
Batch simulation organization and analysis
https://bitbucket.org/mbezaire/simtrackercode
http://mariannebezaire.com/simtracker/
\cite{} - under review
** Sumatra
Batch simulation organization and analysis
http://sumatra.readthedocs.io/
\cite{Dav14}
** pypet
Parameter optimization; batch simulation organization and analysis
https://pypet.readthedocs.io
\cite{Meye16}
** BluePyOpt / HBP Collab GUI
Parameter optimization
https://github.com/BlueBrain/BluePyOpt  
\cite{VanG16}
** NeuroTune
Parameter optimization 
http://optimal-neuron.readthedocs.io/en/latest/ 
Mike Vella  and Padraig Gleeson
** Optimizer
Parameter optimization 
http://optimizer.readthedocs.io/en/latest/ 
\cite{Frie14b}
** NeuronVisio
Analysis and visualization
http://docs.neuronvisio.org/
\cite{Matt12}
** Geppetto/OSBViewer
Analysis and visualization
http://www.geppetto.org/
\cite{Glee15}
** NeuroML
Declarative format for neural models
https://www.neuroml.org/
\cite{Glee10}
** NineML
Declarative format for neural models
http://incf.github.io/nineml/
\cite{Raik12}
** Reaction-diffusion simulators
- RxD
- MCell
- Smoldyn
- STEPS
- NeuroRD
- PSICS
** Reviews / Other lists
- \cite{Bret07}
- \cite{McDo16}
http://software.incf.org/software/?getTopics=Computational%20neuroscience&b_start:int=0&-C=
http://software.incf.org/software?getTopics=Large%20scale%20modeling&-C=

* Paper
** Title
NetPyNE: a tool to develop, simulate and analyze data-driven biological neuronal network models
** Journal
- PLOS Comp Biol (similar to X-J Wang paper)
** Figures
- overview of netpyne stages
- structure of netParams
- how netParams specs translate to network: a) pops with yfrac, b) cell Model HH (import) vs Izhi, b) conn rules (eg. cell
  type, yfrac, pop)
- yfrac-based connectivity illustration - with real data
- sCRACM-based subcellular example - with real data
- simulation process - distribution of cells and gathering (cite Neural Comp)
- RL+STDP ... for behavioral task: arm (intervalUpdateFunc)
- Analysis: raster, hist, LFP, 2dnet, conn matrix
- Conversion to NeuroML: example of neuroml code? Gepetto/OSB visualization?
- Example nets: M1, claustrum, RL

* Grant (moved to grant folder /u/salvadord/Work/netpyne_grant/sdnotes.org)
** 16aug17 11:00 MBL bill discuss netpyne with hines - sald notesi []
- value of dictionaries would be a small lambda function that gives generality 

- two things i'd like to see -- notation is reasonable but very descriptive 
-- seems there would be a better way to organize it [similar to NeuroML but shorter; needs to be standardized format]
-- what can be additional value added for the user [easy creation, parallel sim and analysis of net; complex conn patterns simplified; subcellular; inputs]

-- ultimate would the the traub model -- very compact network level description of the traub model 13 cell types, ~128
  projection types -- 128 statements -- shouldn't have to write down the same things -- pij, weight, delay (cf NQS) [conn
  matrix can be converted to netpynec conn rules eg. M1; but need to write down same things so have consistent standard
  format for all nets, eg. some not based on pij, dist-dep, yfrac] 
-- extract all this from the current 15k line code [neuroml version can extract net instance; but will have to check manually
  for high-level conn rules]

- lambda function style encourages compactness; or def if used more than once [can use; string-based more compact and same effect; complexity of lambda: have to include arguments (eg. dist, x loc), not same for all rules]

- on the setup set -- instantiation -- target cells for a particular rank -- only setup on that rank
  due to the sources, building the netcon depends on location of the source; rules have SRC->TARG info so need to use the
  net-rendezvous-rank strategy (a common idiom used to resolve these problems)

- net-rendezvous-rank strategy: used if trying to decide if something exists or not; can't answer question unless all of the
  types exist but they exist randomly distributed across all the ranks so have to gather info from all the ranks; were do we
  meet?  -- we don't meet at a single master;  we are in double loops (for targ over TARG for src over SRC) -- 
  here's the answer:  we rendezvous at target_gid%nhost to decide  [can implement in netpyne]

- bad (but still common) idiom: sometimes useful to do net-rendezvous-rank in 2 phases - build round-robin system first and
  then throw away and rebuild with balanced distribution 

- I mentioned mark hereld example of an interactive HPC (also cf vslice) sim that is managed thru a remote GUI [netpyne GUI,
  OSB gepetto, new NEURON GUI, NSG]

- change name? -- NetPyNe sounds to much like PYNN -- mh also works with Andrew Davison so would like to avoid  the apparent
overlap; domain of PYNN -- metasimulator to construct models in NEURON, NEST, BRIAN, using neuromorophic  simulators
  (spinnaker, analog VLSI); NeuroML, MUSIC (multi-simulator-coordinator == lower level data interchange) in somewhat similar
  domains [mostly phonetic similarity; many python packages have py so similar; discuss with Andrew in Janelia]

 
- look into Nengo -- language used to put together Eliasmith -- prob has a good network connectivity algorithm/layout 
  https://pythonhosted.org/nengo/examples/network_design.html: 'def motor_cortex(command_threshold, n_neurons_per_command=30)'
  https://pythonhosted.org/nengo/examples/network_design_advanced.html?highlight=tips%20tricks [included most of NEST conn
  features + others; Nengo very artificial non-bio eg. implement math funcs using spiking neurons]

- separate issues: advantages of branch failure; cf Paul Rhodes branch point failure [?]

** 16aug26 MBL meeting (sald notes)
*** Reverse engineering
- inverse problem: approximation, computer-aided design
- use GA to aid in the inverse problem
- netpyne can generate initial attempt to inverse network; then user can update the randomizer functions etc based on the
  source code
- modelview gets lowest hangin fruit, but netpyne could do more sophisticated analysis to extract features
- network
-- find cell types
-- connections to other types etc
-- given projection is there a constant/pattern that can be reverse engineered, convergence
- Try out example of reverse engineering -- maybe CA3 model
- reverse engineer data - eg. M1 model have physio + conns and turn into model
- netpyne can import cells from hoc template or cell class instance
- people have done before -- create model that generates data, and from data use Bayesian learning to infer params
- 1000 noisy channels, get data and do experiments to get back params of sodium channels back
- eg. get maximal conductance param from data - maximum likelihood (won't be same since noise)
- hidden parameters that have to be informed - markov model 
- process noise + experimental noise - log likelihood 
- always wrong - only approximation

- 3 approaches:
-- 1) current modeldb - get approx same rule
-- 2) GA - get different rule from original 
-- 3) BRAIN (reality)

*** Evolutionary
- What to optimize
-- 1) GA - Learning params (eg. learning rate)
-- 2) High-level specs (eg. prob of conn)
-- 3) Network instance params (eg. explicit weights) 

- What to invert from GA generated network
-- 1) High-level specs (eg. prob of conn)
-- 2) Dynamical properties (can be used to fit)

*** Aim 1
- Brett et al 

*** grant approach
- we have done this in the last 5 years - can we do this for the next 5 years

- significance
- innovation
- investigator


*** redefine aims
- Aim 1: front end
-- GUI
-- dendritic connectivity

- Aim 2: back end
-- rendezvous

- not good - front vs back

- make Aim 2: parallelization
-- parallelize setup - rendezvous
-- load balance
-- parameter optimization (evol etc)

*** subworlds
- set of nodes working on same networks
- can have 10 subworlds, each for 1 net
- bulletin board - old 1994 - currently master but could be done as distributed bulletin baoard

*** GUI
- interface to create network
- 
- simtracker managing of sims
- simtracker summary of model data

** 16aug26 Bill notes
*** get output of modelview to read the flat instantiated model but currently doesn't do networks well
*** Aim3 modelview outputs a small subset of cells (sees different templated / ?classes) and can export to netpyne 
finds commonality also by common parameters, morphologies
random values in 1 location -- can't currently find it -- could find distributions but can't find random seed (a cryptographic solution)
does the netpyne and original create the same net -- Sub## are two networks identical
Sub## netpyne description of the flat file -- straightforward
subroutines for inverting random distros --- eg sampling without replacement -- if pick 50 out of 1000 
*** can apply GA to the high level expression -- 
NetPyNe expresses it and modelview interprets it 
*** LEMS, LEMD (low entropy model description)
*** current traub 20k fortran model to 20k hoc model 
*** often have to factor out what is different among very similar fragments
*** should we start with the single cell?  -- could that be the main piece to do here Sub3.x 
cell build session file vs netpyne description; hoc file written by cell builder
cell templates are usually never touched -- get a few
PRELIM Data -- netpyne currently create instances and then reads those instances
*** what are the metrics of similarity? -- how are we going to compare whether the output is good enough
not currently much randomness in the modeldb models
*** networks have been very program specific in the past and network construction is embodied in the code -- 1st step is to
get rid of code accidents
*** Aim3.x --- CAD vs fully automated
CAD -- stick randomizer here 
universals -- number of cells, how many types (small # of types based on morphology with minor variations)
modelview currently only gets the lowest of low hanging
*** same heuristics that are used for cells can be used for networks - whole pool of connections
1. draw circles around all the types; 
2. in that type are there connection to every other type or to a few types
3. given a projection is there a constant or a distribution (make some usual assumptions -- eg, no 2 projections to 1 cell --
without replacement);  what are the statistics of the projections; what those 35 cells are is random ?
*** try one with 3 types - CA3 -- try to catch up with ernie
*** HBP - read in 1e4 morphologies of 100 morphoelectric sites and Peter's principal 
*** BRAIN -> modeldb -> we will reverse engineer M1 which we're already doing
*** figure of merit -- size of the original code vs size of the final netpyne description
*** how to create the network -- how to grow networks; growing networks; find some emergent rules
just use GA on a set of parameters -- cell params and weights
learning network -- RL or other, homeostatic plasticity 
grow from axon growth cone rules  -- or GA on probabilities
2 step growning -- grow the learning rules and then grow the network
emergent properties -- dynamical properties, properties of network organization (not an inverse problem)
  do the netpyne solutions give networks with dynamical properties that are similar to that seen with the grown network
*** a lot of times algorithms for analysis need to look at places that you have the answer -- you don't care that it's not
exact; need to see that 
reduction problem from a 3D net to a stylized
Bush and Sejnowsi -- reduce to a small cell that captures the dynamics of the big cell  (Pinsky and Rinzel, Michele, Ted, HBP)
*** approach of having a test example of algorithms -- explore algorithms used for optimization - does your fitness function
of getting back an optimal similar to the other model -- Sean Carver did this Bayesian optimization of ion channels
1. develop a model (HH type channel model); 2. output data; 3. learn model with Bayesian algorithm from single channel data
1000 Na channels so a noisy set -- what experiments can you do on this system to get back the parameters of the channel
Bayesian == maximum likelihood -- a parameterized model ; a noisy system; let's say only param is gbar -- let's retrieve it
orig data had randomness in it -- any model could create this but likelihood is low if the params isn't correct but even if
correct won't get the data exactly since seed wasn't same
practical difficulty 
markov model contained some hidden parameters so that had some states for which had no data
one problem with least squares on trajectories is that least squares depends on the 'fact' that every point on the curve is
  independent ; it's a curve not a bunch of random points -- least squares is missing the parameterization
*** two kinds of noise -- process noise and experimental noise (artifact)
forcing it to be on the original data trajectory -- what's the likelihood that it's actually on that trajectory -- extremely
small so work with log(likelihood)
*** doing an AP in a model -- you are close to threshold so any kid of noise will cause a spike at any time or no spike at all
*** statistical philosophy -- you can take any amount of data out of my distribution; want to know the mean of my distro
  can take different ones and end up with a lot of means -- is your distribution of means which should be gaussian? what is
  distro of the mean -- this now is recursive
mean can be very different from what you find
expectation value if the anomalous card had a very large value associated with it
maximum likelihood - 95% likelihood but now can run 1e6 times and see ideally would see that 95% but only see 90% so is 90%
close enough to 95% so that that is the same follow
*** new way of organizing grants -- this is what we published in last 5 years -- is this good enough to continue
*** LEMD == low-entropy model description, simplified model description, high-level model description, logical model description
*** Aim 1 RxD part is innovative
subcellular connectivity -- dendritic connectivity; deal with regions of the cell
have to define the regions -- make a description that is indep of the specific morphology
NeuronDB canonical cells -- medial proximal distal; basal apical axonal; 1st order, 2nd order, 3rd order; yfrac, distances from soma
linear dec in IH, IA are functions of distance from soma
do we want to find basilar dendrites? -- define cells 
*** hoc uses strings and python traditionally uses callables but we're using strings here; lambdas are not particularly interesting
give an explain as to why we use strings rather than lambda func -- nothing exists until it's instantiated
*** why do we use python -- python gives flexibility for things like error checking interactively
*** arbitrary keys (with arbitrary values) can be used in values
*** Aim 4: GUI enter rules into a form that computes the netpyne file
fill in the blanks
pictorial stuff - drag&drop? 
problems of the outsider -- what is the meaning of the terms that are obvious to the inventor? -- eg probability defined by a sin function??
incorporate -- pdf -- probability distribution function
biased distribution since no cells with too many or too few connections -- use convergence or divergence in netpyne
*** how to do parallel setup -- integrate rendezvous rank in netpyne so all the implicit loops are parallel loops
*** split up aims based on User Experience: Aim 1 -- include GUI?) 
vs Aim 2: BackEnd -- parallel setup (rendezvous rank, use hash to find the node where you will rendezvous), evolutionary algorithms, 
(5,3,7).__hash__()%1024 # 87 so can rendezvous on 14 -- #40 wants that and #375 has it so can find out where to send
  (send the key of key:value or send the hash)
collecting data can also use this use %10 to collect 10 files in 10 places
*** instantiating on 64k nodes -- everyone has the description but no one can see the whole model
can get in TACC or SDSC
*** running tests and benchmarks -- standard tests
*** outer loop of targets (exist on a particular node), inner loop of sources 
   does everyone need to know about all targets -- we hope not
gid contains no information about the cell unless you ask for it
*** can hash the dict for describing a pop2pop connection -- node has a target or set of targets that know what set of sources
they are looking for -- the source population doesn't exist anywhere (it's just a conceptual object; NB the source population
(or target pop) will not fit on any node)  -- src gids have to declare themselves and made note of their node location
NO - not so easy since the rules at the target will be intersections and unions of rules known at a source
UHOH being when src->targ based on distance and then only define based on relation of src to targ
pc.gidconnect(srcgid)
for cell in targets: for netpyne_sources ,,,,
relationship of target to source -- no common hash -- each one has a hash -- the target knows what sources it's looking for
and the sources know what targets it's looking for
*** distance -- can be handled in general - the hash is the rule -- everyone now in the same place -- the master
handle with a specialized algorithm;  any rule that involves pruning is ok; as long as only get a reasonable size subet
*** testing on megamachines is one reason we want to have a bunch of models to work with -- Traub, CA3, M1, Soltesz
*** Aim 2 could be parallel assistance, fun with parallel
1. rendezvous rank for setup
2. load balance -- can always reduce to a round robin
3. parameter optimization evolve,GA (subworlds)
*** subworlds: doing allgather needs to be restricted to a subset of ranks so that those are doing the same problem
then use bulletin board to throw out the networks -- bulletin board is a master/worker style of computation
  could do bulletin board as a 'distributed bulletin board' (could be wasteful) -- Linda idea was distributed BB
extremes is 1 subworld or 1 node per network and all bulletin board
*** what are the modern ideas for distributed databases 
*** model, view, controller
*** graphical introspection -- what created this graph? -- do something by analogy; find something similar to what you want to do and modify
*** declarative programming vs procedural -- Backus notation
http://maude.cs.uiuc.edu/maude2-manual/html/maude-manualch1.html
is there a grammar of networks?  can we invent one?  would it be useful?  -- NO, NO, NO
the more that things correspond to reality the more likely they are to persist whereas when you are abstract a slight change
  in perspective obviates the prior results
*** Nengo -- draw lines between networks
*** representation of the network instance -- exhaustive --- each cell has the full set of properties repeated or reference to
some shared prototype -- each of the cells which are closely related have a shared representation with separate randomizers
*** appropriate scaling -- typically scale down the weights if increase the convergence with increased network size
once you get up to 1e4 no longer allow more convergence with increased network size
scale is critical for debugging since need to work with a small networks or hybrid networks
reduce to ART_CELLS --- can do that
*** generate the network and save the network -- save to disk, save on subworlds, modify a model in netpyne
remove a cell and dump the network back to netpyne -- idea of cell death different from another indstance of the network

** 16dec02 meeting at yale
- This tool will subsequently be expanded to allow it to automate the process of employing new data being gathered by ongoing
  efforts (BRAIN, HBP, Allen) to define specific brain networks and their cellular constituents. 
-- eveything data-driven, clarify to what extent 

- NEURON, including the intracellular molecular reaction chains for metabotropic synapses, a level of detail not provided by
  most neural  simulators. We are also building in the ability to readily handle variant hybrid networks, where some cells
  are modeled in great detail (MC cells)
-- 

- All of the parts, all of this complexity, will remain under the umbrella of a single conceptual model designed using
  NetPyNE
--

- NetPyNE already supports the use of a simple spike-timing dependent plasticity (STDP) mechanism, which has been used to
  develop a model of sensorimotor cortex that learns to drive a musculoskeletal arm model via reinforcement learning.

- provide facilities for readily varying hybrid networks so that, for example, the many runs needed for parameter exploration
  would be done with only a few MC cells,
-- still complicated to switch in a biological sense -- need to take into account if connections change as a func of more
biophys cell model
-- computer-assisted

- SA1 - comparison of original Traub model with netpyne version

- Dont have space to put everyhting or say already done it -- appropriate prelim results that give credibility to what you
  are going to do:
-- eg. Traub model

- Netpyne is an organizational method for promoting conceptual control
-- the more compact, lower entropy 
-- tends toward entropy, but also organizes into conceptual blocks without having the whole model in your head

- without programming expertise - red flags
-- use templates, can change parameters in isolated ways

- high-level parameters to describe complex synaptic distribution
-- include figs of sCRACM -> syn distribution

- code optimization methods might be required to make the process feasible
-- algorithmic optimization

- A second premise is that there is not enough memory in any one process to hold a mapofwhichranksholdwhichobjects.
-- a map supplied by single process does not scale

- example of within dependent pre-and post-synaptic cell condition -- = not dist dependent

- The simple random distribution of cells evenly on all processors provides a performance baseline for comparison with more
  sophisticated distribution algorithms, such as dynamic load balance and least processing time algorithm 
-- only used round-robin or least-processing time

- However, it transiently requires twice the memory of the model, does not handle (the rare case) of mod files that use
  POINTER, and typically shows no improvement for single thread models
-- not true, significant

gid compression is only available if each processor owns fewer than 256 cells
- 16 -- from 12 to 2 -- could be to 3 or 4

- the NEURON Subworlds feature has not been extensively used or tested and is based on an old implementation. Its efficiency
should be evaluated and the implementation improved if deemed necessary.
bulletin board does nto scale because of master rank -- 

- remove grid search

- reverse eng - spy skulduggery -- remove


** Questions 
*** GPU will be available for all users of just HBP? include in grant that netpyne will support?
- yes will be available in core neuron - so open source, can be added to netpyne
*** load balancing techniques? papers 

*** Netpyne integrated with NEURON?


* TODO (moved to Github issues - 16may31)
** DONE - unify cellmodel 
- cell prop conditions: 
-- cellType=RS; cellModel=HH
-- cellType=RS; cellModel=Izhi
- provide option to insert distribute mechanism or point process
- single cell class 
- then add support for 2007a - spikes+record from izh._ref_V

- INCLUDE BOTH HH AND IZHI IN SAME RULE AND USE CELLMODEL TAG IN CELL TO CHOOSE WHICH TO USE!!

** DONE - Overwrite files optional (timestamp)
** DONE - Default simConfig
** DONE - Import cells with generic set of arguments
** DONE - Use mechanismType to make importCell more robust
https://www.neuron.yale.edu/neuron/static/new_doc/modelspec/programmatic/mechtype.html
https://www.neuron.yale.edu/neuron/static/new_doc/programming/mechstan.html
http://neurosimlab.org/ramcd/pyhelp/mechstan.html#MechanismStandard - 2nd example

- use params with initial underscore '_var' to indicate used by netpyne, not mechanism/pointprocess variable - add to docu!
** DONE Check Izhi2007a
** DONE Distinguish syns from other point processes 
- no way to do it
- assume 'syn' in name -- establish naming convention -- added to doc

- syn: true, false, false (.is_netcon_target() = True; .has_net_event(i) = False; .is_artificial() = false)
- artcell: true, true?, true
- izh2007a: true, true, false
- izhi2007b: true, false, false

MechanismType.is_netcon_target()
Syntax:
boolean =  mt.is_netcon_target(i)
Description:
The i'th point process has a NET_RECEIVE block and can therefore be a target for a NetCon object.

MechanismType.has_net_event() 
Syntax:
boolean = mt.has_net_event(i)
Description:
The i'th point process has a net_event call in its NET_RECEIVE block and can therefore be a source for a NetCon object. This
means it is NetCon stimulator or that the point process can be used as an artificial neural network cell.

MechanismType.is_artificial() 
Syntax:
boolean = mt.is_artificial(i)
Description:
The i'th point process is an ARTIFICIAL_CELL and can therefore be a source for a NetCon object. This means it is NetCon stimulator or that the point process can be used as an artificial neural network cell.

This seems to have, but does not, equivalent functionality to has_net_event() and was introduced because ARTIFICIAL_CELL
objects are no longer located in sections. Some ARTIFICIAL_CELLs such as the PatternStim do not make use of net_event in
their implementation, and some PointProcesses do use net_event and must be located in sections for their proper function,
e.g. reciprocal synapses.

** DONE Make list of data saved part of simCfg
- simConfig, netParams, net, simData
- added to docu

** DONE Test importing Friesen, mainen, traub cell models
- Read python names in importCell
-- use dir; check if section; compare with secList

- 'synReceptor' check for syn type not name

** DONE Associate_gid from axon
- section['spikeGenLoc'] = 0.5

** DONE HDF5
- tried h5py (http://docs.h5py.org/en/latest/quick.html)
Saving output as example-20160108_200403.hdf5... 
Traceback (most recent call last):
  File "init.py", line 24, in <module>
    f.sim.saveData()                    # save params, cell info and sim output to file (pickle,mat,txt,etc)
  File "/usr/site/nrniv/pypkg/netpyne/sim.py", line 346, in saveData
    hickle.dump(dataSave, f.cfg['filename']+'.hdf5', mode='w')
  File "/u/salvadord/anaconda/lib/python2.7/site-packages/hickle.py", line 376, in dump
    dumper(obj, h5f, **kwargs)
  File "/u/salvadord/anaconda/lib/python2.7/site-packages/hickle.py", line 300, in dump_dict
    _dump_dict(obj, hgroup, **kwargs)
  File "/u/salvadord/anaconda/lib/python2.7/site-packages/hickle.py", line 282, in _dump_dict
    _dump_dict(dd[key], new_group, **kwargs)
  File "/u/salvadord/anaconda/lib/python2.7/site-packages/hickle.py", line 269, in _dump_dict
    hgroup.create_dataset("%s" % key, data=dd[key], **kwargs)
  File "/u/salvadord/anaconda/lib/python2.7/site-packages/hickle.py", line 88, in create_dataset
    return super(H5GroupWrapper, self).create_dataset(*args, **kwargs)
  File "/u/salvadord/anaconda/lib/python2.7/site-packages/h5py/_hl/group.py", line 94, in create_dataset
    dsid = dataset.make_new_dset(self, shape, dtype, data, **kwds)
  File "/u/salvadord/anaconda/lib/python2.7/site-packages/h5py/_hl/dataset.py", line 79, in make_new_dset
    tid = h5t.py_create(dtype, logical=1)
  File "h5t.pyx", line 1389, in h5py.h5t.py_create (h5py/h5t.c:13046)
  File "h5t.pyx", line 1463, in h5py.h5t.py_create (h5py/h5t.c:12893)
TypeError: Object dtype dtype('O') has no native HDF5 equivalent

- tried hdf5storage (http://pythonhosted.org/hdf5storage/introduction.html#getting-started)
Traceback (most recent call last):
  File "init.py", line 24, in <module>
    f.sim.saveData()                    # save params, cell info and sim output to file (pickle,mat,txt,etc)
  File "/usr/site/nrniv/pypkg/netpyne/sim.py", line 348, in saveData
    hdf5storage.write(dataSave, filename=f.cfg['filename']+'.hdf5')
  File "build/bdist.macosx-10.5-x86_64/egg/hdf5storage/__init__.py", line 1399, in write
    
  File "build/bdist.macosx-10.5-x86_64/egg/hdf5storage/__init__.py", line 1318, in writes
    
  File "build/bdist.macosx-10.5-x86_64/egg/hdf5storage/lowlevel.py", line 114, in write_data
  File "build/bdist.macosx-10.5-x86_64/egg/hdf5storage/Marshallers.py", line 1557, in write
NotImplementedError: Dictionaries with non-unicode keys are not supported: 'netParams'

- try this: http://stackoverflow.com/questions/16705274/fastest-way-to-convert-a-dicts-keys-values-from-str-to-unicode

- converted to unicode using dict2utf8() func, but now get segmentation fault for all except simConfig dict

- empty dicts {} caused seg fault -- replaced with []

** DONE Enable providing num spikes in Netstim (paper)
** DONE Set v_init before calling init() (paper)
- netParam param
- 'vinit' param in section
- automatically set vinit=vr for izhis - not needed cause fixed mod
- add to doc

** DONE Conv and div conn (paper)
- made conn very flexible by allowing function for: prob, conv, div, weight and delay
- funcs can include spatial/distance variables; and others defined in netParams
- can implement a large range of functionalities with very generic implementation
** DONE Add x,z,xnorm,znorm positions (paper)
** DONE Plot cell from specific population (paper)
- and or one of each population

** DONE Allow to define xrange and zrange of pops
- also xfracrange and zfracrange
- for fixed cell density, easy, just don't calcualte rand
- for functional density more complex
- make generic so no distinction between coordinates
** DONE Fix NetStim connectivity
- no convergent or divergent; only full and prob
** DONE fix so lambda funcs saved as string
** DONE setup.py pip install (paper)
** DONE timing (paper)
** DONE Record subset of time, and only record traces for subset of cells
- recordTraces = ['all', 'P', 1]
- plotTraces = ['all', 'P', 1]

- pops means just 1 cell of that pop!
- automatically add elements of plotTraces to recordTraces!!

** DONE Fix pops starting with same characters
EMstim == EM !!
** DONE Add support for SectionLists (paper)
- also when importing

** Rename point process '_type' -> 'mod', '_loc' -> 'loc'
** Import synapses into synMechParams
** Cell position in ellipsoid 

** Subcellular synaptic connectivity (paper)
- distribution of syns across segments based on empirical map
- concept of logical connection subsumes subset of unitary connections
** simple LFP (paper) 
- simple voltage sum 
** Plot conn matrix (paper)
- by cells and populations
** import/export NeuroML (paper)
- padraig (see notes above)
** Functions to load simConfig, netParams, net, simData (paper)
** importCell can modify h variables (eg. celsius) (paper)
- maybe just note in documentation that shouldnt modify h.vars - undesired effects

** import python lists of sections (equivalent hoc sectionLists)

** DONE Plasticity (paper?)
- Hebbian
- STDP

** Stimulation - iclamp,vclamp, opto, microelectrode (paper?)
- maybe iclamp for paper?
- can implement via pointp in cell properties? - no, so can assign to multiple
- create new struct stimParams

netParams['stimParams'] = []
netParams['stimParams']['sourceList'].append({'label': 'Input_1', 'type': 'IClamp', 'delay': 0.1, 'dur': 0.5, 'amp': 0.5})
netParams['stimParams']['stimList'].append({
	'source': 'Input_1', 
	'sec':'soma', 
	'loc': 0.5, 
	'conditions': {'pop':'PYR', 'cellList': [0,5]}})




in NeuroML:

   <pulseGenerator id="Input_1" delay="0.1s" duration="0.5s" amplitude="6.0E-10A"/>
    <pulseGenerator id="Input_0" delay="0.1s" duration="0.5s" amplitude="1.0E-10A"/>

        <inputList id="Input_1" component="Input_1" population="pyramidals">
            <input id="0" target="../pyramidals/0/pyr_4_sym" destination="synapses"/>
        </inputList>


** Upload examples to netpyne repo (paper)
- Evol params batch
- virtual arm with RL+STDP
- robot control

** User input error checking
eg. getattr(a,b, DEFAULT VALUE!)
** Travis CI
test automatically examples
** Set positions in Neuron's 3D space
** LFPy
cliff?
** Save plots to file
** Conn/props just in master node
** normalized transfer entropy (nTE)
cliff?
** Granger causality
cliff?
** 3D animation of network
- use johns code
** Add support for point neuron outside of section
eg. IntFire1,2,3,4 
 ARTIFICIAL_CELL means
     3 	: that this model not only has a NET_RECEIVE block and does NOT
     4 	: have a BREAKPOINT but is not associated with a
     5 	: section location or numerical integrator. i.e it does not
     6 	: refer to v or any ions or have a POINTER. It is entirely isolated
     7 	: and depends on discrete events from the outside to affect it and
     8 	: affects the outside only by sending discrete events.

- outside of section so need different method - maybe not worth? 

** RxD 
/u/samn/m1dyst -> models/m1dyst
https://www.neuron.yale.edu/neuron/static/docs/rxd/index.html
** recreating spikes
 
Setting up the re-simulation utilizes {\tt PatternStim} to feed the spikes back into the single cell.  The setup code is

pattern = h.PatternStim()
pattern.fake_output = 1
pattern.play(tvec, idvec)
** Saving at intervals
** modify instantiated network
- don't destroy NEURON objects, so can interact with them
- load net and provide new set of params
** Add sim options for efficient parallel sim
- add timing of computational vs exchange
- load balance
- cvode.cache_efficient
- compress spikes
- bin queue

** Save space using __slots__
http://tech.oyster.com/save-ram-with-python-slots/
** Make simulator-indep using NeuroML internal format
** GUI
** Test adaptive exp cell (no Neuron code)
student doing
** Make opensource with contributions from community
There are several ways to contribute to PyNN:

reporting bugs, errors and other mistakes in the code or documentation;
making suggestions for improvements;
fixing bugs and other mistakes;
adding or maintaining a simulator backend;
major refactoring to improve performance, reduce code complexity, or both.
** DONE Replace search in list with next()
a = next((i for i in userInput if i in wordsTask), None)
** Netstim with different types of random input
- emphasize alpha, beta, gamma
- external pre-recorded signal

** Allow range of properties
eg. 'gnabar':[0.11, 0.13] and each cell being assigned a random value within that range
** Wrappers to change properties interactively both of NEURON+netpyne object
maybe can define generic wrappers for some of the most common cases; maybe include within same global wrapper that checks which needs to be used
** generate interactive net struct from code
- collapse/expand
http://neurosimlab.org/netpyne/_images/netstruct.png
** add units
- uS for synMech weight
** DONE Netstim default start
** Plot cell subset of each population, indicating relative index
** DONE ? Connection function with specific connections
- fromList 
- relativePreIds
- relativePostIds
- connList

** DONE Update Cm of section based on C of Izhi
** Add option to save different data (specs, instance, output) to different file names
including dat (txt) format


