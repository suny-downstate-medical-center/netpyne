* 15may27 Modularized framework for NEURON/Python network simulations with MPI
** Overview
Using this modularized structure can select different cell types, populations, connectivities, etc. just by modifying the
parameters in params.py. 

An example is provided in params.py which switches from a single Hodgkin-Huxley population, randomly connected model
(mpiHHTut); to a multiple Izhikevich populations, yfrac-dependent connected M1 model.

To test this just modify the variable simType in params.py: 
simType = 'M1model' # 'mpiHHTut' 

*** Bill's description of what this repo should be
we should try to make this our main organizational code that can spin off multiple projects? -- would like a clean code center-org so that not so painful as it has been with our prior code base (which btw was all my fault and not sam's -- he inherited from me)
then any pushes back to this main center would have to be agreed by curator (you) and would generally involve just some small fix to a single file

** README with description of the different files
List of files:

- main.py: Main executable; calls functions from other modules.

- params.py: Contains all static parameters. It is imported as "p" from all other modules, so that params can be referenced from any file using p.paramName

- shared.py: Contains all the model shared variables and modules (except params.py). It is imported as "s" from all other file, so that any variable or module can be referenced from any file using s.varName

- sim.py: Simulation control functions (eg. runSim)

- network.py: Network related functions (eg. createCells)

- cell.py: contains cell and population classes 

- conn.py: contains class 'Conn' used to instantiate connections, and contains methods to connect cells (eg. random, yfrac-based)

- analysis.py: functions to plot and analyse data

- stimuli.py: functions and parameters for differnt types of neural stimulation

- izhi2007.mod: NMODL definition of Izhikevich 2007 neuron model

- evol.py: Functions to run evolutionary algorithms (using inspyred) to optimize model parameters

** Known issues, potential improvements, and alternative implementations (outdated - see TODO list at end of file)
*** TODO - Saving only happens at the end (instead of at fixed intervals)
*** TODO - Need to add a DEBUG mode or similar (like mpiHHTut had)
- currently have a verbose flag, that prints some additional info
- also have print messages along the code, which could be made optional
*** TODO - Check structure of data saved to file
- some nested lists with inhomogeneous dimensionality were converted to 'object' data types in order to be saved -- check if
  structure makes sense when reading from python/matlab
*** DONE - Some attributes/variables of the class 'Cell' and 'Pop' are not used but still initialized to [ ]
- maybe can find alternative using different constructors for different cell types
- fixed by using dictionary of tags - flexible for eahc type
*** DONE - Labels (eg. AMPA, IT, HH,...) are defined by assigning numeric values to variables
- can use dictionaries instead
- need to check pros and cons of each -- are dicts slower or have any limitations compared to lists/arrays ?
- changed to using dictionaries
*** TODO - stimuli.py not tested with this model
- left there cause thought could be useful for future
*** TODO - analysis.py still has many functions which havent been adapted to new structure
*** TODO - Some variables inherited from cliff still have too long names, eg. backgroundSpikevec
*** TODO - Lines too long, need to split using \
*** DONE - if increase p.backgroundNoise > 0.0 get memory error 
- had to store rnadom noise generator separately for each cell
*** DONE - Find a way to save lambda funcs (can't be pickled)
can use:
>>>import inspect 
>>>inspect.getsource(myfunc)
*** DONE - Clearing vector in simdata now gives error because also has python variables
for v in s.simdata.itervalues() -- fix error
separated vectors
*** TODO - 'Cell' class record method uses eval() which is unsafe
*** DONE - currently setup to record traces from all cells
*** DONE - bug when saving cell traces using multiple cores 
Gathering spikes...
>>> >>> >>> Traceback (most recent call last):
  File "main.py", line 46, in <module>
    runSeq()
  File "main.py", line 37, in runSeq
    s.sim.gatherData()
  File "sim.py", line 117, in gatherData
    for d in gather: tmp.extend(d[k]) 
KeyError: 'cellTraces_233'

- now saved using different structure 
- had to remove hoc objects that are not pickable


*** TODO - Load/save net+sim parameters from file
- load net and sim parameters file from mat?
- have different .py file to generate the params files

within params.py - have option to load from file, or set params and save to 2 files net and sim.mat
- maybe functions in sim.py? can be called from params?
*** DONE - Store net and sim params in dictionaries inside params.py
eg. p.net['ncells']
- facilitates saving to file (prev point)
- can use if key in dict:

- use regexp in submlime text to replace in all files:
Find What: p\.(\w+)
Replace With: p\.sim['$1']

*** TODO - Use dict of tags/attributes for pop params and for cells
eg. p.net['popParams'][i]['cellModel']
- can use if key in dict:
*** Define conn rules based on pair of tag/value for pre and post
eg. use tuple key: connProbs['name','IT','name','IT']  = (lambda x,y: 0.1*x+0.01/y) 
or dict of dict with tuple keys: connProbs['name','IT']['name','IT']  = (lambda x,y: 0.1*x+0.01/y) 
*** DONE - Add $Id$ hg info
- can do with https://mercurial.selenic.com/wiki/KeywordExtension
- but not recommended 
- bill wanted to do because cliff and I add last update and author info to files -- which is never updated correctly
- checked other github repos and they don't have it - just eg. Contributors
*** DONE - Rename main.py with init.py
*** DONE Remove popType and connType variables - infer from dict keys
*** DONE Remove popid from popParams - can use list index
*** TODO Replace topClass and subClass with projection-type, type (neurotransmitter involved?)
**** email to Ben
Hey Ben, Im working on some of the changes we discussed. I've replaced variables with dictionaries of tags/attributes. For now, I've kep the 'population' concept, although can replace in future version if makes sense. 

For both the 'population' and 'cell' objects you suggested replacing the 'topClass' and 'subClass' tags with 'projectionType' and 'cellType' if my notes are correct. I know projType for Exc cells will be 'IT', 'PT' or 'CT', but not sure what would be the best classification for Inh cells? Same thing for cellType, I think you mentioned neurotransmitters involved, but could you elaborate on what would be the list of possible values for both 'Exc' and 'Inh' cells/pops ?  

We can use the google chat or this google doc to bounce ideas back and forth (link points to new section ready to be filled in).

*** TODO Synapse
- synapses as list of objects inside each cell (postsynaptic) - netcon in pre is stub; netcon in post is real synapse
- netcon (neuron object) as part of synapse object



* 15dec28 Convert into python package
- PyNet ? NeuPyNE, NeuPyNet, netpyne !! PYthon-based NETwork development framework for the NEuron simulator
- make shared -> framework 
- from pynet import framework as f
- just need init.py and param.py file
- to add cells or conn functions use:
-- class newCellClass(PointNeuron): ... ;  f.newCellClass = newCellClass 
-- class newConnFunc(): ... ; f.newConnFunc = newConnFunc
- default simConfig
- from pynet import init ; init.createAndRun(netParams, simConfig)

* 16jan26 Possibly making more simulator-indep using NeuroML-based format
** NeuroML format 
- could represent all nml format using python dicts (instantiated net)
- additional abstract layer (connParams, netParams etc) - using more general format and then converted to nml
- eg. https://github.com/OpenSourceBrain/Thalamocortical/tree/master/neuroConstruct/generatedNeuroML2
- https://www.neuroml.org/getneuroml
- https://www.neuroml.org/tool_support
- https://github.com/NeuralEnsemble/libNeuroML
- https://github.com/NeuroML/pyNeuroML
- http://bioportal.bioontology.org/ontologies/CNO
- http://www.neuroconstruct.org/
- http://neuronvisio.org/


*** Issues
- Would like to keep simple declarative (python dicts based) specifications
- Want to make netpyne more NEURON-independent, both at specifications, and py instantiated network
- netpyne makes use of mod files, but neuroml requires detailed specification
- netpyne provides conversion from abstract specifications -> instantiated network, and support for multicompartment, and
  subcellular connectivity
- netpyne provides instantiation of NEURON objects, and parallel simulation of network
- netpyne can use NeuroML structure but using dictionaries instead of xml text - so easy to manipulate
- libneuroml and pynn - procedural, not so intuitive, and require internal definition of cell types etc (eg. IAF); whereas
  netpyne is 'declarative', more intuitive?, can define arbitrary cell props based on mechs and syns
- dictionary of equivalences NEURON<->NeuroML (eg. tau1, rise)

*** cells
NOTE: segment = sections/segment; segmentGroup = sectionList/section
- can have segmentGroups that consist of segmentGroups
- Neuron sections->segmentGroups
- Neuron 3d points -> segmnets
- Neuron nseg -> property tag numberInternalDivisions
- if have pointProcess in segment -> mapping of position along section and where pointprocess is placed

    <include href="nap.channel.nml"/>

    <include href="pas.channel.nml"/>

<cell id="SupAxAx">

        <notes>Cell: supaxax_0 exported from NEURON ModelView</notes>

        <morphology id="morphology_SupAxAx">

            <segment id="0" name="Seg0_comp_1">
                <proximal x="0.0" y="0.0" z="0.0" diameter="15.0"/>
                <distal x="0.0" y="10.0" z="0.0" diameter="15.0"/>
            </segment>

            <segment id="1" name="Seg1_comp_1">
                <parent segment="0"/>
                <distal x="-4.371139E-7" y="20.0" z="0.0" diameter="15.0"/>
            </segment>

 <segmentGroup id="prox_dend_soma">
                <include segmentGroup="comp_1"/>
                <include segmentGroup="comp_41"/>
                <include segmentGroup="comp_28"/>
                <include segmentGroup="comp_15"/>
                <include segmentGroup="comp_2"/>
            </segmentGroup>


	<biophysicalProperties id="biophys">

            <membraneProperties>
                
                <channelDensity condDensity="0.0 mS_per_cm2" id="ar_ModelViewParmSubset_1" ionChannel="ar__m00_25" segmentGroup="ModelViewParmSubset_1" erev="-40.0 mV" ion="ar"/>
                
                <channelDensity condDensity="0.1 mS_per_cm2" id="cal_ModelViewParmSubset_4" ionChannel="cal" segmentGroup="ModelViewParmSubset_4" ion="ca" erev="125.0 mV"/>
                
                <channelDensity condDensity="0.2 mS_per_cm2" id="cal_ModelViewParmSubset_5" ionChannel="cal" segmentGroup="ModelViewParmSubset_5" ion="ca" erev="125.0 mV"/>
                
                <channelDensity condDensity="0.0 mS_per_cm2" id="cat_ModelViewParmSubset_1" ionChannel="cat" segmentGroup="ModelViewParmSubset_1" ion="cat" erev="125.0 mV"/>
                
                <channelDensity condDensity="0.0 mS_per_cm2" id="k2_all" ionChannel="k2" ion="k" erev="-100.0 mV"/>
                
                <spikeThresh value="0.0 mV"/>

                <specificCapacitance value="1.0 uF_per_cm2"/>

                <initMembPotential value="-65.0 mV"/>


*** connections
<projection id="LTS_AxAx_sm" presynapticPopulation="CG_C04_LTS_sm" postsynapticPopulation="CG_C04_AxAx_sm" synapse="Inh_LTS_FS">
            <connection id="0" preCellId="../CG_C04_LTS_sm/5/SupLTSInter" postCellId="../CG_C04_AxAx_sm/0/SupAxAx" preSegmentId="112" preFractionAlong="0.26785243" postSegmentId="82" postFractionAlong="0.36041966"/>
            <connection id="1" preCellId="../CG_C04_LTS_sm/3/SupLTSInter" postCellId="../CG_C04_AxAx_sm/0/SupAxAx" preSegmentId="116" preFractionAlong="0.6782849" postSegmentId="91" postFractionAlong="0.99472666"/>
            <connection id="2" preCellId="../CG_C04_LTS_sm/6/SupLTSInter" postCellId="../CG_C04_AxAx_sm/0/SupAxAx" preSegmentId="112" preFractionAlong="0.42696908" postSegmentId="84" postFractionAlong="0.46009916"/>
            <connection id="3" preCellId="../CG_C04_LTS_sm/0/SupLTSInter" postCellId="../CG_C04_AxAx_sm/0/SupAxAx" preSegmentId="113" preFractionAlong="0.92599744" postSegmentId="83" postFractionAlong="0.60695267"/>
            <connection id="4" preCellId="../CG_C04_LTS_sm/9/SupLTSInter" postCellId="../CG_C04_AxAx_sm/0/SupAxAx" preSegmentId="113" preFractionAlong="0.5823235" postSegmentId="39" postFractionAlong="0.646692"/>
            <connection id="5" preCellId="../CG_C04_LTS_sm/6/SupLTSInter" postCellId="../CG_C04_AxAx_sm/0/SupAxAx" preSegmentId="113" preFractionAlong="0.16917303" postSegmentId="57" postFractionAlong="0.6089958"/>

*** synapses
<?xml version="1.0" encoding="ISO-8859-1"?>
<neuroml xmlns="http://www.neuroml.org/schema/neuroml2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.neuroml.org/schema/neuroml2 https://raw.github.com/NeuroML/NeuroML2/development/Schemas/NeuroML2/NeuroML_v2beta4.xsd" id="Syn_AMPA_L4SS_IN">

    <notes>ChannelML file describing a single synaptic mechanism</notes>

    <alphaSynapse id="Syn_AMPA_L4SS_IN" tau="0.8ms" gbase="2.94303552937e-07mS" erev="0.0mV">

        <notes>Synapse with syn scaling constant c = 1 nS (translating to max cond of 2.94304e-07 mS), time course: 0.8 ms and reversal potential: 0 mV.
        Automatically generated by command:  genSyn.py Syn_AMPA_L4SS_IN 0.8 1 0 </notes>
</alphaSynapse>

</neuroml>
*** population

        <population id="CG_C04_FRB_sm" component="L23PyrFRB_varInit" type="populationList" size="6">
           <annotation>
                <property tag="color" value="0.0 0.0 0.0"/>
            </annotation>
            <instance id="0">
                <location x="-739.27563" y="-798.43396" z="-440.9723"/>
            </instance>
            <instance id="1">
                <location x="975.8342" y="-870.85077" z="1090.1094"/>
            </instance>
            <instance id="2">
                <location x="-1012.162" y="-785.71173" z="1053.8684"/>
            </instance>
            <instance id="3">
                <location x="-1391.423" y="-776.4188" z="-32.483643"/>
            </instance>
            <instance id="4">
                <location x="149.5564" y="-790.7691" z="433.74915"/>
            </instance>
            <instance id="5">
                <location x="585.53955" y="-765.37933" z="819.1377"/>
            </instance>
        </population>


*** pulse generator (netstim?)
   <pulseGenerator id="DepCurr_L23FRB" delay="0.0s" duration="20.0s" amplitude="3.0E-10A"/>
    
    <pulseGenerator id="DepCurr_L23FRB__0" delay="0.0s" duration="20.0s" amplitude="3.37936E-10A"/>
** chat with Bill
summary of 3-hr meeting with Ben: 1) he really likes netpyne, 2) discussed how to add subcellular syn info (3 main methods: sectionlists, yfrac-based, path distance-based), 3) provided his unpublished code to convert sCRACM data to synapse density maps and said we can use in netpyne, 4) suggested making netpyne more NEURON/simulator-independent (similar to Kim Blackwell)

on this last point (simu-indep), I looked at NeuroML2 format, and some of the tools Padraig has built 2 interface it with Python and Neuron (eg. neuroconstruct, pyNeuroML, libNeuroML), and read Robert's reproducibility paper

I think it might be possible to make netpyne simulator-independent at the specs and instantiated network, using a NeuroML-like internal format (but using python dicts instead of xml so can manipulate data) -- and then keep final stage where its converted to Neuron simulatable objects

sent padraig an email to discuss the technical details of what they've already implemented and how netpyne could fit, and be useful to fill in missing tools in this whole story

an alternative is to keep it as a tool specific for Neuron, with its internal Neuron-based format for specs and network, and the possibility of exporting/importing from NeuroML and others (ie. its current status)

** chat with Padraig
- good to separate M1 model from netpyne
- similarities with pnn and libneuroml
- important of neuroml is conceptual structure
- libneuroml has cell types
- mapping from pyneuroml to mod files, but not the other way around

- standardization of abstract conn rules is above pynn and nueroml/pyneuroml
- eg 10 conn algorithms -> pynn -> neuroml
- morphology - segments, segment groups

- mod files would need to be translated into nueroml (not fully translated); alternative would be point to nueroml
  definition, convert via pyneuroml to Neuron mod
- setup.py to netpyne
- dot.travis.yml continuous integration server - run tests every time there is a commit to repository - make sure its consistent
  with latest version

- convert from Neuron model to NeuroML:
-- export specifications 
-- OSB converting to NeuroML2 cell morphology (pyneuroml.convert_to_neuroml2) - in future if already in neuroml dont need to
 define in Nueron/netpyne format 
-- Izhikevich (params) - abstract definiton
-- export to Nueroml2 positions and connectivity - no current tool to convert
-- https://github.com/OpenSourceBrain/Cerebellum3DDemo
-- http://www.opensourcebrain.org/docs#Converting_To_NeuroML2


- convert from NeuromML to Neuron:
-- java script to convert neuroml to mod and Neuron/py files - wait for better iteration
-- adapt java code to convert directly to netpyne
-- https://github.com/NeuroML/org.neuroml.export/blob/development/src/main/java/org/neuroml/export/neuron/NeuronWriter.java
-- https://github.com/NeuroML/org.neuroml.export/blob/development/src/main/java/org/neuroml/export/pynn/PyNNWriter.java
-- check param files hhtut izhitut updated so can padraig can modify
-- add load cell function in netpyne in neuroml format


- differences:
1) declarative
2) netpyne makes use of mod files, but neuroml requires detailed specification
3) netpyne provides conversion from abstract specifications -> instantiated network, and support for multicompartment, and
  subcellular connectivity
4) netpyne provides instantiation of NEURON objects, and parallel simulation of network

- options:
-- long-term: use Neuroml internally for instantiated network 
-- short-term:  Neuron-based and conversion to NeuroML; 

* 16jan27 Consolidate connectivity functions
** Full conn -> fullConn
- =probConn with prob = 1?
** combine convConn, divConn, and randConn?
- probFunc = optional param -- if not present, then:
- select function depending of param included? eg. 'convergence', 'divergence', 'probability'
** Random conn with N conns per postsyn cell (convergence) -> convConn
~= conv conn
- conv param allowed as function eg. uniform, gauss
- also allows for weight+delay as func
** Random conn with N conns per presyn cell (divergence) -> divConn
** Random conn with fixed, function (including distance-dep) prob, weight, delay -> probConn
*** fixed
number eg. 5
*** func
- uniform
*** func dist-dep
- function of yfrac
- function of 3d distance
- generalizable to func of 
-- (pre, post, dist) + '_' + (xfrac, yfrac, zfrac, x, y, z) = 18 variables
-- (dist) + '_' + (xznorm, xyznorm, xz, xyz) = 4 variables
-- total: 22 variables
- create dictionary with each variable associated to its value/variable/function -- don't evaluate to save
- enter as string, and convert to function
- other variables allowed: any that are defined in f.net.params[var] -- arbitrary
** implementation
- use **kwargs
- string based - converted to function, extract variables
- arguments weight and delay valid for all conn types; and can be functional

Options to implement func:
*** lambda with kwargs - NO
prob = lambda(**d): d['pre_ynorm']*0.5
*** lambda with args - NO!
prob = lambda(*d): d[3]*0.5
*** string
prob = 'pre_ynorm*0.5'
prob = 'post_xyznorm*0.5
prob = 'uniform()'
prob = 'gauss(10,5)'
prob = 'uniform(1,5)'
- functions allow all of python random functions 
- internal implementation:
-- identifiy variables (pre, post or dist x,y,z,2d or 3d; plus any arbitrary defined in netParams)
-- define dict mapping variable name to lambda function returning actual variable using preCell and postCell as args
-- convert string to lambda function with variables as arguments
-- call lambda function with args as dict with each entry mapped to lambda func that returns the variable
*** efficiency
- calculate all delay, prob, weight funcs together at the beginning
- calcualte weights+delays for all possible conns despite some will not be used?
- alternative might be more comput costly (calling 1 by 1), and repeated code
- use map(lambda, list)
- calculate final list of weights,probs,delays and pass to specific conn func

*** errors
- arguments by reference using lambda func only works for 'delay' if 'convergence' func loops over preCellsTags and postCells
  -- even though they have nothing to do with each other!! whats going on? python bug? Im missing something?!

** comparison to PyNN
*** class AllToAllConnector(allow_self_connections=True, safe=True, callback=None)[source]
=fullConn
*** class OneToOneConnector(safe=True, callback=None)[source]
=conn rule specifying cell ids
*** class FixedProbabilityConnector(p_connect, allow_self_connections=True, rng=None, safe=True, callback=None)[source]
=probConn
*** class FromListConnector(conn_list, column_names=None, safe=True, callback=None)[source]
=conn rule specifying cell ids
*** class FromFileConnector(file, distributed=False, safe=True, callback=None)[source]
=conn rule specifying cell ids
*** class ArrayConnector(array, safe=True, callback=None)[source]
=conn rule specifying cell ids
*** class FixedNumberPreConnector(n, allow_self_connections=True, with_replacement=False, rng=None, safe=True, callback=None)
=divConn
*** class DistanceDependentProbabilityConnector(d_expression, allow_self_connections=True, rng=None, safe=True, callback=None)[source]
= probConn with dist-dep func

*** class IndexBasedProbabilityConnector(index_expression, allow_self_connections=True, rng=None, safe=True, callback=None)[sour
= conn rule specifying cell ids
*** class SmallWorldConnector(degree, rewiring, allow_self_connections=True, n_connections=None, rng=None, safe=True, callback=N
not implemented
*** class CSAConnector(cset, safe=True, callback=None)[source]
not implemented
** comparison to NEST
*** ConvergentConnect
Connect many source nodes to one target node.
=convConn
*** DivergentConnect
Connect one source node to many target nodes.
= divConn
*** RandomConvergentConnect
Randomly connect one source node to many target nodes.
= convConn with uniform func
*** RandomDivergentConnect
Randomly connect one source node to many target nodes.
= divConn with uniform func
*** BinomialConvergentConnect
Connect a target to a binomial number of sources.
??

* TODO
** DONE - unify cellmodel 
- cell prop conditions: 
-- cellType=RS; cellModel=HH
-- cellType=RS; cellModel=Izhi
- provide option to insert distribute mechanism or point process
- single cell class 
- then add support for 2007a - spikes+record from izh._ref_V

- INCLUDE BOTH HH AND IZHI IN SAME RULE AND USE CELLMODEL TAG IN CELL TO CHOOSE WHICH TO USE!!

** DONE - Overwrite files optional (timestamp)
** DONE - Default simConfig
** DONE - Import cells with generic set of arguments
** DONE - Use mechanismType to make importCell more robust
https://www.neuron.yale.edu/neuron/static/new_doc/modelspec/programmatic/mechtype.html
https://www.neuron.yale.edu/neuron/static/new_doc/programming/mechstan.html
http://neurosimlab.org/ramcd/pyhelp/mechstan.html#MechanismStandard - 2nd example

- use params with initial underscore '_var' to indicate used by netpyne, not mechanism/pointprocess variable - add to docu!
** DONE Check Izhi2007a
** DONE Distinguish syns from other point processes 
- no way to do it
- assume 'syn' in name -- establish naming convention -- added to doc

- syn: true, false, false (.is_netcon_target() = True; .has_net_event(i) = False; .is_artificial() = false)
- artcell: true, true?, true
- izh2007a: true, true, false
- izhi2007b: true, false, false

MechanismType.is_netcon_target()
Syntax:
boolean =  mt.is_netcon_target(i)
Description:
The i'th point process has a NET_RECEIVE block and can therefore be a target for a NetCon object.

MechanismType.has_net_event() 
Syntax:
boolean = mt.has_net_event(i)
Description:
The i'th point process has a net_event call in its NET_RECEIVE block and can therefore be a source for a NetCon object. This
means it is NetCon stimulator or that the point process can be used as an artificial neural network cell.

MechanismType.is_artificial() 
Syntax:
boolean = mt.is_artificial(i)
Description:
The i'th point process is an ARTIFICIAL_CELL and can therefore be a source for a NetCon object. This means it is NetCon stimulator or that the point process can be used as an artificial neural network cell.

This seems to have, but does not, equivalent functionality to has_net_event() and was introduced because ARTIFICIAL_CELL
objects are no longer located in sections. Some ARTIFICIAL_CELLs such as the PatternStim do not make use of net_event in
their implementation, and some PointProcesses do use net_event and must be located in sections for their proper function,
e.g. reciprocal synapses.

** DONE Make list of data saved part of simCfg
- simConfig, netParams, net, simData
- added to docu

** DONE Test importing Friesen, mainen, traub cell models
- Read python names in importCell
-- use dir; check if section; compare with secList

- 'synReceptor' check for syn type not name

** DONE Associate_gid from axon
- section['spikeGenLoc'] = 0.5

** DONE HDF5
- tried h5py (http://docs.h5py.org/en/latest/quick.html)
Saving output as example-20160108_200403.hdf5... 
Traceback (most recent call last):
  File "init.py", line 24, in <module>
    f.sim.saveData()                    # save params, cell info and sim output to file (pickle,mat,txt,etc)
  File "/usr/site/nrniv/pypkg/netpyne/sim.py", line 346, in saveData
    hickle.dump(dataSave, f.cfg['filename']+'.hdf5', mode='w')
  File "/u/salvadord/anaconda/lib/python2.7/site-packages/hickle.py", line 376, in dump
    dumper(obj, h5f, **kwargs)
  File "/u/salvadord/anaconda/lib/python2.7/site-packages/hickle.py", line 300, in dump_dict
    _dump_dict(obj, hgroup, **kwargs)
  File "/u/salvadord/anaconda/lib/python2.7/site-packages/hickle.py", line 282, in _dump_dict
    _dump_dict(dd[key], new_group, **kwargs)
  File "/u/salvadord/anaconda/lib/python2.7/site-packages/hickle.py", line 269, in _dump_dict
    hgroup.create_dataset("%s" % key, data=dd[key], **kwargs)
  File "/u/salvadord/anaconda/lib/python2.7/site-packages/hickle.py", line 88, in create_dataset
    return super(H5GroupWrapper, self).create_dataset(*args, **kwargs)
  File "/u/salvadord/anaconda/lib/python2.7/site-packages/h5py/_hl/group.py", line 94, in create_dataset
    dsid = dataset.make_new_dset(self, shape, dtype, data, **kwds)
  File "/u/salvadord/anaconda/lib/python2.7/site-packages/h5py/_hl/dataset.py", line 79, in make_new_dset
    tid = h5t.py_create(dtype, logical=1)
  File "h5t.pyx", line 1389, in h5py.h5t.py_create (h5py/h5t.c:13046)
  File "h5t.pyx", line 1463, in h5py.h5t.py_create (h5py/h5t.c:12893)
TypeError: Object dtype dtype('O') has no native HDF5 equivalent

- tried hdf5storage (http://pythonhosted.org/hdf5storage/introduction.html#getting-started)
Traceback (most recent call last):
  File "init.py", line 24, in <module>
    f.sim.saveData()                    # save params, cell info and sim output to file (pickle,mat,txt,etc)
  File "/usr/site/nrniv/pypkg/netpyne/sim.py", line 348, in saveData
    hdf5storage.write(dataSave, filename=f.cfg['filename']+'.hdf5')
  File "build/bdist.macosx-10.5-x86_64/egg/hdf5storage/__init__.py", line 1399, in write
    
  File "build/bdist.macosx-10.5-x86_64/egg/hdf5storage/__init__.py", line 1318, in writes
    
  File "build/bdist.macosx-10.5-x86_64/egg/hdf5storage/lowlevel.py", line 114, in write_data
  File "build/bdist.macosx-10.5-x86_64/egg/hdf5storage/Marshallers.py", line 1557, in write
NotImplementedError: Dictionaries with non-unicode keys are not supported: 'netParams'

- try this: http://stackoverflow.com/questions/16705274/fastest-way-to-convert-a-dicts-keys-values-from-str-to-unicode

- converted to unicode using dict2utf8() func, but now get segmentation fault for all except simConfig dict

- empty dicts {} caused seg fault -- replaced with []

** DONE Enable providing num spikes in Netstim (paper)
** DONE Set v_init before calling init() (paper)
- netParam param
- 'vinit' param in section
- automatically set vinit=vr for izhis - not needed cause fixed mod
- add to doc

** setup.py pip install (paper)
** DONE Conv and div conn (paper)
- made conn very flexible by allowing function for: prob, conv, div, weight and delay
- funcs can include spatial/distance variables; and others defined in netParams
- can implement a large range of functionalities with very generic implementation
** DONE Add x,z,xnorm,znorm positions (paper)
** DONE Plot cell from specific population (paper)
- and or one of each population

** DONE Allow to define xrange and zrange of pops
- also xfracrange and zfracrange
- for fixed cell density, easy, just don't calcualte rand
- for functional density more complex
- make generic so no distinction between coordinates
** Fix NetStim connectivity
** fix so lambda funcs saved as string
** import/export NeuroML (paper)
- padraig (see notes above)
** Functions to load simConfig, netParams, net, simData (paper)
** timing (paper)
** Add support for SectionLists (paper)
** importCell can modify h variables (eg. celsius) (paper)
- maybe just note in documentation that shouldnt modify h.vars - undesired effects
** simple LFP (paper) 
- simple voltage sum 
** Plot conn matrix (paper)
- by cells and populations
** Subcellular synaptic connectivity (paper)
- distribution of syns across segments based on empirical map
- concept of logical connection subsumes subset of unitary connections

** Stimulation - iclamp,vclamp, opto, microelectrode (paper?)
- maybe iclamp for paper?


** Evol params batch
** Set positions in Neuron's 3D space
** LFPy
** Save plots to file
** Conn/props just in master node
** normalized transfer entropy (nTE)
** Granger causality
** Add support for point neuron outside of section
eg. IntFire1,2,3,4 
 ARTIFICIAL_CELL means
     3 	: that this model not only has a NET_RECEIVE block and does NOT
     4 	: have a BREAKPOINT but is not associated with a
     5 	: section location or numerical integrator. i.e it does not
     6 	: refer to v or any ions or have a POINTER. It is entirely isolated
     7 	: and depends on discrete events from the outside to affect it and
     8 	: affects the outside only by sending discrete events.

- outside of section so need different method - maybe not worth? 

** RxD 
/u/samn/m1dyst -> models/m1dyst
https://www.neuron.yale.edu/neuron/static/docs/rxd/index.html
** Saving at intervals
** Plasticity
- Hebbian
- STDP
** modify instantiated network
- load net and provide new set of params
** Make simulator-indep using NeuroML internal format
** GUI
** Test adaptive exp cell (no Neuron code)
student doing
** Make opensource with contributions from community
There are several ways to contribute to PyNN:

reporting bugs, errors and other mistakes in the code or documentation;
making suggestions for improvements;
fixing bugs and other mistakes;
adding or maintaining a simulator backend;
major refactoring to improve performance, reduce code complexity, or both.
